% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{fontspec}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{colortbl}
\usepackage{hhline}
\newlength\Oldarrayrulewidth
\newlength\Oldtabcolsep
\usepackage{longtable}
\usepackage{array}
\usepackage{hyperref}
\usepackage{float}
\usepackage{wrapfig}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={R for Environmental Chemistry},
  pdfauthor={David Hall, Steven Kutarna, Kristen Yeh, Hui Peng, Chaerin Song, and Jessica D'eon},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{R for Environmental Chemistry}
\author{David Hall, Steven Kutarna, Kristen Yeh, Hui Peng, Chaerin Song, and Jessica D'eon}
\date{Last built on: 2024-02-11}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
## v dplyr     1.1.4     v readr     2.1.4
## v forcats   1.0.0     v stringr   1.5.1
## v ggplot2   3.4.4     v tibble    3.2.1
## v lubridate 1.9.3     v tidyr     1.3.0
## v purrr     1.0.2     
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
\end{verbatim}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

Howdy,

This website is more-or-less the living result of a collaborative project between us. We're not trying to be an exhaustive resource for all environmental chemists. Rather, we're focusing on developing broadly applicable data science course content (tutorials and recipes) based in \texttt{R} chemistry courses and research.

This book will is broken up into four sections:

\begin{itemize}
\tightlist
\item
  \textbf{Section 1: Getting Started in R} is a general guide for the complete novice that will help you install, setup, and run R code.
\item
  \textbf{Section 2: How to Code in R} introduces the basics of R programming as well as a usual R workflow, and how to use R markdown to communciate your code with others.
\item
  \textbf{Section 3: Data Wrangling} introduces data analysis workflows and showcases \emph{how} you can use R and the \texttt{tidyverse} to import and clean up your data into a consistent format to tackle the vast majority of the data science/analysis problems you'll encounter in undergraduate environmental chemistry courses.
\item
  \textbf{Section 4: Data Analysis Toolbox} provides code and theory behind the most common data analysis practices in environmental chemistry. These include linear regression analysis, a myriad of visualizations, etc.
\item
  \textbf{Section 5: Notes for Env. Chem. Labs} consist of chapters specific to individual laboratory experiments. They rely upon knowledge from the previous three sections to introduce concepts unique to individual labs.
\end{itemize}

We recommend that you read through Sections 1 and 2 in sequential order. These provide the foundation for the consistent data analysys workflow used throughout Sections 3 and 4.

\hypertarget{providing-feedback}{%
\section*{Providing Feedback}\label{providing-feedback}}
\addcontentsline{toc}{section}{Providing Feedback}

If you notice an error, mistake or if you have suggestions for adding features or improving the book, please reach out to us or flag an issue on \href{https://github.com/UofTChem-Teaching/R4EnvChem/issues}{GitHub}.

\begin{itemize}
\tightlist
\item
  \href{https://www.chemistry.utoronto.ca/people/directories/all-faculty/jessica-deon}{Jessica D'eon} at \url{jessica.deon@utoronto.ca}
\end{itemize}

\hypertarget{acknowlegements}{%
\section*{Acknowlegements}\label{acknowlegements}}
\addcontentsline{toc}{section}{Acknowlegements}

Additionally, we would like to thank Jeremy Gauthier, Andrew Folkerson, Mark Panas, and Stephanie Schneider for all of their comments, suggestions, and hard work integrating the concepts of this book into the \emph{CHM410} Laboratory curriculum.

\hypertarget{part-part-1-getting-started-in-r}{%
\part*{Part 1: Getting Started in R}\label{part-part-1-getting-started-in-r}}
\addcontentsline{toc}{part}{Part 1: Getting Started in R}

\hypertarget{intro-to-r-and-rstudio}{%
\chapter{Intro to R and RStudio}\label{intro-to-r-and-rstudio}}

You may have heard about the coding or the R programming language, but figuring out how to get started can be a hurdle; at least it was for us. In this guide, we will walk you through the process of setting up R and RStudio, both locally on your computer and remotely using the University of Toronto's JupyterHub R Studio server.

\hypertarget{r-language}{%
\section{R Language}\label{r-language}}

\textbf{R} is the programming language we'll code in. R is hosted on the Comprehensive R Archive Network (CRAN) and is one of the most popular programming languages for statisticians and scientist alike due to its vast array of tools and packages.

A quick aside, but don't be intimidated by the term ``coding''. Coding is simply writing instructions for the computer to execute. The only catch is has to be in a language that both we, humans, and the computer can understand. For our needs we're using R, and like any language, R has it's own syntax, rules, and quirks which we'll cover in later chapters.

\hypertarget{rstudio}{%
\section{RStudio}\label{rstudio}}

\textbf{RStudio} is a popular \emph{integrated development environment (IDE)} specifically designed for working with R, providing a user-friendly interface and various productivity features. It's where you'll actually be typing your code and interacting with R. Again, R is a language, and you need somewhere to write it down to make use of it. Writing in English can be done with a pencil and notepad or a word processor filed with useful tools to help you write.

R and RStudio work in tandem to provide an efficient and seamless experience for data analysis, visualization, and model building. RStudio enhances the R workflow with features like code editing, interactive visualization, version control, and package management.

\hypertarget{setting-up-your-environment}{%
\section{Setting Up Your Environment}\label{setting-up-your-environment}}

Students learning R have \textbf{two options}: working \emph{locally} or \emph{remotely}

\emph{Working locally} involves installing R and RStudio on their computer, providing direct control over data and code without an internet connection. On the other hand, \emph{working remotely} enables access to RStudio through a web browser, avoiding local installations and allowing collaboration. \textbf{We recommend working remotely}, leveraging platforms like the University of Toronto's JupyterHub for its convenience and stable R Studio environment, making learning R easier and more efficient. We will go into more details in the below paragraphs.

\hypertarget{working-remotely-recommended}{%
\subsection{Working Remotely (Recommended)}\label{working-remotely-recommended}}

Working remotely means accessing R and RStudio from a remote server or cloud-based platform.

\textbf{UofT JupyterHub RStudio server}

To facilitate remote access to RStudio, the University of Toronto provides a JupyterHub R Studio server. This allows you to access RStudio from any web browser, eliminating the need for local installations. With this, you can perform data analysis, collaborate with others, and work on your R projects remotely with ease.

To get started, visit \href{https://r.datatools.utoronto.ca/}{UofT JupyterHub}. You will need to log in with your UofT credentials to access the RStudio environment.

\begin{itemize}
\tightlist
\item
  While working remotely, you may need to upload data to the RStudio server or download analysis results. The RStudio interface allows you to upload files directly from your computer to the server and vice versa.
\item
  When working remotely, ensure that you save your R scripts and analysis files on the server. This will allow you to continue your work from any device with internet access.
\item
  Most R packages are pre-installed on the University of Toronto's R Studio server. However, if you require additional packages, we will soon learn how to install packages.
\end{itemize}

Remember that while working remotely, a stable internet connection is essential to ensure a smooth and uninterrupted experience. Additionally, always remember to save your work and log out properly after each session to maintain the security of your data. Happy coding!

\hypertarget{working-locally}{%
\subsection{Working Locally}\label{working-locally}}

When you work locally, you need to install both R and RStudio on your personal computer or a machine that you physically have access to.

\hypertarget{downloading-r-and-rstudio}{%
\subsubsection{Downloading R and RStudio}\label{downloading-r-and-rstudio}}

You can download the latest build of \textbf{R} for your operating system \href{https://cloud.r-project.org/}{here}. Choose the appropriate version for your operating system (Windows, macOS, or Linux) and follow the installation instructions.

You can download the latest version of \textbf{RStudio} \href{https://www.rstudio.com/products/rstudio/download/\#download}{here}.

Once you have both R and RStudio downloaded, go ahead and open up RStudio.

\hypertarget{using-rstudio}{%
\section{Using RStudio}\label{using-rstudio}}

When you open your RStudio (either locally or remotely), you'll be greeted with an interface divided into numerous panes. We've highlighted the major ones in the image below:

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_startup_regions.png}
\caption{The RStudio interface with annottated regions}
\end{figure}

Each pane serves a specific role:

\begin{itemize}
\tightlist
\item
  \textbf{The console} allows you to directly type and run your code. It also provides messages, warnings, and errors from any code you run.
\item
  \textbf{The environment} window lists all variables, data, and functions you've created since the start of your coding session.\\
\item
  \textbf{The viewer} shows your outputs, help documents, etc. which each has their own tab.
\end{itemize}

\hypertarget{running-r-code}{%
\section{Running R Code}\label{running-r-code}}

As we've already seen, you can run bits of R code directly from the console. Throughout the book, code you can copy and run will look like this:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{+} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

Noticed that both the code (the first part) and what the code outputs (the second part) are shown. Throughout this book code outputs will be proceeded by \texttt{\#\#}. You can run code directly from the console. It's handy for short and sweet snippets of code, something that can be typed in a single line. Examples of this is the \texttt{install.packages()} function, or to use R as a calculator:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{*} \DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{10}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.70796
\end{verbatim}

However, working like this isn't very useful Imagine printing a book one sentence at a time, you couldn't really go back and edit earlier work because it's already printed. That's why we write out code in \emph{scripts}. \emph{Scripts} are similar to recipes, in that they're a series of instructions that R evaluates from the top of the script to the bottom. More importantly, writing your code out in a script makes it \emph{more readable} to humans (presumably this includes you). Don't undervalue the usefulness of legible code. Your code will evaluate in seconds or minutes whereas it may take you hours to understand what it does.

Let's open up a new script in RStudio by going to \emph{File}-\textgreater{}\emph{New File}-\textgreater{}\emph{R Script}, or by clicking on the highlighted button in the image below.

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_newscript.png}
\caption{Figure 2.5: Opening a new script in RStudio.}
\end{figure}

This should open up a new window in the RStudio interface, as shown in the following image.

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_scriptwindow.png}
\caption{Figure 2.6: Scripts window in RStudio.}
\end{figure}

You can copy and paste the code above into the script, save it, edit it, etc. and ultimately run specific lines of code by highlighting them and pressing Ctrl+Enter (Cmd+Enter on Mac), or by clicking the ``Run'' button in the top right corner of the Scripts window. Whenever you copy code blocks from this website (or other online sources). If you're reading this book online, you can easily copy an entire block of code using the \texttt{copy} button in the top right corner of the code block.

We'll dive into the basics of coding in R in the next chapter.

\hypertarget{customizing-rstudio}{%
\section{Customizing RStudio}\label{customizing-rstudio}}

As many of us spend an absurd amount of time staring at bright screens, some of you may be interested in setting your RStudio to Dark Mode.

You can customize the appearance of your RStudio interface by clicking \emph{Tools}-\textgreater{}\emph{Global Options}, or \emph{RStudio}-\textgreater{}\emph{Preferences} on Mac, then clicking ``Appearance'' on the left. Select your preferred Editor Theme from the list.

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_darkthemes.png}
\caption{Figure 2.4: RStudio Appearance customization window.}
\end{figure}

\hypertarget{where-to-get-help}{%
\section{Where to get help}\label{where-to-get-help}}

While it's often tempting to contact your TA or Professor at the first sign of trouble, it's better to try and resolve your issues on your own. Given the popularity of R, if you've run into an issue, someone else has too and they've complained about it and someone else has almost certainly solved it! An often unappreciated aspect of coding/data science is knowing \emph{how} to get help, \emph{how} to search for it, and \emph{how} to translate someone's solutions to your unique situation.

Places to get help include:

\begin{itemize}
\tightlist
\item
  Google, Stack Overflow, etc. When in doubt Google it.
\item
  Using built-in documentation (\texttt{?help})
\item
  reference books such as the invaluable \href{https://r4ds.had.co.nz/index.html}{\emph{R for Data Science}}, which inspired this entire project.
\item
  And yes, when all else fails, holler at your TA/profs.
\end{itemize}

\hypertarget{summary}{%
\section{Summary}\label{summary}}

In this chapter we've covered:

\begin{itemize}
\tightlist
\item
  How to use RStudio to do R programming, both remotely and locally
\item
  Installing the \texttt{tidyverse()} package, the basis of the subsequent code in this book
\item
  How to customize the appearance of RStudio so you don't burn out your eyes at night
\end{itemize}

In the next chapter we'll break down how to setup your work in R for legibility, simplicity, and reproducibility. After all, the person cursing any of your sloppy work will invariably be you, so be kind to yourself, and do it right the first time.

\includegraphics{images/changing-stuff.jpg}

\hypertarget{exercise}{%
\section{Exercise}\label{exercise}}

Now that you've learned the basics of setting up and customizing R and RStudio, let's put some of that knowledge into practice.

\hypertarget{setup}{%
\subsection{Setup}\label{setup}}

\begin{itemize}
\tightlist
\item
  Access UofT JupyterHub RStudio server \href{https://r.datatools.utoronto.ca/}{here}.
\item
  (Optional) Change your RStudio appearance as you like.
\end{itemize}

\hypertarget{basic-r-commands}{%
\subsection{Basic R Commands}\label{basic-r-commands}}

\begin{itemize}
\tightlist
\item
  In the \texttt{Console} tab, write an expression to calculate 10 plus 5 and press \texttt{enter}.
\item
  Open a new R script and type in the following commands:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ y}
\FunctionTok{print}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15
\end{verbatim}

(In the future, we will work with an R markdown instead of an R script, which we will explain more in the following chapters.)

\begin{itemize}
\tightlist
\item
  Run the script. What is the output?
\end{itemize}

\hypertarget{using-the-help-function}{%
\subsection{USing the Help Function}\label{using-the-help-function}}

\begin{itemize}
\tightlist
\item
  Let's say you've come across a function in R that you don't know how to use, for example, \texttt{sqrt()}. Use the \texttt{?} command to access the documentation for this function from your console tab.
\item
  What does the \texttt{sqrt()} function do?
\end{itemize}

\hypertarget{reflection}{%
\subsection{Reflection}\label{reflection}}

\begin{itemize}
\tightlist
\item
  What are your first impressions of RStudio as an IDE? Do you have any prior experience with other programming languages or IDEs? If so, how does RStudio compare?
\end{itemize}

\hypertarget{rstudio-projects}{%
\chapter{RStudio Projects}\label{rstudio-projects}}

You're probably eager to start coding, but an equally important aspect is understanding the structure of your work. Knowing how to organize the files needed for your analysis and how to access them quickly is critical. Learning this early on will save you plenty of time and heartache down the line. So let's hold off on coding and consider \emph{where} we're working on your computer.

Because we believe in it so much, we'll say it up top: \textbf{Always work inside an RStudio Project, and use a unique project for each lab/experiment.}

\hypertarget{uploading-files-to-rstudio-server-on-jupyterhub}{%
\section{Uploading Files to RStudio server on JupyterHub}\label{uploading-files-to-rstudio-server-on-jupyterhub}}

When using the RStudio Server instance provided through JupyterHub, you may want to upload local data files, R scripts, or other relevant resources to work with them directly in RStudio. Here's a straightforward guide on how to accomplish this.

\textbf{Step-by-step guide}

\begin{itemize}
\item
  Once inside the RStudio server, you'll notice several panes. One of these is the \texttt{Files} pane, typically found in the bottom right corner. This pane displays the current directory's contents and allows you to manage files and folders.
\item
  In the \texttt{Files} pane, locate and click on the \texttt{Upload} button.
\end{itemize}

\includegraphics{images/upload_rstudio1.png}

\begin{itemize}
\tightlist
\item
  Then, click \texttt{Choose\ File} button to navigate to the location of the files on your local computer that you wish to upload to the RStudio Server.
\end{itemize}

\includegraphics{images/upload_rstudio2.png}

\begin{itemize}
\item
  This will prompt a file dialog to appear. Select the desired file(s) and click on Open or Choose (depending on your browser).
\item
  Once the file names appear in the RStudio interface, there might be a confirmation step to complete the upload. Click on \texttt{OK} or \texttt{Upload} to finalize the process.
\item
  After uploading, the uploaded files will appear in the \texttt{Files} pane.
\end{itemize}

\hypertarget{paths-and-directories}{%
\section{Paths and directories}\label{paths-and-directories}}

Before you get started with running your code, it is good to know where your analysis is actually occurring, or where your \textbf{working directory} is. The working directory is the folder where R looks for files that you have asked it to import, and the folder where R stores files that you have asked it to save.

RStudio displays the current working directory at the top of the console, as shown below, but can also be printed to the console using the command \texttt{getwd()}.

\includegraphics{images/Rstudio_wd.png}

By default, R usually sets the working directory to the home directory on your computer. The \texttt{\textasciitilde{}} symbol denotes the home directory, and can be used as a shortcut when writing a file path that references the home directory.

You can change the working directory using \texttt{setwd()} and an absolute file path. Absolute paths are references to files which point to the same file, regardless of what your working directory is set to. In Windows, absolute paths begin with \texttt{"C:"}, while they begin with with a slash in Mac and Linux (i.e., \texttt{"/Users/Vinny/Documents"}). It is important to note that absolute paths and \texttt{setwd()} should \textbf{never} be used in your scripts because they hinder sharing of code -- no one else will have the same file configuration as you do. If you share your script with your TA or Prof, they will not be able to access the files you are referencing in an absolute path. Thus, they will not be able to run the code as-is in your script.

In order to overcome the use of absolute paths and \texttt{setwd()}, we strongly recommend that you conduct all work in RStudio within an \textbf{R project}. When you create an R project, R sets the working directory to a file folder of your choice. Any files that your code needs to run (i.e., data sets, images, etc.) are placed within this folder. You can then use relative paths to refer to data files in the project folder, which is much more conducive to sharing code with colleagues, TAs, and Profs.

\hypertarget{importing-a-project}{%
\section{Importing a project}\label{importing-a-project}}

While you can create a project from scratch (discussed below), we've created a draft project template. Download it, and you'll have a working RStudio project that you can use as you follow along with the code in the rest of this chapter and the tutorial exercise.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Downloading the template project (zip file) from the \href{https://github.com/DavidRossHall/R4EnvChem-ProjectTemplate}{GitHub repository here}; there are instructions on downloading at the bottom of the repositories webpage.
\item
  Upload the project zip file to JupyterHub, and unzip the folder.
\item
  From RStudio click \texttt{File} -\textgreater{} \texttt{Open\ Project...} and open the \texttt{R4EnvChem-ProjectTemplate.Rproj} file from the unzipped folder.
\end{enumerate}

If you've followed the steps above you should have successfully downloaded and opened an RStudio project, and it should look like this:

\includegraphics{images/r-project-open.jpg}

Note how the project name is displayed on the top right. You can quickly switch between projects here which is useful if you'll be using R for many different labs/courses. As well, take note that the working directory has changed to the one where the RStudio project is located. Since you've downloaded the entire project, the working directory for the project includes the example scripts and data files you'll need to continue along with the remainder of this book. If you open the project folder (or access it from the \texttt{Files} tab) it should look like this:

\begin{verbatim}
R4EnvChem-ProjectTemplate
│   R4EnvChem-ProjectTemplate.Rproj
│   Rscript-example.R
|   README.md
|   Rmarkdown-example.rmd
│
└───data
│       2018-01-01_60430_Toronto_ON.csv
│       2018-07-01_60430_Toronto_ON.csv
|       ...
│    
└───images
    │   DHall_TorontoPano.jpg
\end{verbatim}

With the \texttt{R4EnvChem-ProjectTemplate.Rproj} file located in the main folder, this is important as we'll be able to readily look for files we stored in project subfolders such as \texttt{data} and \texttt{images}.

As you can see, the \texttt{R4EnvChem-ProjectTemplate.Rproj} file is located in the main folder, which RStudio will now treat as the working directory. Essentially it means we'll be able to quickly access files in project subfolders such as data and images without having to find out what the full file path is for your own computer. You'll appreciate this as you progress through this book.

In the future you can create your own projects from scratch, but it behooves you to follow the template layout. Having consistently named folders you'll use in every project will help simplify your life down the road.

\hypertarget{creating-an-rstudio-project}{%
\section{Creating an RStudio project}\label{creating-an-rstudio-project}}

We've provided instructions on creating your own RStudio project from scratch, but you can always copy the template project folder above (or any for that matter) to re-purpose it as you see fit.

To create a new project: go to \emph{File}-\textgreater{}\emph{New Project}, or click the button highlighted in the image below. Click \emph{New Directory}, then \emph{New Project}.

\includegraphics{images/Rstudio_newproject.png} You may want your project directory to be a sub-folder of an existing directory on your computer which already contains your data sets. If this is the case, click \emph{Existing Directory} instead of \emph{New Directory} at the previous step, and then select the folder of your choice.

Next, you'll be asked to choose a sub-directory name and location. Enter your selected name and choose an appropriate location for the folder on your computer. Click \emph{Create Project}, and you should now see your chosen file path displayed in the \emph{Files} tab of the Viewer pane:

\includegraphics{images/Rstudio_Rproj.png}

When working on assignments for coursework, it is good practice to create a new R project for each assignment you work on. You should store the data, images, and any other files required for that assignment within the folder for the designated R project. You can create sub-folders for data and images, however, you may want to avoid making too many nested sub-folders, as this will make your paths long and tiresome to type. For a hypothetical course with 5 Labs (\emph{cough} CHM410 \emph{cough}), your coursework would look like this:

\begin{verbatim}
CHM410
|
└─── Project 1
|     |
|     |   project1.Rproj
|     |   project1WriteUp.Rmd
|     └───data
|     │     ...
|     └───images
|           ...
|
└─── Project 2
      |
      |   project2.Rproj
      |   project2WriteUp.Rmd
      └───data
      │     ...
      └───images
            ...
...
\end{verbatim}

With a separate folder for each experiment, and within each folder is an RStudio project, data, images, and other files required for \emph{that} specific project. You shouldn't have nested R studio project as their is no benefit to this approach. Keep everything you need in one location, and no more.

\hypertarget{a-sneak-peek-at-.rmd-files}{%
\section{\texorpdfstring{A sneak peek at \texttt{.Rmd} files}{A sneak peek at .Rmd files}}\label{a-sneak-peek-at-.rmd-files}}

In this textbook, \textbf{you will exclusively work with \texttt{.Rmd} (R Markdown) files}, which offer a dynamic and interactive platform for blending code, text, and output.

Within an \texttt{.Rmd} file, you will encounter two distinct components: \textbf{code and text}.

\begin{itemize}
\tightlist
\item
  \emph{Text fields}, easily accessible by inserting regular text, allow you to compose explanations, context, and interpretations using plain language. These text fields can be created directly within the \texttt{.Rmd} document.
\item
  \emph{Code chunks}, on the other hand, house R code that can be executed to generate results and graphics.
\end{itemize}

We will learn more about working with R markdown in the later chapters.

\hypertarget{summary-1}{%
\section{Summary}\label{summary-1}}

In this chapter we've covered:

\begin{itemize}
\tightlist
\item
  Importing the \emph{R4EnvChem Project Template} so we have access to data for the tutorial (amongst other things)
\item
  The concept of paths and directories and how relative referencing withing a project greatly simplify this
\end{itemize}

\hypertarget{exercise-1}{%
\section{Exercise}\label{exercise-1}}

For this chapter, you will create your own R project in UofT JupyterHub RStudio.

\hypertarget{get-started}{%
\subsection{Get Started:}\label{get-started}}

\begin{itemize}
\tightlist
\item
  Launch RStudio on the UofT JupyterHub server.
\end{itemize}

\hypertarget{confirm-your-working-directory}{%
\subsection{Confirm Your Working Directory}\label{confirm-your-working-directory}}

\begin{itemize}
\tightlist
\item
  Use the \texttt{getwd()} function in RStudio to display the current working directory in the console.
\item
  Ensure that the working directory in RStudio is the location where you'd like to set up your project.
\end{itemize}

\hypertarget{creating-your-own-project}{%
\subsection{Creating Your Own Project:}\label{creating-your-own-project}}

\begin{itemize}
\tightlist
\item
  Launch a new RStudio project. To do this, go to File -\textgreater{} New Project.
\item
  Choose ``New Directory''.
\item
  Select ``New Project''.
\item
  Name the project ``MyFirstRProject'' and choose a convenient location to save it.
\item
  Click on ``Create Project''.
\item
  Use the \texttt{getwd()} function again to check your current working directory and confirm you're in the ``MyFirstRProject'' directory.
\item
  Inside the ``MyFirstRProject'' directory, create two new folders: ``data'' and ``notebook''. You can do this using RStudio's `Files' tab or using the \texttt{dir.create()} function in the R console.
\end{itemize}

\hypertarget{create-your-rmd-file}{%
\subsection{Create Your Rmd File:}\label{create-your-rmd-file}}

\begin{itemize}
\tightlist
\item
  Within your ``MyFirstRProject'' directory, create a new \texttt{.Rmd} (R Markdown) file. You can do this by going to File -\textgreater{} New File -\textgreater{} R Markdown.
\item
  Name the file ``MyFirstRMarkdown'' and set HTML as the default output format.
\item
  In the text section of the \texttt{.Rmd} file, write one thing you remember about R and RStudio.
\item
  Insert a code chunk below what you wrote. In this code chunk, type \texttt{sum(1:10)}, which calculates the sum of numbers from 1 to 10.
\item
  Knit the document to see the results. This will produce an HTML or PDF document that shows both your text and the results of your R code.
\end{itemize}

\hypertarget{upload-a-file-from-your-computer}{%
\subsection{Upload a file from your computer:}\label{upload-a-file-from-your-computer}}

\begin{itemize}
\tightlist
\item
  Start by visiting the \href{https://uoft-chem.shinyapps.io/Air_Quality_App/}{Exploring Air Quality Data} website and navigate to the \texttt{My\ Data} tab.
\item
  Once there, choose your preferred options on the left side. Then, on the right side, input your student number to retrieve your data. After your data displays, click on the \texttt{Download\ Your\ Data!} button to download the data as a CSV file (as shown in Figure 1).
\item
  Next, upload this downloaded data to the ``data'' folder within your RStudio project. If you've forgotten how, just refer back to the beginning of this chapter for a quick reminder.
\item
  After the upload, you'll be able to spot your data in the \texttt{Files} pane of RStudio. Simply click on the data's name and then select \texttt{View\ File} to peek at your raw data.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/shinyapp.png}
\caption{Figure 1}
\end{figure}

\hypertarget{reflection-1}{%
\subsection{Reflection:}\label{reflection-1}}

\begin{itemize}
\tightlist
\item
  Explain the difference between relative and absolute paths. Why are relative paths preferred when working in RStudio projects?
\end{itemize}

\hypertarget{how-to-use-this-textbook}{%
\chapter{How to Use This Textbook}\label{how-to-use-this-textbook}}

Before we move onto the actual coding part, let's talk about how to navigate and utilize this textbook.

\hypertarget{keep-in-mind}{%
\section{Keep in mind}\label{keep-in-mind}}

\textbf{1. Reading and Active Engagement}

This textbook encourages active learning. Don't merely read through the content---interact with it. Type out the code in your R environment and see the results firsthand. This hands-on approach will solidify your comprehension and enhance your practical skills. Observe how the code behaves, experiment with modifications, and observe how changes impact the outcomes.

\textbf{2. Curiosity and Inquisitiveness}

When you encounter code you don't fully understand or want to know the underlying process, lean into your curiosity. Don't hesitate to ask ``Why?'' and explore concepts beyond the immediate scope. Seek to understand the ``why'' and ``how'' alongside the ``what.''

\textbf{3. Resources and Further Explanation}

This textbook is a stepping stone to your R journey. Beyond the content provided, explore the references, suggested readings, and online resources mentioned throughout the chapters. Embrace a curious attitude and continue to expand your knowledge by delving into more advanced topics or specific applications that align with your interests.

\textbf{4. Discussion and Collaboration}

If you're using this textbook as part of a class or a group, engage in discussions with your peers. Sharing insights, clarifying doubts, and collaborating on exercises can enhance your learning experience. Don't hesitate to ask questions, seek help, and contribute to a supportive learning environment.

\hypertarget{useful-features}{%
\section{Useful features}\label{useful-features}}

\hypertarget{searching-throughout-the-textbook}{%
\subsection{Searching throughout the textbook}\label{searching-throughout-the-textbook}}

By clicking on the magnifying glass icon in the top left corner, you have the ability to search for keywords across the entire textbook without worrying about case sensitivity. For instance, entering ``tidyverse'' will display all chapters where tidyverse is mentioned. This gives you a glimpse into future chapters, offering a preview of the various ways you'll be engaging with tidyverse later on!

\hypertarget{how-to-view-the-original-r-markdown-of-textbook-chapters}{%
\subsection{How to view the original R Markdown of textbook chapters}\label{how-to-view-the-original-r-markdown-of-textbook-chapters}}

This textbook is assembled from individual Rmd files, each representing a chapter. As you progress through the chapters, you may wish to examine the associated Rmd files to delve deeper into the code and its execution.

Simply click on the edit icon in the top left corner to be directed to the corresponding Rmd file on GitHub, opened in a new tab. You're encouraged to download these files, experiment with the code, and observe our Rmd formatting techniques!

\includegraphics[width=0.7\textwidth,height=\textheight]{images/view_source.png}

\hypertarget{end-of-chapter-exercises}{%
\section{End-of-chapter Exercises}\label{end-of-chapter-exercises}}

As you progress through each chapter, you'll find \texttt{.Rmd} (R Markdown) files available for practice and reinforcement. These Rmd files are designed to provide you with hands-on exercises that align with the concepts covered in the textbook.

Within each Rmd file, you'll encounter straightforward exercises that give you the opportunity to apply what you've learned in each chapter. After completing an exercise, you can run the provided unittest cell to check your answers and receive instant feedback.

Here is an instruction to how to start on the exercises:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Access the Repository:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Recommended for those who have access to UofT JupyterHub}: Click on the following link to automatically clone the ``R4EnvChem-Exercises'' repository to your UofT JupyterHub:
    \href{https://r.datatools.utoronto.ca/hub/user-redirect/git-pull?repo=https\%3A\%2F\%2Fgithub.com\%2FUofTChem-Teaching\%2FR4EnvChem-Exercises\&urlpath=rstudio\%2F}{R4EnvChem-Exercises Repository}. This is a preferred method for anyone completing exercises as part of a UofT course.
  \item
    Alternatively, you can directly download the files from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
  \end{itemize}
\item
  Work on the Exercise:

  \begin{itemize}
  \tightlist
  \item
    Once inside your JupyterHub's RStudio environment, in the ``Files'' pane you'll see ``R4EnvChem-Exercises'' folder (figure below). If you click into this folder, you will see a list of chapter folders. Each chapter folder contains the respective exercise Rmd files. Navigate to the desired chapter's folder and click on the exercise Rmd file you wish to work on. This will open the file in the RStudio editor.
    \includegraphics{images/gitpuller.png}
  \item
    Once the Rmd file is open, you can edit, run code chunks, and add your solutions directly in the file. Remember to save your progress regularly. If you want to generate an output document (like a PDF or HTML) to view your results, click on the ``Knit'' button usually located at the top of the script editor.
  \item
    To enhance readability, you optionally click on the \texttt{Visual} tab at the top of the file view and work on the exercises.
  \end{itemize}
\end{enumerate}

\textbf{Optional Extra Questions}

For those seeking an additional challenge and a chance to delve into topics beyond the textbook, we offer optional extra questions. Resources and explanations will be provided to support you in tackling these optional questions.

By engaging with these interactive Rmd files, you can actively reinforce your learning, gain practical experience, and explore R concepts in depth. We encourage you to make the most of these resources to enhance your R proficiency. Happy learning!

\hypertarget{part-part-2-how-to-code-in-r}{%
\part*{Part 2: How to Code in R}\label{part-part-2-how-to-code-in-r}}
\addcontentsline{toc}{part}{Part 2: How to Code in R}

\hypertarget{r-coding-basics}{%
\chapter{R Coding Basics}\label{r-coding-basics}}

Now that you know how to navigate RStudio and have a working project, we'll take a look at the basics of R. As we're chemist first, and not computer programmers, we'll try and avoid as much of the nitty-gritty underneath the hood aspects of R. However, a risk of this approach is being unable to understand errors and warnings preventing your code from running. As such, we'll introduce the most important and pertinent aspects of the R language to meet your environmental chemistry needs.

\hypertarget{variables}{%
\section{Variables}\label{variables}}

We've already talked about how R can be used like a calculator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{1000} \SpecialCharTok{*}\NormalTok{ pi) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1570.796
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{2} \SpecialCharTok{*} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{*} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26
\end{verbatim}

But managing these inputs and outputs is simplified with \textbf{variables}. Variables in R, like those you've encountered in math class, can only have one value, and you can reference or pass that value along by referring the variable name. And, unlike the variables in math classes, you can change that value whenever you want. Another way to think about it is that a variable is a box in which you store your value. When you want to move (reference) your value, you move the box (and whatever is inside of it). Then you can simply open the box somewhere else without having to worry about the hassle of what's inside.

You can assign the a value to a variables using \texttt{\textless{}-}, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{12}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12
\end{verbatim}

In addition to reading code top to bottom, you often \emph{read it from right to left}. \texttt{x\ \textless{}-\ 12} would be read as ``take the value \texttt{12} and store it into the variable \texttt{x}''. The second line of code, \texttt{x}, simply returns the value stored inside \texttt{x}. Note that when a variable is typed on it own, R will print out it's contents. You can now use this variable in snippets of code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{*} \FloatTok{6.022e23}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.2264e+24
\end{verbatim}

Remember, R evaluates from right to left, so the code above is taking the number \texttt{6.022e23} and multiplying it by the value of \texttt{x}, which is 12 and storing that value back into \texttt{x}. That's how we're able to modifying the contents of a variable using it's current value. You can also overwrite the contents of a variable at anytime (i.e.~\texttt{x\ \textless{}-\ 25}).

Note that variable names are case sensitive, so if your variable is named \texttt{x} and you type \texttt{X} into the console, R will not be able to print the contents of \texttt{x}. Variable names can consist of letters, numbers, dots (\texttt{.}) and/or underlines (\texttt{\_}). Here are some rules and guidelines for naming variables in R:

\begin{itemize}
\tightlist
\item
  \textbf{Variable Name Requirements} as dictated by R

  \begin{itemize}
  \tightlist
  \item
    names must begin with a letter or with the dot character. \texttt{var} and \texttt{.var} are acceptable.
  \item
    Variable names \emph{cannot} start with a number or the \texttt{.} character cannot be preceded by number. \texttt{var1} is acceptable, \texttt{1var} and \texttt{.1var} are not.
  \item
    Variable names \emph{cannot} contain a space. \texttt{var\ 1} is interpreted as two separate values, \texttt{var} and \texttt{1}.
  \item
    Certain words are reserved for R, and cannot be used as variable names. These include, but are not limited to, \texttt{if}, \texttt{else}, \texttt{while}, \texttt{function}, \texttt{for}, \texttt{in}, \texttt{next}, \texttt{break}, \texttt{TRUE}, \texttt{FALSE}, \texttt{NULL}, \texttt{Inf}, \texttt{NA}, and \texttt{NaN}
  \end{itemize}
\end{itemize}

Good names for variables are short, sweet, and easy to type while also being somewhat descriptive. For example, let's say you have an air pollution data set. A good name to assign the data set to would be \texttt{airPol} or \texttt{air\_pol}, as these names tell us what is contained in the data set and are easy to type. A bad name for the data set would be \texttt{airPollution\_NOx\_O3\_June20\_1968}. While this name is much more descriptive than the previous names, it will take you a long time to type, and will become a bit of a nuisance when you have to type it 10+ times to refer to the data set in a single script. Please refer to the \href{http://adv-r.had.co.nz/Style.html}{\emph{Style Guide}} found in \emph{Advanced R} by H. Wickham for more information.

Lastly, R evaluates code from top-to-bottom of your script. So if you reference a variable it must have already been created at an earlier point in your script. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{12}
\end{Highlighting}
\end{Shaded}

The code above returns the \texttt{object\ \textquotesingle{}y\textquotesingle{}\ not\ found} error because we're adding \texttt{+\ 1} to \texttt{y} which hasn't been created yet, it's created on the next line. These errors also pop up when you edit your code without clearing your workplace. All variables created in a session are stored in the working environment so you can call them, even if you change your code. This means you can accidentally reference a variable that isn't reproduced in the latest iteration of your code. Consequently, a good practice is to frequently clear your work-space suing the `broom' button in the \emph{environment} pane. This will help you to ensure the code you're writing will is organized in the correct order; see {[}Saving R scripts{]} for why this is important.

\hypertarget{data-types}{%
\section{Data types}\label{data-types}}

Data types refer to how data is stored and handled by and in R. This can get complicated quickly, but we'll focus on the most common types here so you can get started on your work. Firstly, here are the data types you'll likely be working with:

\begin{itemize}
\tightlist
\item
  \textbf{character}: \texttt{"a"}, \texttt{"howdy"}, \texttt{"1"}, is used to represent string values in R. Basically it's text that you'd read. Strings are wrapped in quotation marks. For example, \texttt{"1"}, despite being read as number by us, is stored as a character and treated as such by R.
\item
  \textbf{numeric} is any real or decimal number such as \texttt{2}, \texttt{3.14}, \texttt{6.022e23}.
\item
  \textbf{integer} such as \texttt{2L}, note the `L' tells R this is an integer.\\
\item
  \textbf{logical} is a Boolean logic value, they can only be \texttt{TRUE} or \texttt{FALSE}
\end{itemize}

Sometimes R will misinterpret a value as the wrong data type. This can hamper your work as you can't do arithmetic on a string! So let's look at some helpful functions to test the data type of a value in R, and how to fix it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \StringTok{"6"}
\NormalTok{x }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in x/2: non-numeric argument to binary operator
\end{verbatim}

``non-numeric argument to binary operator'' is a commonly encountered error, and it's simply telling you that you're trying to do math on something you can't do math on. You might think if \texttt{x} is 6, why can't I divide it by 2? Let's see what type of data \texttt{x} is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.numeric}\NormalTok{(x)   }\CommentTok{\# test if numeric }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.logical}\NormalTok{(x)   }\CommentTok{\# test if logical}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.integer}\NormalTok{(x)   }\CommentTok{\# test if integer }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.character}\NormalTok{(x) }\CommentTok{\# test if character}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

So the value of \texttt{x} is a character, in other words R treats it as a word, and we can't do math on that (think, how would you divide a word by a number?). So let's convert the data type of \texttt{x} to numeric to proceed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "6"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(x)}
\FunctionTok{is.numeric}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

So we've converted our character string \texttt{"6"} to the numerical value \texttt{6}. Keep in mind there are other conversion functions which are described \href{https://www.geeksforgeeks.org/conversion-functions-in-r-programming/}{elsewhere}, but you can't always convert types. In the above example we could convert a character to numeric because it was ultimately a number, but we couldn't do the same if the value of \texttt{x} was \texttt{"six"}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\StringTok{"six"}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

``NAs introduced by coercion'' means that R didn't know how to convert ``six'' to a numeric value, so it instead turned it into an \emph{NA}, representing a missing value.

\hypertarget{data-structures}{%
\section{Data structures}\label{data-structures}}

Data structures refers to how R stores data. It's easy to get lost in the weeds here, so we'll start with the focus on the most common and useful data structure for your work: \emph{data frames}.

\hypertarget{data-frames}{%
\subsection{Data Frames}\label{data-frames}}

Data frames consist of data stored in rows and columns. If you've ever worked with a spreadsheet (i.e.~\emph{Excel}), it's essentially that with the caveat that \emph{all data stored in a column must be of the same type}. Again, different columns can have different data types, but \emph{within} a column all the data needs to be the same type. R will convert your data otherwise to make it all the same. A common error is a single character in a column of numerical values leading to the entire column to be interpreted as character values; similar to what we discussed above. Errors like this most often stem from mistakes in recording and importing your data so be careful!

\hypertarget{creating-a-new-dataframe-from-scratch}{%
\subsubsection{Creating a new dataframe from scratch}\label{creating-a-new-dataframe-from-scratch}}

Let's see how we can create a dataframe by explicitly listing out the values.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data}
\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{, }\StringTok{"Charlie"}\NormalTok{, }\StringTok{"David"}\NormalTok{, }\StringTok{"Eve"}\NormalTok{)}
\NormalTok{ages }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{19}\NormalTok{)}
\NormalTok{food }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Bubble Tea"}\NormalTok{, }\StringTok{"Pineapple Pizza"}\NormalTok{, }\StringTok{"Diet Pepsi"}\NormalTok{, }\StringTok{"Korean BBQ"}\NormalTok{, }\StringTok{"Sushi AYCE"}\NormalTok{)}

\CommentTok{\# Creating the dataframe}
\NormalTok{students }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Name =}\NormalTok{ names, }\AttributeTok{Age =}\NormalTok{ ages, }\AttributeTok{Food =}\NormalTok{ food)}

\CommentTok{\# Displaying the dataframe}
\FunctionTok{print}\NormalTok{(students)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Name Age            Food
## 1   Alice  20      Bubble Tea
## 2     Bob  21 Pineapple Pizza
## 3 Charlie  22      Diet Pepsi
## 4   David  23      Korean BBQ
## 5     Eve  19      Sushi AYCE
\end{verbatim}

\hypertarget{reading-data-from-a-file}{%
\subsubsection{Reading data from a file}\label{reading-data-from-a-file}}

Obviously when we have many more data, it would be unrealistic to manually list them out in our code. So instead, we can create a dataframe by reading a file.

From the \texttt{R4EnvChem-ProjectTemplate}, downloaded in \protect\hyperlink{importing-a-project}{Importing a project}, let's import some real data as follows by typing the following into the console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{airPol }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/2018{-}01{-}01\_60430\_Toronto\_ON.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{read.csv()} is a useful R built-in function which, as you might guess from its name, can read a \texttt{.csv} file and convert it into a data frame. The data we just imported contains air quality data measured in downtown Toronto around January 2018. The ``Column specification'' summary printed to the console is a useful feature of \texttt{read.csv()}. It tells you what data type was determined for each column when it was imported. Note that \emph{double} is simply another term for the \emph{numeric} data type. Some of the variables are:

\begin{itemize}
\tightlist
\item
  \texttt{naps}, \texttt{city}, \texttt{p}, \texttt{latitude}, \texttt{longitude} to tell you where the data was measured.
\item
  \texttt{data.time} for when the measurements were taking. Note this is a \texttt{datetime}, which is a subset of numeric data. The values contained herein correspond to time elements such as year, month, data, and time.
\item
  \texttt{pollutant} for the chemical measured
\item
  \texttt{concentration} for the measured concentration in parts-per-million (ppm).
\end{itemize}

We've assigned it to the variable: \texttt{airPol}. This is so we can reference it and make use of it later on (see below). If we didn't do this our data would simply be printed to the console which isn't helpful. Let's take a look at the first few rows of the data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(airPol)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    naps    city  p latitude longitude           date.time pollutant
## 1 60430 Toronto ON 43.70944  -79.5435 2018-01-01 00:00:00        O3
## 2 60430 Toronto ON 43.70944  -79.5435 2018-01-01 00:00:00       NO2
## 3 60430 Toronto ON 43.70944  -79.5435 2018-01-01 00:00:00       SO2
## 4 60430 Toronto ON 43.70944  -79.5435 2018-01-01 01:00:00        O3
## 5 60430 Toronto ON 43.70944  -79.5435 2018-01-01 01:00:00       NO2
## 6 60430 Toronto ON 43.70944  -79.5435 2018-01-01 01:00:00       SO2
##   concentration
## 1             3
## 2            39
## 3             1
## 4             1
## 5            47
## 6             3
\end{verbatim}

Here we see that the data is stored in a \textbf{tidy} format, which is to say each column is a variable and each row is an observation. So reading the first row, we know that the Toronto 60430 station on 2018-07-01 at midnight measured ambient O\textsubscript{3} concentrations of 46 ppm (Note the concentration column isn't printed due to width). The concept of tidy data is important and is integral to working in R. It's discussed further in \protect\hyperlink{tidying-your-data}{Tidying Your Data}. Lastly, R will only output a small chunk of our data for us to see. If you'd like to see it in full, go the the \texttt{Environment} pane and double click on the \texttt{airPol} data.

\hypertarget{accessing-data-in-subfolders}{%
\subsection{Accessing data in subfolders}\label{accessing-data-in-subfolders}}

Note that \texttt{read.csv()} requires us to specify the file name, but in the above example we prefixed our file name with \texttt{"data/2018..."}. This is because the \texttt{.csv} file we want to open is stored in the \texttt{data} sub-folder. By specifying this in the prefix, we tell \texttt{read.csv()} to first go to the \texttt{data} sub folder in the working directory and \emph{then} search for and open the specified data file.

What we've done above is called \emph{relative referencing} and it's a huge benefit of projects. The actual data file is stored somewhere on your computer in a folder like \texttt{"C:/User/Your\_name/Documents/School/Undergrad/Second\_Year/R4EnvChemTemplate/data/2018-01-01\_60430\_Toronto\_ON.csv"}. If we weren't in a project, this is what you'd need to type to open your file, but since we're working in the project, R assumes the long part, and begins searching for files inside the project folder. Hence, why we only need \texttt{"data/2018..."}. Not only is this much simpler to type, and but it makes sharing your work with colleagues, TAs, and Profs (and yourself!) much easier. In other words, if you wanted to share your code, you would send the entire project folder (code \& data) and the receiver could open it and run it as is.

\hypertarget{other-data-structures}{%
\subsection{Other data structures}\label{other-data-structures}}

R has several other data structures. They aren't as frequently used, but it's worth being aware of their existence. Other structures include:

\begin{itemize}
\tightlist
\item
  \textbf{Vectors}, which contain multiple elements \emph{of the same type}; either numeric, character (text), logical, or integer. Vectors are created using \texttt{c()}, which is short for combine. A data frame is just multiple vectors arranged into columns. Some examples of vectors are shown below.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{num}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{char }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"red"}\NormalTok{)}
\NormalTok{char}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "blue"  "green" "red"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{log}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{Lists} are similar to vectors in that they are one dimensional data structures which contain multiple elements. However, lists can contain multiple elements of different types, while vectors only contain a single type of data. You can create lists using \texttt{list()}. Some examples of lists are shown below. You can use \texttt{str()} to reveal the different components of a list, in a more detailed format than if you were to simply type the assigned name of the list.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hi }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"Greetings"} \OtherTok{=} \StringTok{"Hello"}\NormalTok{, }\StringTok{"someNumbers"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{20}\NormalTok{), }\StringTok{"someBooleans"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{))}
\FunctionTok{str}\NormalTok{(hi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 3
##  $ Greetings   : chr "Hello"
##  $ someNumbers : num [1:4] 5 10 15 20
##  $ someBooleans: logi [1:3] TRUE TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hi}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $Greetings
## [1] "Hello"
## 
## $someNumbers
## [1]  5 10 15 20
## 
## $someBooleans
## [1]  TRUE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hi}\SpecialCharTok{$}\NormalTok{Greetings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello"
\end{verbatim}

There are many freely available resources online which dive more in depth into different data structures in R. If you are interested in learning more about different structures, you can check out the \href{http://adv-r.had.co.nz/Data-structures.html}{\emph{Data structure}} chapter of \emph{Advanced R} by Hadley Wickham.

\hypertarget{conditional-statements}{%
\section{Conditional Statements}\label{conditional-statements}}

In programming, it's often necessary to make decisions and execute certain portions of code based on specific conditions. That's where conditional statements come into play.

In R, the primary mechanism to make decisions is the \texttt{if-else} construct. With it, you can evaluate a condition and, based on whether it's true or false, choose which code block to execute.

\hypertarget{understanding-r-syntax}{%
\subsection{Understanding R Syntax}\label{understanding-r-syntax}}

Before diving into conditional statements, let's take a moment to understand the syntax used in R.

R, like many programming languages, uses a combination of parentheses \texttt{()}, curly braces \texttt{\{\}}, and other symbols to organize and structure the code.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Parentheses \texttt{()}: These are primarily used to enclose arguments of functions and conditions in control statements, like if. For example, in \texttt{if\ (x\ \textgreater{}\ 5)}, the condition \texttt{x\ \textgreater{}\ 5} is enclosed in parentheses.
\item
  Curly Braces \texttt{\{\}}: These are used to group multiple lines of code into a block. This is particularly useful in control statements where more than one line of code should be executed based on a condition.
\end{enumerate}

The reason the curly bracket might span multiple lines is for readability. It makes it clear where a block of code begins and ends. While it's possible to write if-else statements without braces if only one statement is being conditioned, it's a good practice to always use them for clarity.

Now, with this understanding, let's move on to how R uses these in conditional statements.

\hypertarget{the-basic-if-statement}{%
\subsection{\texorpdfstring{The basic \texttt{if} statement}{The basic if statement}}\label{the-basic-if-statement}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{10}

\CommentTok{\# In this example, R checks if x is greater than 5. }
\ControlFlowTok{if}\NormalTok{ (x }\SpecialCharTok{\textgreater{}} \DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is greater than 5!"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "x is greater than 5!"
\end{verbatim}

\hypertarget{expanding-with-else-and-else-if}{%
\subsection{\texorpdfstring{Expanding with \texttt{else} and \texttt{else\ if}}{Expanding with else and else if}}\label{expanding-with-else-and-else-if}}

For situations where you want to specify actions for both true and false conditions, you can add an \texttt{else} section.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{3}

\ControlFlowTok{if}\NormalTok{ (x }\SpecialCharTok{\textgreater{}} \DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is greater than 5!"}\NormalTok{)}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{ }\CommentTok{\# if x \textless{}= 5}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is 5 or less!"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "x is 5 or less!"
\end{verbatim}

Here, because \texttt{x} is 3 (which is not greater than 5), R prints ``x is 5 or less!''.

For situations where multiple conditions need to be evaluated in sequence, you can use the else if construct. This allows you to add more conditions after the initial if.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{6}

\ControlFlowTok{if}\NormalTok{ (x }\SpecialCharTok{\textgreater{}} \DecValTok{10}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is greater than 10!"}\NormalTok{)}
\NormalTok{\} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (x }\SpecialCharTok{\textgreater{}} \DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is greater than 5 but less than or equal to 10!"}\NormalTok{)}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
  \FunctionTok{print}\NormalTok{(}\StringTok{"x is 5 or less!"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "x is greater than 5 but less than or equal to 10!"
\end{verbatim}

In terms of syntax, it's important to remember:

\begin{itemize}
\tightlist
\item
  Always enclose the condition you're testing within parentheses \texttt{()}.\\
\item
  Use curly braces \texttt{\{\}} to group the lines of code that should be executed for a particular condition.\\
\item
  Make sure each else if or else follows an if or another else if. They cannot stand alone.
\end{itemize}

\hypertarget{r-built-in-functions}{%
\section{R built-in functions}\label{r-built-in-functions}}

Built-in functions are the essential tools that allow you to perform a wide range of tasks without having to write the underlying code from scratch. These functions are part of the R language itself and are readily available for your use.

In this chapter, you've already come across a few built-in functions that are incredibly useful. For instance, you've used the \texttt{read.csv()} function to import data from CSV files into your R environment. Additionally, the \texttt{as.numeric()} function has been employed to convert data to numeric format, and the \texttt{list()} function has aided in creating lists to organize and store data elements.

\hypertarget{exploring-more-built-in-functions}{%
\subsection{Exploring More Built-In Functions}\label{exploring-more-built-in-functions}}

Let's delve into a few more built-in functions that are integral to your R experience:

\textbf{print()}: The \texttt{print()} function displays output on the console. When you want to see the result of an expression or the contents of a variable, \texttt{print()} makes it effortless.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{"Hello, R!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello, R!"
\end{verbatim}

\textbf{mean()}: The \texttt{mean()} function calculates the average of a numeric vector.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12.5
\end{verbatim}

\textbf{max()/min()}: With the \texttt{max()} function, you can effortlessly determine the maximum value within a numeric vector. Similarly, \texttt{min()} function returns the minimum value within a vector.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{min}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\hypertarget{function-documentation}{%
\subsection{Function documentation}\label{function-documentation}}

An often unappreciated aspect of packages is that they not only contain functions we can use, but documentation. Documentation provides a description of the function (what it does), what arguments it takes, details, and working examples. Often the easiest way to learn how to use a function is to take a working example and change it bit by bit to see how it works etc. To see documentation check the ``help'' tab in the ``outputs'' window or type a question mark in front of a functions name:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Takes you to the help document for the read.csv function}
\NormalTok{?read.csv}
\end{Highlighting}
\end{Shaded}

You can also write you're own functions. Please see {[}Programming with R{]} for additional details.

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

In this chapter we've covered:

\begin{itemize}
\tightlist
\item
  The basics of coding in R including variables, data types, and data structures (notably \texttt{data.frames}).
\item
  Importing data from your project folder into R
\item
  Using if-else structure to build a conditional logic
\item
  Using R built-in functions and opening function documentations
\end{itemize}

Now that you're familiar with navigating RStudio and some basic R coding, you may have realized that working the console can get real messy, real quick. Read on to \protect\hyperlink{workflows-for-r-coding}{Workflows for R Coding} where we'll discuss R workflows to make everyone's lives easier.

\hypertarget{exercise-2}{%
\section{Exercise}\label{exercise-2}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{workflows-for-r-coding}{%
\chapter{Workflows for R Coding}\label{workflows-for-r-coding}}

In the previous chapter, we conducted our coding in the console, which quickly became unwieldy. To address this, we transition to using R Markdown \texttt{.Rmd} files, which we briefly talked about before. Instead of running code interactively in the console, we write code blocks within the .rmd files, creating a comprehensive document that others can follow.

\hypertarget{creating-or-opening-an-r-markdown-document}{%
\section{Creating or opening an R Markdown document}\label{creating-or-opening-an-r-markdown-document}}

To start an R Markdown document:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to \emph{File} -\textgreater{} \emph{New File} -\textgreater{} \emph{R Markdown}
\item
  Then save your document by going to \emph{File} -\textgreater{} \emph{Save As\ldots{}}.
  a. Make sure to save your file with the \texttt{.Rmd} suffix.
  b. \textbf{Save your script in your project folder}, otherwise you'll run into issues.
\end{enumerate}

We've also provided an example script in the R4EnvChem project template. Assuming you're currently in the template project you can open the script as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to \texttt{File} -\textgreater{} \texttt{Open\ File} -\textgreater{} open the \texttt{Rscript-example.Rmd} file. This action will open a new pane above the console, dedicated to writing your R Markdown content.
\end{enumerate}

\hypertarget{workspace-and-whats-real}{%
\section{Workspace and what's real}\label{workspace-and-whats-real}}

We've already mentioned the \emph{environment} pane that displays objects present in your R session. While they are useful to work with, they're not considered \emph{real}. That is to say, if you close your R session, those objects will be lost. And while RStudio allows you to save a working environment (and it's associated objects), it's crucial to understand that \emph{only your saved scripts/markdown documents are real}. You can't readily share your working environment, and even so it's bad practice as you may reference a previous iteration of an object giving you erroneous results. Think back to the chemistry labs: you may jot notes down on loose leaf, but only what's written in your lab book is considered real\ldots{} we'll that's how it's supposed to work anyways.

The idea is everything you need can be generated from the original data and the instructions in your R script/markdown document. Anyone should be able to take your data and your code and get the same results you got. This is paramount for the reproducibility of your work and your results.

\hypertarget{saving-r-markdown}{%
\section{Saving R Markdown}\label{saving-r-markdown}}

To save an R Markdown document:

\begin{itemize}
\tightlist
\item
  Navigate to \emph{File -\textgreater{} Save} or use the `Save' icon in the top left corner of your document.
\end{itemize}

Content saved to an .Rmd file is considered real and self-contained. Variables, plots, or datasets that appear in your workspace or the \texttt{Environment} window aren't self-contained. Whenever you close RStudio, any objects in R that are not considered \emph{real} will be lost in that R session. Furthermore when you need to share your code (for school or publication) you'll need to share your data and your script, but never your work-space. This is to increase predictability and helps people (and you) to make sure your work is reproducible, an under appreciate hallmark of science.

\hypertarget{what-should-i-save}{%
\subsection{What should I save?}\label{what-should-i-save}}

At this point in the chapter, two things should be clear:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  R Markdown documents saved to \texttt{.Rmd} files are the real record of your work.
\item
  Objects in your work-space/environment are not real, and will not be available to you after you close and re-open RStudio unless you re-run the code used to generate the work-space.
\end{enumerate}

So what is important to save in R, and how often should you save these files?

\begin{itemize}
\tightlist
\item
  Save the R Markdown scripts you write, and do so regularly. Even minor changes are worth saving before closing RStudio, as it's easy to forget those small differences upon return.
\item
  Ensuring that even if you lose an object in your workspace, your R Markdown script contains the code needed to recreate that object.
\item
  Generate the object before referencing it in subsequent commands. This ensures that variables are generated in the workspace before being referenced by later commands when running scripts from top to bottom.
\end{itemize}

By adhering to these practices, you ensure your R Markdown documents remain accurate, your code is complete, and your work remains reproducible.

\hypertarget{saving-objects}{%
\subsection{Saving objects}\label{saving-objects}}

In some cases, your code may be used to generate large datasets which require quite a bit of time to create. It can be quite tedious to re-run the code used to generate these large data sets every time you open RStudio, and you might find yourself wanting to save the data to a \emph{real} file that you can simply import the next time you open the application. Also, you may be finished with your analysis and want to save the final data. You can save your the data contained in your data frame as a \texttt{.csv} file using \texttt{write.csv()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# dummy data frame to save}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}
                 \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\StringTok{"yes"}\NormalTok{, }\StringTok{"no"}\NormalTok{, }\StringTok{"maybe"}\NormalTok{))}

\FunctionTok{write.csv}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df, }
          \AttributeTok{file =} \StringTok{"testData.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Breaking it down:

\begin{itemize}
\tightlist
\item
  we created a dummy data frame \texttt{df}; in reality you'll already use a data frame from your analysis.
\item
  we called \texttt{write.csv()} and

  \begin{itemize}
  \tightlist
  \item
    \texttt{x\ =\ df} specifies we want to save the data.frame \texttt{df}
  \item
    \texttt{file\ =\ "data/testData.csv"} specifies \emph{where} we want the file to save (in the \emph{data} sub-directory, more later), and \emph{what} our file will be called (\emph{testData.csv}). It's important to specify the file extension so R knows how to save it.
  \end{itemize}
\end{itemize}

\hypertarget{script-formatting}{%
\section{Script formatting}\label{script-formatting}}

You should now be familiar with how to open the Scripts window, as well as some of the advantages of typing your code into this window rather than into the console directly. Before you write your first script, let's review some basic script formatting.

Before you enter any code into your script, it is good practice to fill the first few lines with text comments which indicate the script's title, author, and creation or last edit date. You can create a comment in a script by typing \texttt{\#} before any text. An example is given below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Title: Ozone time series script}
\CommentTok{\#Author: Georgia Green}
\CommentTok{\#Date: January 8, 2072}
\end{Highlighting}
\end{Shaded}

Below your script header, you should include any packages that need to be loaded for the script to run. Including the necessary packages at the top of the script allows you, and anyone you share your code with, to easily see what packages they need to install. This also means that if you decide to run an entire script at once, the necessary packages will always be loaded before any subsequent code that requires those packages to work.

The first few lines of your scripts should look something like the following.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Title: Example R Script for Visualizing Air Quality Data }
\CommentTok{\# Author: John Guy Rubberboots}
\CommentTok{\# Date: 24 June 2021}

\CommentTok{\# 1. Packages {-}{-}{-}{-} }

\CommentTok{\# Install tidyverse if you haven\textquotesingle{}t already }
\CommentTok{\#install.packages("tidyverse")}

\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

The rest of your script should be dedicated to executable code. It is good practice to include text comments throughout the script, and in between different chunks of code to remind yourself what the different sections of code are for (i.e., \texttt{\#\ 1.\ Packages\ -\/-\/-\/-} in the above example). This also makes it easy for anyone you share your code with to understand what you're trying to do with different sections within the script.

You can also use headers and sub-headers in your scripts using \texttt{\#}, \texttt{\#\#}, and \texttt{\#\#\#} before your text and \texttt{-\/-\/-} after as shown below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Section {-}{-}{-}{-}}
\DocumentationTok{\#\# Subsection {-}{-}{-}{-}}
\DocumentationTok{\#\#\# Sub{-}subsection {-}{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

Headings and subheadings are picked up by RStudio and displayed in the Document Outline box. You can open the Document Outline box by clicking the button highlighted in the image below. Use of these headings allows easy navigation of long scripts, as you can navigate between sections using the Document Outline box.

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_documentoutline2.png}
\caption{Example script headings, document outlines, and comments. Note the ``---'' which tells RStudio this comment is to be treated as a script heading.}
\end{figure}

\hypertarget{viewing-data-and-code-simultaneously}{%
\section{Viewing data and code simultaneously}\label{viewing-data-and-code-simultaneously}}

Before we get into more about coding and workflows, you may find yourself wanting to be able to to view your scripts and data side-by-side. You can open a script, plot, or data set in a new window by clicking and dragging the tab in RStudio or by clicking the button highlighted in the image below.

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/Rstudio_newwindow.png}
\caption{How to open an R script/plot/data set in a new window.}
\end{figure}

\hypertarget{troubleshooting-error-messages}{%
\section{Troubleshooting error messages}\label{troubleshooting-error-messages}}

In the previous section, you were introduced to your first error message in R, and we briefly discussed how to resolve the issue. As you begin to code, many of your errors will be routine syntax error such as unmatched parenthesis (the dreaded ``Incomplete expression:''). Fortunately, RStudio will highlight any syntax errors in your code with a red squiggly line and an `x' in the side bar, as shown below. You can hover over the `x' to see what is causing the error.

\begin{figure}
\centering
\includegraphics{images/Rstudio_diagnostics.png}
\caption{Figure 3.8: RStudio highlights syntax errors in the Scripts window.}
\end{figure}

In the above message, R is telling you that it is not sure what to do with \texttt{b}. As mentioned previously, variable assignment is done in the format \texttt{name\ \textless{}-\ assignment}. However, in the above example, the variable assignment statement is written as \texttt{name\ name\ \textless{}-\ assignment}. Since variable names cannot contain spaces, R reads \texttt{a\ b} as two separate input variable names, not as a single string. If you wanted to assign a value of 0 to both \texttt{a} and \texttt{b}, you would need to write the statement once per variable, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{b }\OtherTok{\textless{}{-}} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

Let's look at another example. Some functions require you to write code with nested parentheses. A good example would be the \texttt{aes()} argument that is called inside of \texttt{ggplot()}, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#plot ozone concentration vs. time}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ airPol, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date.time,}
           \AttributeTok{y =}\NormalTok{ concentration,}
           \AttributeTok{colour =}\NormalTok{ pollutant)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

(For more detail about importing and using \texttt{ggplot2}, please re-visit Chapter 2, section 2.3.4, or see Chapter 11.)

If you were to forget one of the parentheses in the previous line of code, RStudio would highlight it similar to below:

\begin{figure}
\centering
\includegraphics{images/Rstudio_unmatched.png}
\caption{Figure 3.9: RStudio highlights unmatched parentheses in the script window.}
\end{figure}

Here R is telling you that you have an unmatched opening bracket. To resolve the error, simply add a closing bracket to match.

The \texttt{expected\ \textquotesingle{},\textquotesingle{}\ after\ expression} is a common error that you will see accompanying unmatched opening brackets. Sometimes you might get this error in the console after running code that is missing a bracket somewhere. It is good practice to check your parentheses a few times before running your code to make sure that all the commands are closed, and that R doesn't keep waiting for you to continue inputting code after you've click \emph{Run}. If you notice that the \texttt{\textgreater{}} in your R console has turned into a \texttt{+}, this is likely because you've just run a command that is missing a closing bracket, and thus, R is not aware that your code is finished. Simply input a closing bracket into the console, and the \texttt{\textgreater{}} should return.

While the script window is very useful for pointing out syntax errors in your code, there are many other errors that can arise in RStudio which the script window is not able to capture. These are generally errors that arise from trying to execute your code, rather than from mistakes in your syntax.

The following is a prime example of such an error.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q }\OtherTok{\textless{}{-}} \DecValTok{8} \SpecialCharTok{+} \StringTok{"hi"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in 8 + "hi": non-numeric argument to binary operator
\end{verbatim}

Here we are trying to add a numeric value (8) to a character string (``hi''), then set the sum of the two to variable \texttt{q}. R has given us an error in return, because there is no logical way for R to add a numeric value to non-numeric text. The error indicates that we have passed a \texttt{non-numeric\ argument\ to\ binary\ operator}, meaning we have used a non-numeric data type for an expression which is exclusively reserved for numeric data.

It is important to be aware of error codes as many functions require specific data types as their inputs. You can alwways consult the function documentation by via the \emph{Help} tab of the \emph{Viewer} pane or by typing a \texttt{?} followed by the name of the function in the console (i.e.~\texttt{?ggplot}).

\hypertarget{summary-3}{%
\section{Summary}\label{summary-3}}

In this chapter we've covered:

\begin{itemize}
\tightlist
\item
  R workflows in the context of projects and markdown documents
\item
  What's considered \emph{real} when working in RStudio
\item
  How to format your markdown for legibility (Remember you're the one who's going to be stuck rereading it!)
\item
  Troubleshooting some common error messages
\end{itemize}

Now that you're familiar the above, we'll introduce \protect\hyperlink{using-r-markdown}{Using R Markdown}, a way to combine your R code, it's outputs, and your writing all in one dynamic document (like your lab reports!).

\hypertarget{exercise-3}{%
\section{Exercise}\label{exercise-3}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{using-r-markdown}{%
\chapter{Using R Markdown}\label{using-r-markdown}}

Before going into more details of R Markdown, let's talk about two common options in the world of R coding: the R script (.R) and the dynamic R Markdown document (.Rmd).

\textbf{R Scripts}: Imagine coding as crafting a detailed recipe of R commands---a script---that guides R through specific tasks. Conventional R scripts (.R files) are dedicated to these commands, handling calculations and operations. However, as scripts grow, they become complex and sharing insights alongside code becomes challenging.

\textbf{R Markdown}: R Markdown (.Rmd) elevates the coding experience by harmonizing code with explanatory text. Within an R Markdown document, code blocks act like individual scripts---smaller, more focused units. These blocks merge code with explanations seamlessly, creating a coherent narrative. Unlike isolated scripts, R Markdown emphasizes both code functionality and its significance within the context. For these reasons, we'll be sticking to working in \texttt{.Rmd} files.

In a nutshell, R Markdown allows you to analyse your data with R and write your report in the same place (this entire book was written with R Markdown). This has loads of benefits including a \href{https://www.youtube.com/watch?v=s3JldKoA0zw}{\emph{reproducible workflow}}, and streamlined thinking. No more flipping back and forth between coding and writing to figure out what's going on.

Let's run some simple code as an example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{+}\DecValTok{2}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

What we've done here is write a snippet of R code, ran it, and printed the results (as they would appear in the console). While the above code isn't anything special, we can extend this concept so that our R markdown document contains any data, figures or plots we generate throughout our analysis in R. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse) }
\FunctionTok{library}\NormalTok{(knitr)}

\NormalTok{airPol }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/2018{-}01{-}01\_60430\_Toronto\_ON.csv"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ airPol, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date.time, }
           \AttributeTok{y =}\NormalTok{ concentration, }
           \AttributeTok{colour =}\NormalTok{ pollutant)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-37-1.pdf}
\caption{\label{fig:unnamed-chunk-37}Time series of 2018 ambient atmospheric O\textsubscript{3}, NO\textsubscript{2}, and SO\textsubscript{2} concentrations (ppb) in downtown Toronto}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumAirPol }\OtherTok{\textless{}{-}}\NormalTok{ airPol }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{drop\_na}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(city, naps, pollutant) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(concentration), }
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(concentration), }
            \AttributeTok{min =} \FunctionTok{min}\NormalTok{(concentration), }
            \AttributeTok{max =} \FunctionTok{max}\NormalTok{(concentration))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(sumAirPol, }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|r|r|r}
\hline
city & naps & pollutant & mean & sd & min & max\\
\hline
Toronto & 60430 & NO2 & 20.5 & 11.5 & 7 & 55\\
\hline
Toronto & 60430 & O3 & 19.7 & 8.7 & 1 & 33\\
\hline
Toronto & 60430 & SO2 & 1.1 & 0.3 & 1 & 3\\
\hline
\end{tabular}

Pretty neat, eh? You might not think so, but let's imagine a scenario you'll encounter soon enough. You're about to submit your assignment, you've spent hours analyzing your data and beautifying your plots. Everything is good to go until you notice at the last minute you were supposed to \emph{subtract} value \texttt{x} and not value \texttt{y} in your analysis. If you did all your work in \emph{Excel} (tsk tsk), you'll need to find the correct worksheet, apply the changes, reformat your plots, and import them into word (assuming everything is going well, which is never does with looming deadlines). Now if you did all your work in R markdown, you go to your one \texttt{.rmd} document, briefly apply the changes and re-compile your document.

A lot of scientists work with R Markdown for writing their reports for numerous reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Integrated Workflow}: Combines narrative, data analyses, and visualizations in one document, promoting reproducibility and transparency.
\item
  \textbf{Versatility}: Easily exports to diverse formats like HTML, PDF, and Word, catering to different dissemination needs.
\item
  \textbf{Plot Management}: Offers precise control over visual presentations, allowing for tailored figure sizes, resolutions, and formats.
\end{enumerate}

In sum, R Markdown provides a streamlined platform for scientific communication, merging data analysis with polished publication seamlessly.

\hypertarget{getting-started-with-r-markdown}{%
\section{Getting started with R Markdown}\label{getting-started-with-r-markdown}}

As you've already guessed, R markdown documents use R and are most easily written and assembled in RStudio. If you have not done so, revisit Chapter 1:{[}Installing R{]}. Once setup with R and R Studio, you'll need to install the \texttt{R\ Markdown} and \texttt{tinytex} packages by running the following code in the console:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# These are large packages so it\textquotesingle{}ll take a couple of minutes to install}

\FunctionTok{install.packages}\NormalTok{(}\StringTok{"R Markdown"}\NormalTok{) }\CommentTok{\# downloaded from CRAN}

\FunctionTok{install.packages}\NormalTok{(}\StringTok{"tinytex"}\NormalTok{)}
\NormalTok{tinytex}\SpecialCharTok{::}\FunctionTok{install\_tinytex}\NormalTok{()  }\CommentTok{\# install TinyTeX}
\end{Highlighting}
\end{Shaded}

The \texttt{R\ Markdown} package is what we'll use to generate our documents, and the \texttt{tinytex} package enables compiling documents as PDFs. There's a lot more going on behind the \href{https://R\%20Markdown.rstudio.com/lesson-2.html}{scenes}, but you shouldn't need to worry about it.

Now that everything is setup, you can create your first R Markdown document by opening up R Studio, selecting \texttt{FILE\ -\textgreater{}\ NEW\ FILE\ -\textgreater{}\ R\ Markdown}. A dialog box will appear asking for some basic input parameters for your R markdown document. Add your title and select \emph{PDF} as your default output format (you can always change these later if you want). A new file should appear that's already populated with some basic script illustrating the key components of an R markdown document.

\hypertarget{understanding-r-markdown}{%
\subsection{Understanding R Markdown}\label{understanding-r-markdown}}

Your first reaction when you opened your newly created R markdown document is probably that it doesn't look anything at all like something you'd show your prof. You're right, what you're seeing is the plain text code which needs to be compiled (called \emph{knit} in R Studio) to create the final document. When you create a R markdown document like this in R Studio a bunch of example code is already written. You can compile this document (see below) to see what it looks like, but let's break down the primary components. At the top of the document you'll see something that looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}{-}{-}}
\NormalTok{title}\SpecialCharTok{:} \StringTok{"Temporal Analysis of Foot Impacts While Birling Down the White Water"}
\NormalTok{author}\SpecialCharTok{:} \StringTok{"Jean Guy Rubberboots"}
\NormalTok{date}\SpecialCharTok{:} \StringTok{"24/06/2021"}
\NormalTok{output}\SpecialCharTok{:}\NormalTok{ pdf\_document}
\SpecialCharTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

This section is known as the \emph{preamble} and it's where you specify most of the document parameters. In the example we can see that the document title is \href{https://www.youtube.com/watch?v=upsZZ2s3xv8}{``Temporal Analysis of Foot Impacts While Birling Down the White Water''}, it's written by Jean Guy Rubberboots, on the 24th of June, and the default output is a PDF document. You can modify the preamble to suit your needs. For example, if you wanted to change the title you would write \texttt{title:\ "Your\ Title\ Here"} in the preamble. Note that none of this is \texttt{R} code, rather it's \texttt{YAML}, the syntax for the document's metadata. Apart from what's shown you shouldn't need to worry about this much, just remember that indentation in \href{https://bookdown.org/yihui/R\%20Markdown/pdf-document.html}{YAML matters}.

\hypertarget{output-options-in-r-markdown}{%
\subsubsection{Output Options in R Markdown}\label{output-options-in-r-markdown}}

You can compile your entire document using the \emph{Knit document} button. This is a great way to tinker with your code before you compile your document. Knitting will sequentially run all of your code chunks, generate all the text, knit the two together and output a PDF. You'll basically save this for the end.

R Markdown offers flexibility in terms of output formats, allowing users to knit their documents into various outputs tailored to their needs.

\textbf{Three Common Output Options:}

\begin{itemize}
\item
  \textbf{HTML} (html\_document): Produces an HTML file, suitable for hosting on websites or for sharing via email. This format allows for interactive content, making it ideal for interactive graphs or web applications.
\item
  \textbf{PDF} (pdf\_document): Creates a PDF file. This format is best for documents intended for print or formal submissions, as it maintains consistent formatting across different devices and platforms.
\item
  \textbf{Word} (word\_document): Generates a Microsoft Word document, which can be useful when sharing drafts or collaborating with colleagues who use Word for edits.
\end{itemize}

\textbf{Controlling the Output:}

\begin{itemize}
\item
  \textbf{Modifying the YAML Header}: You can change the output format directly in the YAML header of your Rmd file. In the last example, replacing \texttt{output:\ pdf\_document} with \texttt{output:\ html\_document} or \texttt{output:\ word\_document} would knit the document into HTML or Word, respectively.
\item
  \textbf{Using RStudio's Knit Button}: In the RStudio IDE, at the top of the script editor pane, there's a Knit button. Clicking the small dropdown arrow next to this button allows you to choose the output format you desire. Selecting one of the options will knit the document into that format and update the YAML header accordingly.

  \includegraphics[width=0.7\textwidth,height=\textheight]{images/knit_options.PNG}
\end{itemize}

\hypertarget{running-code-in-r-markdown}{%
\subsection{Running code in R Markdown}\label{running-code-in-r-markdown}}

\hypertarget{how-to-create-code-chunks}{%
\subsubsection{How to create code chunks}\label{how-to-create-code-chunks}}

To create a code chunk within RStudio, you have several options:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the green ``c'' button located at the top right corner of your file view and select ``R''. Make sure your cursor is positioned at the desired location within your .rmd file when you do this.
\end{enumerate}

\includegraphics{images/rmd_codeblock_1.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Type \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}} -- three back-ticks followed by \texttt{\{r\}} -- to initiate a new code chunk, and type \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}} -- three backticks (```) -- to end the code chunk. You can specify code chunks options in the curly braces. i.e.~\texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r,\ fig.height\ =\ 2\}} sets figure height to 2 inches. See the \emph{Code Chunk Options} section below for more details.
\end{enumerate}

\includegraphics{images/rmd_codeblock_2.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Inline code expression, which starts with \texttt{\textasciigrave{}r} and ends with \texttt{\textasciigrave{}} in the body text. Earlier we calculated \texttt{x\ \textless{}-\ 2\ +\ 2}, we can use inline expressions to recall that value.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/inline_code.png}
\caption{When we knit the markdown file shown in the figure, the knitted document will say ``We found that \emph{x} is 4.''}
\end{figure}

\hypertarget{how-to-run-code-chunks}{%
\subsubsection{How to run code chunks}\label{how-to-run-code-chunks}}

To run code within an R Markdown document, you again have various options to choose from.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  You can run a specific code chunk by clicking the green triangle button located within each chunk. This action will execute the entire chunk, including all the code it contains.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/run_code_1.png}
\caption{Run a code chunk using its own run button.}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  For more control, you can run selected lines or chunks. To do this, use the ``Run'' button at the top of the file view. This button provides a range of execution options that allow you to run code in a manner that suits your needs.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/run_code_2.png}
\caption{Example: Run selected line(s)}
\end{figure}

\begin{figure}
\centering
\includegraphics{images/run_code_3.png}
\caption{Example: Run Current Chunk}
\end{figure}

\textbf{Note all the code chunks in a single markdown document work together like a normal R script.} That is if you assign a value to a variable in the first chunk, you can call this variable in the second chunk; the same applies for libraries. \textbf{Also note that every time you compile a markdown document, it's done in a ``fresh'' R session.} If you're calling a variable that exist in your working environment, but isn't explicitly created in the markdown document you'll get an error.

\hypertarget{headings-and-subheadings}{%
\subsection{Headings and Subheadings}\label{headings-and-subheadings}}

In R Markdown, structuring your document with clear headings and subheadings is simple using the pound (\texttt{\#}) sign. This not only helps in organizing content but also aids in creating a table of contents if required.

\begin{itemize}
\tightlist
\item
  \textbf{Main Headings}: Use a single pound sign (i.e.~\texttt{\#\ Main\ Heading})
\item
  \textbf{Subheadings}: Increase the number of pound signs based on the level of the subheading.

  \begin{itemize}
  \tightlist
  \item
    \texttt{\#\#\ Subheading\ Level\ 1}
  \item
    \texttt{\#\#\#\ Subheading\ Level\ 2}
  \item
    \texttt{\#\#\#\#\ Subheading\ Level\ 3}
  \end{itemize}
\end{itemize}

R Markdown will automatically format these appropriately when the document is knit. For example, a main heading will typically appear larger and bolder than its subheadings, like this:

\includegraphics[width=0.4\textwidth,height=\textheight]{images/heading_example.PNG}

By effectively utilizing headings and subheadings, you can provide clear structure and flow to your document, making it more readable and navigable for your audience.

\hypertarget{latex-basics}{%
\subsection{LaTeX Basics}\label{latex-basics}}

\textbf{LaTeX} (pronounced ``Lay-tech'') is a typesetting system that's popular in academia due to its high-quality output format and the ability to handle complex formatting tasks. It's especially favored for documents that contain mathematical symbols, equations, and other specialized notation.

In R Markdown, LaTeX code can be integrated directly into your document to allow for advanced formatting, especially formathematical expressions and equations. When you knit your R Markdown document, the LaTeX code is rendered into beautifully formatted text.

There are two common ways to turn your expressions in a math mode.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Display mathematical expressions}: centers the mathematical expression on its own line\\
\item
  \textbf{Inline mathematical expressions}: appears within the flow of a sentence or text
\end{enumerate}

For chemistry students, one common use of LaTeX is to typeset chemical equations. We will provide examples on the combustion of methane:

\includegraphics[width=0.5\textwidth,height=\textheight]{images/methane_example.jpeg}

\hypertarget{display-math-mode}{%
\subsubsection{Display math mode}\label{display-math-mode}}

You can have an entire line in a math mode using either \texttt{\textbackslash{}{[}...\textbackslash{}{]}} or \texttt{\$\$...\$\$}.

When you write it in rmd, it would look like :

\begin{itemize}
\tightlist
\item
  \texttt{\textbackslash{}{[}\ \textbackslash{}text\{CH\}\_4\ +\ 2\textbackslash{}text\{O\}\_2\ \textbackslash{}rightarrow\ \textbackslash{}text\{CO\}\_2\ +\ 2\textbackslash{}text\{H\}\_2\textbackslash{}text\{O\}\ \textbackslash{}{]}} \emph{or} \texttt{\$\$\ \textbackslash{}text\{CH\}\_4\ +\ 2\textbackslash{}text\{O\}\_2\ \textbackslash{}rightarrow\ \textbackslash{}text\{CO\}\_2\ +\ 2\textbackslash{}text\{H\}\_2\textbackslash{}text\{O\}\ \$\$}
\end{itemize}

When you knit it, it will be displayed as:\\
\[ \text{CH}_4 + 2\text{O}_2 \rightarrow \text{CO}_2 + 2\text{H}_2\text{O} \]

\hypertarget{inline-math-mode}{%
\subsubsection{Inline math mode}\label{inline-math-mode}}

On the other hand, if you want to insert your expression within your sentence, you can use \texttt{\$...\$} syntax.

With our methane combustion example, we can write something like this:

\begin{itemize}
\tightlist
\item
  \texttt{Methane\ (\$\textbackslash{}text\{CH\}\_4\$)\ reacts\ with\ oxygen\ (\$\textbackslash{}text\{O\}\_2\$)\ to\ produce\ carbon\ dioxide\ (\$\textbackslash{}text\{CO\}\_2\$)\ and\ water\ (\$\textbackslash{}text\{H\}\_2\textbackslash{}text\{O\}\$).}
\end{itemize}

When you knit it, this will be displayed as:

\begin{itemize}
\tightlist
\item
  Methane (\(\text{CH}_4\)) reacts with oxygen (\(\text{O}_2\)) to produce carbon dioxide (\(\text{CO}_2\)) and water (\(\text{H}_2\text{O}\)).
\end{itemize}

\hypertarget{useful-latex-syntax}{%
\subsubsection{Useful LaTeX Syntax}\label{useful-latex-syntax}}

Now that you've seen how you can write your scientific expression in two different ways, let's look at some useful LaTeX Syntax for our purpose.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Symbols}

  \begin{itemize}
  \tightlist
  \item
    Greek letters: Use a backslash followed by the name of the letter, e.g., \texttt{\textbackslash{}alpha} for \(\alpha\).
  \item
    Special symbols

    \begin{itemize}
    \tightlist
    \item
      \texttt{\textbackslash{}times} for \(\times\)
    \item
      \texttt{\textbackslash{}approx} for \(\approx\)
    \item
      \texttt{\textbackslash{}geq} for \(\geq\)
    \item
      \texttt{\textbackslash{}rightarrow} for \(\rightarrow\)
    \end{itemize}
  \end{itemize}
\item
  \textbf{Superscripts and Subscripts}

  \begin{itemize}
  \tightlist
  \item
    Superscripts: \texttt{x\^{}2} renders as \(x^2\).
  \item
    Subscripts: \texttt{H\_2O} renders as \(H_2O\)
  \end{itemize}
\item
  \textbf{Formatting}

  \begin{itemize}
  \tightlist
  \item
    Boldface: \texttt{\textbackslash{}textbf\{Text\}} for \(\textbf{Text}\)
  \item
    Italics: \texttt{\textbackslash{}textit\{Text\}} for \(\textit{Text}\)
  \end{itemize}
\end{enumerate}

In R Markdown, you can place your cursor over a LaTeX expression to preview its rendered output. This allows you to verify that the LaTeX formatting is correct before knitting the document.

\hypertarget{more-latex-resources}{%
\subsubsection{More LaTeX Resources}\label{more-latex-resources}}

There are numerous online resources dedicated to LaTeX symbols and their usage.

\begin{itemize}
\tightlist
\item
  A popular starting point is the \href{https://ctan.org/pkg/comprehensive}{Comprehensive LaTeX Symbol List}, available on CTAN (Comprehensive TeX Archive Network). This extensive compilation offers a wide range of symbols used in various disciplines.
\item
  Additionally, platforms like \href{http://detexify.kirelabs.org/classify.html}{Detexify} allow users to sketch a symbol, and the tool then identifies the corresponding LaTeX command.
\item
  Engaging with online communities, such as the \href{https://tex.stackexchange.com/}{TeX - LaTeX Stack Exchange}, can also be invaluable for finding specific symbols or seeking advice on LaTeX-related challenges.
\end{itemize}

\hypertarget{compiling-your-final-report}{%
\section{Compiling your final report}\label{compiling-your-final-report}}

To create a PDF to hand in, you'll need to compile, or knit, your entire markdown document as mentioned above. To knit your R markdown script, simply click the \emph{knit} button in R Studio (yellow box, Figure 2). You can specify what output you would like and R Studio will (hopefully) compile your script. Remember, you can test or run individual code chunks as outlined in \protect\hyperlink{running-code-in-r-markdown}{Running code in R Markdown}.

\hypertarget{authoring-with-r-markdown}{%
\section{Authoring with R Markdown}\label{authoring-with-r-markdown}}

Below is a brief summary of the major elements required to author an R Markdown document. They shoudl address the majority of your needs, but please see the \protect\hyperlink{r-markdown-resources}{R Markdown resources} for more information.

\hypertarget{r-markdown-syntax}{%
\subsection{R markdown syntax}\label{r-markdown-syntax}}

Unlike \emph{Microsoft Word}, R Markdown utilizes a specific syntax for text formatting. Once you get used to it, it makes typing documents much easier than \emph{Word}'s approach. The table below is how some of the most common text formatting is typed in your R Markdown document (syntax \& example column) and how it'll appear in the final output.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2603}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Text formatting
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
syntax
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Example output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
italics & *text* & this is *italics* & this is \emph{italics} \\
bold & **text** & this is **bold** & this is \textbf{bold} \\
subscript & \textasciitilde text\textasciitilde{} & this is \textasciitilde subscript\textasciitilde{} & this is \textsubscript{subscript} \\
superscript & \^{}text\^{} & this is \^{}superscript\^{} & this is \textsuperscript{superscript} \\
monospace & `text` & this is `monospaced` & this is \texttt{monospace} \\
\end{longtable}

For a collection of other R Markdown syntax, please see the useful (and brief) list compiled online \href{https://R\%20Markdown.rstudio.com/authoring_basics.html}{here}. This includes ordered and unordered lists, headers, code blocks, hyperlinks, and figure captions.

\hypertarget{r-code-chunk-options}{%
\subsection{R code chunk options}\label{r-code-chunk-options}}

Your R code is run in chunks and the results will be embedded in the final output file. To each chunk you can specify options that'll effect how you're code chunk is run and displayed in the final output document. You include options in the chunk delimiters \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}} and \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}}. For example the following code tells markdown you're running code written in \texttt{R}, that when you compile your document this code chunk should be evaluated, and that the resulting figure should have the caption ``Some Caption''.

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r, eval = FALSE, fig.cap = "Some caption"\}}

\InformationTok{\# some code to generate a plot worth captioning. }

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

The most common and useful chunk options are shown below. Note that they all have a default value. For example, \texttt{eval} tells R markdown whether the code within the block should be run. It's default option is \texttt{TRUE}, so by default any code in a chunk will be run when you knit your document. If you don't want that code to be run, but still displayed, you would set \texttt{eval\ =\ FALSE}. Another example would be setting \texttt{echo\ =\ FALSE} which allows the code to run, but the code \emph{won't} be displayed on the output document (the outputs will still be displayed though); useful for creating clean documents with plots only (i.e.~lab reports\ldots).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
option
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
default
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
effect
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
eval & TRUE & whether to evaluate the code and include the results \\
echo & TRUE & whether to display the code along with its results \\
warning & TRUE & whether to display warnings \\
error & FALSE & whether to display errors \\
message & TRUE & whether to display messages \\
tidy & FALSE & whether to reformat code in a tidy way when displaying it \\
fig.width & 7 & width in inches for plots created in chunk \\
fig.height & 7 & height in inches for plots created in chunk \\
fig.cap & NA & include figure caption, must be in quotation makrs (``\,``) \\
\end{longtable}

\hypertarget{inserting-images}{%
\subsection{Inserting images}\label{inserting-images}}

Images not produced by R code can easily be inserted into your document. The markdown code isn't R code, so between paragraphs of bodytext insert the following code.

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![Caption for the picture.](path/to/image.png)}\NormalTok{\{width=50\%, height=50\%\}}
\end{Highlighting}
\end{Shaded}

Note that in the above the use of image atributes, the \texttt{\{width=50\%,\ height=50\%\}} at the end. This is how you'll adjust the size of your image. Other dimensions you can use include \texttt{px,\ cm,\ mm,\ in,\ inch}, and \texttt{\%}.

A final note on images: when compiling to PDF, the LaTeX call will place your image in the ``optimal'' location (as determined by LaTeX), so you might find your image isn't exactly where you though it would be. A more in-depth guide to image placement can be found \href{https://rpubs.com/RatherBit/90926}{here}

\hypertarget{generating-tables}{%
\subsection{Generating tables}\label{generating-tables}}

There are multiple methods to create tables in R markdown. Assuming you want to display results calculated through R code, you can use the \texttt{kable()} function. Or you can consult the \protect\hyperlink{summarizing-data}{Summarizing Data} chapter for making publication ready tables.

Alternatively, if you want to create simple tables manually use the following code in the main body, outside of an \texttt{R} code chunk. You can increase the number of rows/columns and the location of the horizontal lines. To generate more complex tables, see the \texttt{kable()} function and the \texttt{kableExtra} package.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Header 1 | Header 2| Header 3}
\NormalTok{{-}{-}{-}{-}{-}{-}{-}{-}{-}|{-}{-}{-}{-}{-}{-}{-}{-}{-}|{-}{-}{-}{-}{-}{-}{-}{-}{-}|}
\NormalTok{Row 1    | Data    | Some other Data}
\NormalTok{Row 2    | Data    | Some other Data}
\NormalTok{{-}{-}{-}{-}{-}{-}{-}{-}{-}|{-}{-}{-}{-}{-}{-}{-}{-}{-}|{-}{-}{-}{-}{-}{-}{-}{-}{-}|}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Header 1 & Header 2 & Header 3 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Row 1 & Data & Some other Data \\
Row 2 & Data & Some other Data \\
\end{longtable}

We know this can be a tedious process. Luckily, there is a website that generates the markdown syntax when you input the values, and this can save your time trying to correctly format tables. Check it out \href{https://www.tablesgenerator.com/markdown_tables}{here}.

\hypertarget{spellcheck-in-r-markdown}{%
\subsection{Spellcheck in R Markdown}\label{spellcheck-in-r-markdown}}

While writing an R markdown document in R studio, go to the \texttt{Edit} tab at the top of the window and select \texttt{Check\ Spelling}. You can also use the \texttt{F7} key as a shortcut. The spell checker will literally go through every word it thinks you've misspelled in your document. You can add words to it so your spell checker's utility grows as you use it. \textbf{Note} that the spell check may also check your R code; be wary of changing words in your code chunks because you may get an error down the line.

\hypertarget{exporting-r-markdown-documents}{%
\subsection{Exporting R Markdown documents}\label{exporting-r-markdown-documents}}

You'll most likely be exporting your R Markdown documents as PDFs, but the beauty of R Markdown is it dosen't stop there. Your R Markdown documents can be knitted as a HTML document, a book (or both like this book!). You can even make slideshow presentations and yes, if need be, export as a word document that you can open in \emph{Microsoft Word}.

You specify the output format in the document header. To specify you want your document to be outputted as a PDF your YAML header would look like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Your title here"}
\AnnotationTok{output:}\CommentTok{ pdf\_document}
\CommentTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

Here are some links to different output formation available in R Markdown and how to use them:

\begin{itemize}
\tightlist
\item
  \href{https://bookdown.org/yihui/R\%20Markdown/pdf-document.html}{\texttt{pdf\_document}} creates a PDF document via Latex; probably your defacto output.
\item
  \href{https://bookdown.org/yihui/R\%20Markdown/word-document.html}{\texttt{word\_document}} creates a Word document. Note that the formatting options are pretty basic, so while evereything will be where you want it to be, you'll need to pretty it up in Word to comply with your instructors specifications.
\item
  \href{https://bookdown.org/yihui/R\%20Markdown/tufte-handouts.html}{\texttt{tufte\_handout}} for a PDF handout in the style of Edward Tufte. Check it out.
\item
  \href{https://bookdown.org/yihui/R\%20Markdown/ioslides-presentation.html}{\texttt{ioslides\_presentation}}, \href{https://bookdown.org/yihui/R\%20Markdown/ioslides-presentation.html}{\texttt{revealjs::revealjs\_presentation}}, and \href{https://bookdown.org/yihui/R\%20Markdown/powerpoint-presentation.html}{\texttt{powerpoint\_presentation}} are all options to create sldieshow presentations. I personally use \texttt{revealjs} for my own work. It has the steepest learning curve of the bunch, but once setup, you can make incredibly slick slides with ease.

  \begin{itemize}
  \tightlist
  \item
    Note: like \texttt{word\_document}, \texttt{powerpoint\_presentation}'s outputs are stylistically simple. You'll definitly need to pretty them up manually in Powerpoint.
  \end{itemize}
\end{itemize}

\hypertarget{rstudio-tips-and-tricks}{%
\subsection{RStudio tips and tricks}\label{rstudio-tips-and-tricks}}

To further the usefulness of R Markdown, the latest release of RStudio has a \emph{Visual R Markdown} editor which introduces many useful features for authoring documents in R Markdown. Some of the most pertinent are:

\begin{itemize}
\tightlist
\item
  \href{https://rstudio.github.io/visual-markdown-editing/}{Visual editor} so you can see how your document looks (top left of script pane)
\item
  Combining Zotero and RStudio for easy citatiosn of your document (read more \href{https://rstudio.github.io/visual-markdown-editing/citations.html}{here}
\end{itemize}

\hypertarget{r-markdown-resources}{%
\section{R Markdown resources}\label{r-markdown-resources}}

There's a plethora of helpful online resources to help hone your R markdown skills. We'll list a couple below (the titles are links to the corresponding document):

\begin{itemize}
\tightlist
\item
  \href{https://bookdown.org/yihui/R\%20Markdown/basics.html}{Chapter 2} of the \href{https://bookdown.org/yihui/R\%20Markdown/}{\emph{R Markdown: The Definitive Guide}} by Xie, Allair \& Grolemund (2020). This is the simplest, most comprehensive, guide to learning R markdown and it's available freely online.
\item
  \href{https://rstudio.com/wp-content/uploads/2015/02/R\%20Markdown-cheatsheet.pdf}{\emph{The R markdown cheat sheet}}, a great resource with the most common R markdown operations; keep on hand for quick referencing.
\item
  \href{https://bookdown.org/yihui/bookdown/}{\emph{Bookdown: Authoring Books and Technical Documents with R Markdown}} (2020) by Yihui Xie. Explains the \texttt{bookdown} package which greatly expands the capabilities of R markdown. For example, the table of contents of this document is created with \texttt{bookdown}.
\end{itemize}

\hypertarget{r-packages}{%
\chapter{R Packages}\label{r-packages}}

Before we do any real data work with R, now is the good time to introduce you to R packages.

R, as a powerful programming language for statistics and data analysis, boasts a rich ecosystem of packages. In this chapter, we'll demystify what these packages are, their importance, and how to utilize them efficiently.

\hypertarget{what-are-r-packages}{%
\section{What are R packages?}\label{what-are-r-packages}}

In a programming context, a package is akin to a toolbox. It contains sets of functions and data sets crafted to perform specific tasks, similar to how a toolbox contains various tools for different jobs. Instead of building every tool from scratch each time you need it, you can simply open your toolbox and grab the necessary instrument. In R, these tools come in the form of functions and data sets bundled inside packages.

Packages are previously written snippets of code that extend the capabilities of base R. Typically packages are created to address specific issues or workflows in different types of analysis.

\hypertarget{benefits-of-using-packages}{%
\subsubsection{Benefits of using packages:}\label{benefits-of-using-packages}}

\begin{itemize}
\tightlist
\item
  \textbf{Efficiency}: Why reinvent the wheel? Packages save time by offering tried and tested functions for specific tasks.
\item
  \textbf{Community Support}: R packages often have a strong community of developers and users. This means frequent updates, thorough documentation, and a network of users to answer questions and offer support.
\item
  \textbf{Versatility}: The vast library of R packages means that you have tools at your disposal for almost every conceivable task or analysis.
\end{itemize}

\hypertarget{how-to-use-r-packages}{%
\section{How to use R packages}\label{how-to-use-r-packages}}

\hypertarget{how-to-install-packages}{%
\subsection{How to install packages}\label{how-to-install-packages}}

Before using a package, you must first install it. This is a one-time process unless you need to update the package to a newer version. To install a package, use the \texttt{install.packages()} function.

This book will make frequent use of a family of packages called the \texttt{tidyverse} (a popular collection of packages for data manipulation). These packages all share a common thought process and integrate naturally with one another. If you want to install the package named ``tidyverse'', you would use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# You can run this code in your R console as well. }
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{how-to-load-packages}{%
\subsection{How to load packages}\label{how-to-load-packages}}

You'll see a flurry of lines printed to the console indicating the status of the installation. Once installed you won't be able to use these functions until you load it with \texttt{library()}. For example, to load the \texttt{tidyverse} package:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# You can run this code in your R console as well. }
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

The output show's us which packages are included in the \texttt{tidyverse()} and their current version numbers, as well as conflicts (where functions from different packages share the same name). Don't worry about these for now.

After this, all the functions and data sets contained in the ``tidyverse'' package are available for you to use in your session. If you're ever uncertain about how to use a particular function, the R community and the package's documentation are excellent resources. For example, you can take a look at the official tidyverse documentation \href{https://tidyverse.tidyverse.org/}{here}.

\hypertarget{calling-specific-functions}{%
\subsection{Calling specific functions}\label{calling-specific-functions}}

We've called functions like \texttt{ggplot()} and \texttt{read\_csv()} from the \texttt{ggplot2} and \texttt{readr} packages, respectively. When we did so, they were implicitly imported when we called \texttt{library(tidyverse)}. What library does is import \emph{all} of the functions within a package into the R workspace, so we can simply refer to them by name later on. Sometimes you'll want to be explicit to which function you call, as you can run into conflicts where different functions from different packages have the same name. Or you might not want to import the entire package when you only need to call one function. Either way, to explicitly call a function from a specific package you type the package name, followed by \texttt{::}, and the function name. I.e. We can use \texttt{read\_csv()} without importing the \texttt{tidyverse}/\texttt{readr} packages by simply typing: \texttt{readr::read\_csv()}. Note the package still needs to be installed on your computer for this to work.

\hypertarget{tidyverse-the-golden-toolbox-of-r}{%
\section{Tidyverse: The Golden Toolbox of R}\label{tidyverse-the-golden-toolbox-of-r}}

We've emphasized before that \texttt{tidyverse} is an indispensable collection of R packages tailored specifically for data science and in-depth data analysis. As you proceed, you'll find that our chapters heavily, if not exclusively, rely on its functionalities. Let's dive into some of its pivotal functions.

\hypertarget{loading-the-tidyverse}{%
\subsection{Loading the Tidyverse}\label{loading-the-tidyverse}}

Before using the functions from the \texttt{tidyverse}, make sure to load the entire collection.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-visualization}{%
\subsection{Data Visualization}\label{data-visualization}}

One of the strengths of the \texttt{tidyverse} is data visualization. The example below shows how you can iteratively build plots by adding layers of details.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ggplot2 built{-}in dataset on fuel economy}
\FunctionTok{data}\NormalTok{(mpg)}

\CommentTok{\# draw a scatterplot}
\FunctionTok{ggplot}\NormalTok{(mpg, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{displ, }\AttributeTok{y=}\NormalTok{hwy)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-43-1.pdf}

\hypertarget{data-manipulation}{%
\subsection{Data Manipulation}\label{data-manipulation}}

The tidyverse provides a set of functions to help solve common data manipulation challenges. The syntax is intuitive and readable, which simplifies both writing and understanding the code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mpg }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(class }\SpecialCharTok{==} \StringTok{"suv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_hwy =} \FunctionTok{mean}\NormalTok{(hwy))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   mean_hwy
##      <dbl>
## 1     18.1
\end{verbatim}

\textbf{Code explanation} (Optional for now; For your curiosity):

\begin{itemize}
\item
  The \texttt{\%\textgreater{}\%} symbol (pipe operator) is a key part of tidyverse. The operator is used to pass an object into a function, allowing for sequential operations to be performed without the need for intermediate variables. For the example above, it's using the operator for data manipulation (filter and summarizing). The result of the left-hand side of the \texttt{\%\textgreater{}\%} is used as the first argument to the function on the right-hand side.
\item
  The \texttt{filter()} function is used to extract a subset of rows from a data frame based on logical conditions. It returns all rows where the condition is \texttt{TRUE}.
\item
  The \texttt{summarize()} function is used to create summary statistics for different variables. You provide named arguments where the name will be the name of a new column, and the value will be the summary statistic to compute.
\end{itemize}

\hypertarget{efficient-data-reading}{%
\subsection{Efficient Data Reading}\label{efficient-data-reading}}

The \texttt{tidyverse} allows for efficient reading of rectangular data, such as CSV and TSV files. For instance, instead of using the R built-in function \texttt{read.csv()}, you can employ a similar function, \texttt{read\_csv()}, from \texttt{tidyverse} to quickly import a CSV file as a data frame. This function provides more flexibility and is optimized for faster performance.

\hypertarget{smile-handling-chemical-structures-in-r}{%
\section{Smile: Handling Chemical Structures in R}\label{smile-handling-chemical-structures-in-r}}

Let's look at one more package that you might find interesting: \texttt{smile}.

\hypertarget{installation}{%
\subsection{Installation}\label{installation}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# to be added}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-simple-example}{%
\subsection{A simple example}\label{a-simple-example}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# to be added}
\end{Highlighting}
\end{Shaded}

\hypertarget{summary-4}{%
\section{Summary}\label{summary-4}}

In this chapter, we delved into the world of R packages, understanding their significance and advantages over built-in R functions. We highlighted the functionalities of \texttt{tidyverse}, showcasing practical examples.

Armed with this foundational knowledge of R packages, we're now poised to harness their capabilities in our R programming journey.

\hypertarget{exercise-4}{%
\section{Exercise}\label{exercise-4}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{loops-and-functions-in-r}{%
\chapter{Loops and Functions in R}\label{loops-and-functions-in-r}}

In this chapter, we will delve into two fundamental concepts in R programming: loops and writing functions. Loops are a powerful tool for iterating over a sequence, making them essential for tasks that require repetitive operations. Writing functions, on the other hand, allows you to create reusable blocks of code, enhancing the efficiency and organization of your programming projects. By the end of this chapter, you will gain a solid understanding of how to effectively use for loops to automate repetitive tasks and how to write your own functions in R, thereby elevating your coding skills to a new level.

\hypertarget{loops}{%
\section{Loops}\label{loops}}

Repetition is a key component of programming. Loops enable you to execute the same piece of code multiple times, making data processing more efficient. If you have a previous programming experience in any language, these syntax should look familiar.

\hypertarget{the-for-loop}{%
\subsubsection{\texorpdfstring{The \texttt{for} loop}{The for loop}}\label{the-for-loop}}

The \texttt{for} loop in R is used to iterate over elements in a vector or list.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(i)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5
\end{verbatim}

This will print numbers from 1 to 5. The loop iterates over each element in the sequence \texttt{1:5}, setting the value to \texttt{i} and executing the code inside the loop.

\hypertarget{the-while-loop}{%
\subsubsection{\texorpdfstring{The \texttt{while} loop}{The while loop}}\label{the-while-loop}}

The \texttt{while} loop continues executing as long as a specified condition remains true.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{count }\OtherTok{\textless{}{-}} \DecValTok{1}

\ControlFlowTok{while}\NormalTok{ (count }\SpecialCharTok{\textless{}=} \DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(count)}
\NormalTok{  count }\OtherTok{\textless{}{-}}\NormalTok{ count }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5
\end{verbatim}

In this example, the loop will keep printing and incrementing the value of counter until counter is no longer less than or equal to 5.

Remember, be cautious with while loops. If the condition never becomes false, the loop will run indefinitely!

\hypertarget{writing-custom-functions-in-r}{%
\section{Writing custom functions in R}\label{writing-custom-functions-in-r}}

Functions form the backbone of most programming languages, and R is no exception. While R provides a rich library of built-in functions, there are times when you'll need to define your own. Custom functions in R allow you to encapsulate a series of commands into a single reusable unit.

\textbf{Why write custom functions?}

\begin{itemize}
\tightlist
\item
  \textbf{Reusability}: Once you've written and tested a function, you can use it repeatedly without having to retype or copy-paste the same lines of code.
\item
  \textbf{Maintainability}: Changes can be made in one place (inside the function) rather than at multiple locations where the code might be used.
\item
  \textbf{Clarity}: Well-named functions can make your main code more readable, as they abstract away the complexity.
\end{itemize}

\hypertarget{simple-example}{%
\subsubsection{Simple example}\label{simple-example}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add\_two }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, b) \{}
  \CommentTok{\# Add a and b and return the value}
\NormalTok{  added }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ b}
  \FunctionTok{return}\NormalTok{(added)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{add\_two} is the custom name of the function.
\item
  \texttt{a} and \texttt{b} are the inputs to the function. You can name them \texttt{x} and \texttt{y}, or anything else, as long as they are kept consistent throughout the function definition. You can also change the number of inputs for your function.
\item
  The \texttt{return} statement specifies the output of your function. If omitted, the function will return the result of the last expression evaluated.
\end{itemize}

You can run this function with various choices of \texttt{a} and \texttt{b}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{add\_two}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{add\_two}\NormalTok{(}\DecValTok{20}\NormalTok{, }\FloatTok{35.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 55.5
\end{verbatim}

At this time, we shall keep it simple. You will eventually see more complex usages of custom functions.

\hypertarget{conditional-arguments}{%
\section{Conditional arguments}\label{conditional-arguments}}

Condaitional arguments used to specify a path in a function depending on whether a statement is \texttt{TRUE} or \texttt{FALSE}. These are explored in greater detail via the links in the \protect\hyperlink{further-reading}{Further reading} section, but here's a quick example of a function that uses the conditional \texttt{if} statement to print out which number is largest:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{isGreater }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y)\{}
  \ControlFlowTok{if}\NormalTok{(x }\SpecialCharTok{\textgreater{}}\NormalTok{ y)\{}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{paste}\NormalTok{(x, }\StringTok{"is greater than"}\NormalTok{, y, }\AttributeTok{sep =} \StringTok{" "}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (x }\SpecialCharTok{\textless{}}\NormalTok{ y)\{ }
    \FunctionTok{return}\NormalTok{(}\FunctionTok{paste}\NormalTok{(x, }\StringTok{"is less than"}\NormalTok{, y, }\AttributeTok{sep =} \StringTok{" "}\NormalTok{))}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{paste}\NormalTok{(x, }\StringTok{"is equal to"}\NormalTok{, y, }\AttributeTok{sep =} \StringTok{" "}\NormalTok{))}
\NormalTok{\}}

\FunctionTok{isGreater}\NormalTok{ (}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2 is greater than 1"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isGreater}\NormalTok{ (}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1 is less than 2"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isGreater}\NormalTok{ (}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1 is equal to 1"
\end{verbatim}

Our simple function compares two numbers, \texttt{x} and \texttt{y} and if \texttt{x\ \textgreater{}\ y} evaluate to \texttt{TRUE} it returns the pasted string \texttt{x\ is\ greater\ than\ y}. If \texttt{x\ \textless{}\ y} evaluates to \texttt{FALSE}, as in \texttt{y\ \textgreater{}\ x}, our function returns the pasted string \texttt{x\ is\ less\ than\ y}, and finally if neither \texttt{x\ \textgreater{}\ y} and \texttt{x\ \textless{}\ y} evaluate to TRUE, they must be equal! Therefore the final output is \texttt{x\ is\ equal\ to\ y}. This is an example of an \texttt{else\ if} statement. If you're simply evaluating two conditions (\texttt{TRUE} or \texttt{FALSE}) you only need the \texttt{if()} conditional, see \protect\hyperlink{further-reading}{Further reading} for more details.

\hypertarget{piping-conditional-statements}{%
\subsection{Piping conditional statements}\label{piping-conditional-statements}}

You can already see the potential for simple conditional statements in the pipe. However, to keep piping operations legible, \texttt{dplyr} offers the \texttt{case\_when} function, which works similarly to the \texttt{else\ if} statements showcased above. Let's see how it works using a real world example.

In mass spectrometry undetected compounds are recorded by the instrument as having an intensity of 0; but it's a common practice to replace 0 with \(\frac{limit~of~detection}{2}\) for subsequent analysis However, we don't want to replace every value with \(\frac{LOD}{2}\), only 0s. Let's use the \texttt{case\_when()} function to create a new values with the recorded intensities

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lod }\OtherTok{\textless{}{-}} \DecValTok{4000} \CommentTok{\# previously calculated LOD }
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{"mz"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\FloatTok{308.97}\NormalTok{, }\FloatTok{380.81}\NormalTok{, }\FloatTok{410.11}\NormalTok{, }\FloatTok{445.34}\NormalTok{ ), }\CommentTok{\# dummy data}
                      \StringTok{"intensities"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{5000}\NormalTok{, }\DecValTok{10000}\NormalTok{)) }

\NormalTok{results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{reportedIntensities =} \FunctionTok{case\_when}\NormalTok{(intensities }\SpecialCharTok{\textless{}}\NormalTok{ lod }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lod}\SpecialCharTok{/}\DecValTok{2}\NormalTok{,}
                                 \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}}\NormalTok{ intensities))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       mz intensities reportedIntensities
## 1 308.97           0                2000
## 2 380.81        1000                2000
## 3 410.11        5000                5000
## 4 445.34       10000               10000
\end{verbatim}

Firstly we're creating a new column called \texttt{reportedIntesities} using \texttt{mutate()} and using \texttt{case\_when()} to conditionally fill that column. The inputs we've passed to \texttt{case\_when()} are two-sided formulas. Essentially if the conditions on the left-hand side of the tilda (\texttt{\textasciitilde{}}) evaluate to \texttt{TRUE}, \texttt{case\_when} will execute the right-hand side. Thee first two-sided formula is \texttt{intensities\ \textless{}\ lod\ \textasciitilde{}\ lod/2} and checks if the intensities value is less than the previously calculated limit of detection. If \texttt{intensitis\ \textless{}\ lod} evaluates to \texttt{TRUE} we insert half of the LOD value for that row. If \texttt{intentisites\ \textless{}\ lod} evaluates to \texttt{FALSE}, we move onto the next two-side formula and reevaluate again. The second two-sided formula \texttt{TRUE\ \textasciitilde{}\ intensities} basically means for everything that's remaining (greater than LOD in our instance) just use the value from the \texttt{intensities} column.

Some ideas to consider when working with \texttt{case-when()}:

\begin{itemize}
\tightlist
\item
  There's no limits to the conditions you can pass to \texttt{case\_when()}.
\item
  \emph{However} \texttt{case\_when()} evaluates in order so put the more specific conditions before the more general.
\item
  Remember that the point of \texttt{case\_when()} and piping is legibility. If you're passing multiple conditions, consider writing a function using \texttt{else\ if} statements to keep the pipe legible.
\end{itemize}

\hypertarget{further-reading}{%
\section{Further reading}\label{further-reading}}

These chapter has been intentional succinct. We've omitted several other aspects of programming in R such as \texttt{for} loops, and other iterative programming. To get a better sense of programming in R and to learn more, please see the following links:

\begin{itemize}
\tightlist
\item
  \href{https://dplyr.tidyverse.org/reference/case_when.html}{case\_when()}: the documentation for the \texttt{case\_when()} function and several useful examples.
\item
  \href{https://r4ds.had.co.nz/functions.html}{Chapter 19: Functions}, \href{https://r4ds.had.co.nz/vectors.html}{Chapter 20: Vectors}, and \href{https://r4ds.had.co.nz/iteration.html}{Chapter 21: Iteration} of \href{https://r4ds.had.co.nz/index.html}{\emph{R for Data Science}} by H. Wickham and G. Grolemund.\\
\item
  \href{https://rstudio-education.github.io/hopr/}{Hands-on Programming in R} by G. Grolemund for a more in-depth (but still approachable) take on programming in R.
\end{itemize}

\hypertarget{part-part-3-data-analysis-in-r}{%
\part*{Part 3: Data Analysis in R}\label{part-part-3-data-analysis-in-r}}
\addcontentsline{toc}{part}{Part 3: Data Analysis in R}

\hypertarget{intro-to-data-analysis}{%
\chapter{Intro to Data Analysis}\label{intro-to-data-analysis}}

Now, we will embark on a comprehensive journey through the data analysis process, focusing on the essential steps of data wrangling and advanced analytical techniques. The chapter is designed to equip you with the necessary skills to use R effectively for organizing and transforming your data, a crucial foundation for any data analysis project. We will delve into the core workflow that is applicable to every data analysis task, regardless of its complexity or duration. This workflow is not just a one-time learning curve but a set of skills you will repeatedly use across various projects.

The explicit workflow we'll be teaching was originally described by Wickham and Grolemund, and consists of six key steps:

\begin{figure}
\centering
\includegraphics[width=0.99\textwidth,height=\textheight]{images/data-science-workflow.png}
\caption{Data science workflow describes by Wickham and Grolemund; image from \emph{R for Data Science}, Wickham and Grolemund (2021)}
\end{figure}

\begin{itemize}
\tightlist
\item
  \textbf{Import} is the first step and consist of getting your data into R. Seems obvious, but doing it correctly will save you time and headaches down the line.
\item
  \textbf{Tidy} refers to organizing your data in a \emph{tidy} manner where each variable is a column, and each observation a row. This is often the least intuitive part about working with R, especially if you've only used Excel, but it's critical. If you don't tidy your data, you'll be fighting it every step of the way.
\item
  \textbf{Transform} is anything you do to your data including any mathematical operations or narrowing in on a set of observations. It's often the first stage of the cycle as you'll need to transform your data in some manner to obtain a desired plot.
\item
  \textbf{Visualize} is any of the plots/graphics you'll generate with R. Take advantage of R and plot often, it's the easiest way to spot an error.
\item
  \textbf{Model} is an extension of mathematical operations to help understand your data. The \emph{linear regressions} needed for a calibration curve are an example of a model.
\item
  \textbf{Communicate} is the final step and is where you share the \emph{knowledge} you've squeezed out of the information in the original data.
\end{itemize}

\emph{Import}, \emph{Tidy}, and \emph{Transformation} go hand-in-hand in a process called \emph{wrangling}. Wrangling is all of the steps needed to get your data ready for analysis. It's often the most tedious and frustrating, hence wrangling (it's a fight\ldots), but once done make the subsequent cycle of understanding your data via \emph{transformation}, \emph{visualizations}, and \emph{modelling} much easier and more predictable.

\hypertarget{example-data}{%
\section{Example Data}\label{example-data}}

Throughout this section and the next we'll be making use of a couple of example datasets. These datasets are all available in the \texttt{data} subfolder of the \emph{R4EnvChem Project Template}. If you haven't already, read \protect\hyperlink{importing-a-project}{Importing a project} for instructions on dowloading the repository and data.

\hypertarget{sneak-peek-at-data-analysis}{%
\section{Sneak Peek at Data Analysis}\label{sneak-peek-at-data-analysis}}

In this trailer section, we'll explore how data analysis can provide insights into real-world phenomena. We'll use the \texttt{storm} dataset from the \texttt{tidyverse} suite in R to investigate the patterns and relationships of storms over the years.

\hypertarget{setting-up}{%
\subsection{Setting Up}\label{setting-up}}

Let's begin by loading our dataset and essential packages.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\CommentTok{\# Import the storm dataset}
\FunctionTok{data}\NormalTok{(storms)}
\end{Highlighting}
\end{Shaded}

Let's see how the data looks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(storms)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\hypertarget{tidying-our-data}{%
\subsection{Tidying Our Data}\label{tidying-our-data}}

Now that you saw how the data looks, before delving into deeper analysis, it's important to have a general sense of our data.

To narrow our focus, let's consider the storm \texttt{name}, \texttt{year}, \texttt{month}, \texttt{day}, \texttt{lat}, \texttt{long}, and \texttt{wind} speed.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1. Selecting relevant variables}

\NormalTok{selected\_storms }\OtherTok{\textless{}{-}}\NormalTok{ storms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(name, year, month, day, lat, long, wind)}

\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(selected\_storms)}
\end{Highlighting}
\end{Shaded}

Next, instead of having separate columns for \texttt{year}, \texttt{month}, and \texttt{day}, it might be more useful to have a single date column.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 2. Creating a unified date column}

\NormalTok{storms\_with\_date }\OtherTok{\textless{}{-}}\NormalTok{ selected\_storms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unite}\NormalTok{(}\StringTok{"date"}\NormalTok{, year, month, day, }\AttributeTok{sep =} \StringTok{"{-}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date =} \FunctionTok{as.Date}\NormalTok{(date, }\AttributeTok{format =} \StringTok{"\%Y{-}\%m{-}\%d"}\NormalTok{))}

\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(storms\_with\_date)}
\end{Highlighting}
\end{Shaded}

Column names should be self-explanatory. Let's rename \texttt{wind} to \texttt{wind\_speed\_knots}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 3. Renaming columns for clarity}

\NormalTok{tidied\_storms }\OtherTok{\textless{}{-}}\NormalTok{ storms\_with\_date }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{wind\_speed\_knots =}\NormalTok{ wind)}
\end{Highlighting}
\end{Shaded}

Now that our data is tidied up, let's see if we can do more in-depth analysis.

\hypertarget{investigating-storm-patterns}{%
\subsection{Investigating Storm Patterns}\label{investigating-storm-patterns}}

\hypertarget{analyzing-powerful-storms}{%
\subsubsection{Analyzing powerful storms}\label{analyzing-powerful-storms}}

For safety and preparedness reasons, meteorologists are often interested in particularly powerful storms. Let's identify storms with wind speeds exceeding 100 knots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{powerful\_storms }\OtherTok{\textless{}{-}}\NormalTok{ tidied\_storms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(wind\_speed\_knots }\SpecialCharTok{\textgreater{}} \DecValTok{100}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(wind\_speed\_knots))}
\end{Highlighting}
\end{Shaded}

\hypertarget{yearly-trends}{%
\subsubsection{Yearly trends}\label{yearly-trends}}

How has the frequency of these powerful storms changed over the years? We can group our data by year to answer this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yearly\_storms }\OtherTok{\textless{}{-}}\NormalTok{ powerful\_storms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{year =} \FunctionTok{year}\NormalTok{(date)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(year) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{storm\_count =} \FunctionTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualization-geographical-distribution}{%
\subsection{Visualization: Geographical Distribution}\label{visualization-geographical-distribution}}

One of the key aspects of understanding storms is analyzing where they occur. Using our powerful storms data, let's plot a scatterplot of \texttt{latitude} versus \texttt{wind\_speed\_knots} to visualize their geographical distribution and intensity.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ powerful\_storms, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lat, }\AttributeTok{y =}\NormalTok{ wind\_speed\_knots)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ wind\_speed\_knots), }\AttributeTok{alpha =} \FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Distribution and Intensity of Powerful Storms"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Latitude"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Wind Speed (knots)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{high =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-64-1.pdf}

Through this brief exploration, we've seen how data analysis can provide insights into storm patterns. With more advanced techniques, which we'll explore in the subsequent chapters, we can delve even deeper, helping inform decisions, ensuring preparedness, and advancing our understanding of meteorological phenomena.

\hypertarget{further-reading-1}{%
\section{Further Reading}\label{further-reading-1}}

In case it hasn't been apparent enough, this entire endeavour was inspired by the \emph{R for Data Science} reference book by Hadley Wickham and Garrett Grolemund. Every step described above is explored in more detail in their book, which can be read freely online at \url{https://r4ds.had.co.nz/}. We strongly encourage you to read through the book to supplement your R data analysis skills.

\hypertarget{importing-your-data-into-r}{%
\chapter{Importing Your Data Into R}\label{importing-your-data-into-r}}

Unlike \emph{Excel}, you can't copy and paste your data into R (or RStudio). Instead you need to \emph{import} your data into R so you can work with it. This chapter will discuss how your data is stored, and how to import it into R (with some accompanying nuances).

\hypertarget{csv-files}{%
\section{.csv files}\label{csv-files}}

While there are a myriad of ways data is stored, raw instrument often record results in a proprietary vendor format, the data you're likely to encounter in an undergraduate lab will be in the form of a \texttt{.csv} or \emph{comma-separated values} file. As the name implies, values are separated by commas (go ahead and open any \texttt{.csv} file in any text editor to observe this). Essentially you can think of each line as a row and commas as separating values into columns, which is exactly how R and \emph{Excel} handle \texttt{.csv} files.

\hypertarget{read_csv}{%
\section{read\_csv}\label{read_csv}}

Importing a \texttt{.csv} file into R simply requires the \texttt{read.csv} or the \texttt{read\_csv} function from tidyverse. The first variable is the most important as it's the file path. Recall that R, unless specified, uses relative referencing. So in the example below we're importing the \texttt{ATR\_plastics.csv} from the \texttt{data} sub-folder in our project by specifying \texttt{"data/ATR\_plastics.csv"} and assigning it to the variable \texttt{atr\_plastics}. Note the inclusion of the file extension.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_plastics }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 7157 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## dbl (5): wavenumber, EPDM, Polystyrene, Polyethylene, Sample: Shopping bag
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

A benefit of using \texttt{read\_csv} is that it prints out the column specifications with each column's name (how you'll reference it in code) and the column value type. Columns can have different data types, but a data type must be consistent within any given column. Having the columns specifications is a good way to ensure R is correctly reading your data. The most common data types are:

\begin{itemize}
\tightlist
\item
  \textbf{int} for integer values (\emph{-1,1, 2, 10, etc.})
\item
  \textbf{dbl} for doubles (decimals) or real numbers (\emph{-1.20, 0.0, 1.200, 1e7, etc.})
\item
  \textbf{chr} for character vectors or strings (\emph{``A'', ``chemical'', ``Howdy ma'am'', etc.})

  \begin{itemize}
  \tightlist
  \item
    note numbers can be encoded as strings, so while you might read ``1'' as a number, R treats it as a character, limiting how you can use this value.
  \end{itemize}
\item
  \textbf{lgl} for logical values, either \texttt{TRUE} or \texttt{FALSE}
\end{itemize}

We can also quickly inspect either through the \emph{Environment} pane in \emph{RStudio} or quickly with the \texttt{head()} function. Note the column specifications under the column name.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(atr\_plastics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavenumber  EPDM Polystyrene Polyethylene `Sample: Shopping bag`
##        <dbl> <dbl>       <dbl>        <dbl>                  <dbl>
## 1       550. 0.212      0.0746     0.000873                 0.0236
## 2       551. 0.212      0.0746     0.000834                 0.0238
## 3       551. 0.213      0.0745     0.000819                 0.0239
## 4       552. 0.213      0.0745     0.000825                 0.0239
## 5       552. 0.214      0.0745     0.000868                 0.0240
## 6       553. 0.214      0.0746     0.000949                 0.0240
\end{verbatim}

As you can see, the \texttt{head()} function, by default, shows the first six rows of the dataframe. If you want to inspect more or fewer rows, you can provide an optional \texttt{n} argument like \texttt{head(data,\ n=10)}. Note the column specifications under the column name.

Also note how the first line of the \texttt{ATR\_plastics.csv} has been interpreted as columns names (or \emph{headers}) by R. This is common practice, and gives you a handle by which you can manipulate your data. If you did not intend for R to interpret the first row as headers you can suppress this with the additional argument \texttt{col\_names\ =\ FALSE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(}\FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 7158 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (5): X1, X2, X3, X4, X5
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 5
##   X1         X2        X3          X4           X5                  
##   <chr>      <chr>     <chr>       <chr>        <chr>               
## 1 wavenumber EPDM      Polystyrene Polyethylene Sample: Shopping bag
## 2 550.0952   0.2119556 0.07463058  0.000873196  0.02364882          
## 3 550.5773   0.2124079 0.07455246  0.000834192  0.02382648          
## 4 551.0594   0.2128818 0.07450471  0.000819447  0.02387163          
## 5 551.5415   0.2133267 0.07449704  0.000825491  0.02391921          
## 6 552.0236   0.2137241 0.07452058  0.000868397  0.02396947
\end{verbatim}

Note in the example above that since the headers are now considered data, and are composed of a string of chatacters, the entire column is then interpreted as character values. This will happen if a single non-numeric character is introduced in the column, so beware of typos when recording data! If we wanted to skip rows (i.e.~to avoid blank rows at the top of our \texttt{.csv}), we can use the \texttt{skip\ =\ n} to skip n rows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(}\FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{skip =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 7157 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## dbl (5): X1, X2, X3, X4, X5
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 5
##      X1    X2     X3       X4     X5
##   <dbl> <dbl>  <dbl>    <dbl>  <dbl>
## 1  550. 0.212 0.0746 0.000873 0.0236
## 2  551. 0.212 0.0746 0.000834 0.0238
## 3  551. 0.213 0.0745 0.000819 0.0239
## 4  552. 0.213 0.0745 0.000825 0.0239
## 5  552. 0.214 0.0745 0.000868 0.0240
## 6  553. 0.214 0.0746 0.000949 0.0240
\end{verbatim}

Note in the example above that we skipped our headers, so \texttt{read\_csv()} created placeholder headers (\texttt{X1}, \texttt{X2}, etc.).

Another useful function to inspect data is \texttt{tail()}, which displays the last six rows of a dataframe. Similarly, it accepts an optional \texttt{n} argument to specify the number of rows you want to view.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(atr\_plastics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavenumber  EPDM Polystyrene Polyethylene `Sample: Shopping bag`
##        <dbl> <dbl>       <dbl>        <dbl>                  <dbl>
## 1      3998. 0.113      0.0706  0                           0.0664
## 2      3998. 0.113      0.0706  0.000000582                 0.0664
## 3      3999. 0.113      0.0706  0.0000242                   0.0664
## 4      3999. 0.113      0.0706  0.000067                    0.0664
## 5      4000. 0.113      0.0706  0.000125                    0.0664
## 6      4000. 0.113      0.0706  0.000195                    0.0663
\end{verbatim}

\hypertarget{tibbles-vs.-data-frames}{%
\subsection{Tibbles vs.~data frames}\label{tibbles-vs.-data-frames}}

Quick eyes will notice the first line outputted above is \texttt{\#\ A\ tibble:\ 6\ x\ 5}. \texttt{tibbles} are a variation of \texttt{data.frames} introduced in section one, but built specifically for the \texttt{tidyverse} family of packages. While \texttt{data.frames} and \texttt{tibbles} are often interchangeable, it's important to be aware of the difference in case you do run into a rare conflict. In these situations you can readily transform a \texttt{tibble} into a \texttt{data.frame} by coercion with the \texttt{as.data.frame()} function, and vice-versa with the \texttt{as\_tibble()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(atr\_plastics))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "data.frame"
\end{verbatim}

\hypertarget{importing-other-data-types}{%
\section{Importing other data types}\label{importing-other-data-types}}

There are other functions to import different types of tabular data which all function like \texttt{read\_csv}, such as \texttt{read\_tsv} for tab-separate value files (\texttt{.tsv}) and \texttt{read\_excel} and \texttt{read\_xlsx} from the \texttt{readxl} package to import \emph{Excel} files. Note most \emph{Excel} files have probably been formatted for legibility (i.e.~merged columns), which can lead to errors when importing into R. If you plan on importing \emph{Excel} files, it's probably best to open them in \emph{Excel} to remove any formatting, and then save as \texttt{.csv} for smoother importing into R.

\hypertarget{saving-data}{%
\section{Saving data}\label{saving-data}}

As you progress with your analysis you may want to save intermediate or final datasets. This is readily accomplished ussing the \texttt{write\_csv()} from the \texttt{readr} package. Similar rules apply to how we used \texttt{read\_csv}, but now the second argument specifies the save location and file name, while the first argument is which \texttt{tibble}/\texttt{data.frame} we're saving. Note that R \emph{will not} create a folder this way, so if you're saving to a sub-folder you'll have to make sure it exists or create it yourself.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{write\_csv}\NormalTok{(atr\_plastics, }\StringTok{"data/ATRSaveExample.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A benefit of \texttt{write\_csv} is that it will always save in \texttt{UTF-8} encoding and ISO8601 time format. This standardization makes it easier to share your \texttt{.csv} files with collaborators/yourself.

\hypertarget{further-reading-2}{%
\section{Further Reading}\label{further-reading-2}}

See Chapters \href{https://r4ds.had.co.nz/tibbles.html}{10} and \href{https://r4ds.had.co.nz/data-import.html}{11} of \emph{R for Data Science} for some more details on \texttt{tibbles} and \texttt{read\_csv}.

\hypertarget{exercise-5}{%
\section{Exercise}\label{exercise-5}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{tidying-your-data}{%
\chapter{Tidying Your Data}\label{tidying-your-data}}

You might not have explicitly thought about how you store your data, whether working in \emph{Excel} or elsewhere. Data is data after all. But having your data organized in a systematic manner that is conducive to your goal is paramount for working not only with R, but all of your experimental data. This chapter will introduce the concept of \emph{tidy} data, and how to use some of the tools in the \emph{dplyr} package to get there. Lastly we'll offer some tips for how you should record \emph{your} data in the lab. A bit of foresight and consistency can eliminate hours of tedious work down the line.

\hypertarget{what-is-tidy-data}{%
\section{What is tidy data?}\label{what-is-tidy-data}}

Tidy data has ``\ldots each variable in a column, and each observation in a row\ldots{}'' (Hadley Wickham 2014) This may seem obvious to you, but let's consider how data is often recorded in lab, as exemplified in Figure \ref{fig:tidy-example}A. Here the instrument response of two chemicals (\emph{A} and \emph{B}) for two samples (\emph{blank} and \emph{unknown}) are recorded. Note how the samples are on each row and the chemical are columns. However, someone else may record the same data differently as shown in Figure \ref{fig:tidy-example}B, with the samples occupying distinct columns, and the chemical rows. Either layout may work well, but analyzing both would require re-tooling your approach. This is where the concept of \emph{tidy} data comes into play. By reclassifying our data into \emph{observations} and \emph{variables} we can restructure out data into a common format: the \emph{tidy} format (Figure \ref{fig:tidy-example}C).

\begin{figure}
\includegraphics[width=12.99in]{images/tidy-example} \caption{(A and B) The same data can be recorded in multiple formats. (C) The same data in the tidy format. Note how the tidy data typically has more rows, hence why it's sometimes refered to as 'long' data.}\label{fig:tidy-example}
\end{figure}

In the \emph{tidy} or \emph{long} format, we reclassified out data into three variables (\emph{Sample}, \emph{Chemical}, and \emph{Reading}). This makes the observations clearer as now we know we measured two chemicals (\emph{A} and \emph{B}) in two samples (\emph{blank} and \emph{unknown}) and we've explicitly declared the \emph{Reading} variable for our measured instrument response, which was only implied in the original layouts. Moreover, we can read across a row to get the gist of one data point (i.e.~``Our blank has a reading of 0 for Chemical A''). Again we haven't changed any information, we've simply reorganized our data to be clearer, consistent, and compatible with the \texttt{tidyverse} suit of tools.

This might seem pedantic now, but as you progress you'll want to reuse code you've previously written. This is greatly facilitated by making every data set as consistently structured as possible, and the \emph{tidy} format is an ideal starting place.

\hypertarget{tools-to-tidy-your-data}{%
\section{Tools to tidy your data}\label{tools-to-tidy-your-data}}

Now one of the more laborious parts of data science is tidying your data. If you can follow the tips in the \protect\hyperlink{tips-for-recording-data}{Tips for recording data} section, but the truth is you often won't have control. To this end, the \texttt{tidyverse} offers several tools, notable \texttt{dplyr} (pronounces `d-pliers'), to help you get there.

Let's revisit our spectroscopy data from the previous chapter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_plastics }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{)}

\CommentTok{\# This just outputs a table you can explore within your browser}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(atr\_plastics)}
\end{Highlighting}
\end{Shaded}

As we can see this our ATR spectroscopy results of several plastics, as recorded for a \emph{CHM 317} lab, is structured similarly to the example in Figure \ref{fig:tidy-example}A. The ATR absorbance spectra of the four plastics are recorded in separate columns. Again, this format makes intuitive sense when recording in the lab, and for working in Excel, but isn't the friendliest with R. When making plots with \texttt{ggplot}, we can only specify one \texttt{y} variable. In the example plot below it's the absorbance spectrum of \texttt{Polystyrene}. However, if wanted to plot the other spectra for comparison, we'd need to repeat our \texttt{geom\_point} call.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plotting Polystyrene absorbance spectra}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
       \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ wavenumber,}
            \AttributeTok{y =}\NormalTok{ Polystyrene)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-74-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plotting Polystyrene and Polyethylene absorbance spectra}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
       \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ wavenumber,}
            \AttributeTok{y =}\NormalTok{ Polystyrene)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
                 \AttributeTok{y =}\NormalTok{ Polyethylene))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-74-2.pdf}

\hypertarget{selection-helpers}{%
\subsection{Selection helpers}\label{selection-helpers}}

As you've already seen, there are multiple ways to select columns and variables with the \texttt{dplyr} package. For a complete rundown of other useful helper functions please see \href{https://dplyr.tidyverse.org/reference/select.html}{Subset columns using their names and types}. \texttt{starts\_with()} for selecting columns from a prefix, and \texttt{contains()} for selecting columns that contain a string are two of the most useful.

\hypertarget{seperating-columns}{%
\subsection{Seperating columns}\label{seperating-columns}}

Sometimes your data has already been recorded in a tidy-ish fashion, but there may be multiple observations recorded under one apparent variable, something like \texttt{1\ mM} for concentration. As it stands we cannot easily access the numerical value in the concentration recording because R will encode this as a string due to the \texttt{mM}. We can \textbf{separate} data like this using the \texttt{seperate} function, which operates similarly to how \texttt{pivot\_longer} breaks up headers.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example with multiple encoded observations}
\NormalTok{sep\_example}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          sample reading
## 1  Toronto_O3_1      10
## 2  Toronto_O3_2      22
## 3 Toronto_NO2_1      30
\end{verbatim}

The example above is something you'll come across in the lab, most often with the sample names you'll pass along to your TA where you crammed as much information as possible into that name so you and your TAs know exactly what's being analyzed. In this example, the sample name contains the location (\texttt{Toronto}), the chemical measured (\texttt{O3} or \texttt{NO2}) and the replicate number (i.e.~\texttt{1}). Using the \texttt{seperate} function we can split up these three observations so we can properly group our data later on in our analysis.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Separating observations}

\NormalTok{sep\_data }\OtherTok{\textless{}{-}} \FunctionTok{separate}\NormalTok{(sep\_example,}
    \AttributeTok{col =}\NormalTok{ sample, }
    \AttributeTok{into =} \FunctionTok{c}\NormalTok{(}\StringTok{"location"}\NormalTok{, }\StringTok{"chemical"}\NormalTok{, }\StringTok{"replicateNum"}\NormalTok{),}
    \AttributeTok{sep =} \StringTok{"\_"}\NormalTok{,}
    \AttributeTok{remove =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{convert =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{sep\_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   location chemical replicateNum reading
## 1  Toronto       O3            1      10
## 2  Toronto       O3            2      22
## 3  Toronto      NO2            1      30
\end{verbatim}

Again, let's break down what we did with the \texttt{separate} function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{col\ =\ sample} specifies we're selecting the \texttt{sample} column
\item
  \texttt{into\ =\ c(...)} specifies what columns we're separating our name into.
\item
  \texttt{sep\ =\ "\_"1} specifies that each element is separated by an underscore (\texttt{\_}); you can use \texttt{sep\ =\ "\ "} if they were separated by spaces.
\item
  \texttt{remove\ =\ TRUE} removes the original sample column, no need for duplication; setting this to \texttt{FALSE} would keep the original column.
\item
  \texttt{convert\ =\ TRUE} converts the new columns to the appropriate data format. In the original column ,the replicate number is a character value because it's part of a string, \texttt{convert} ensures that it'll be converted to a numerical value.
\end{enumerate}

Another example why it's paramount to \textbf{be consistent when recording data}.

\hypertarget{unitingcombining-columns}{%
\subsection{Uniting/combining columns}\label{unitingcombining-columns}}

The opposite of the \texttt{separate} function is the \texttt{unite} function. You'll use it far less often, but you should be aware of it as it may come in handy. You can use it for combining strings together, or prettying up tables for publication/presentations as shown in \protect\hyperlink{summarizing-data}{Summarizing Data}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Uniting observations}

\NormalTok{united\_data }\OtherTok{\textless{}{-}} \FunctionTok{unite}\NormalTok{(sep\_data,}
                     \AttributeTok{col=}\NormalTok{sample\_reunited,}
\NormalTok{                     location}\SpecialCharTok{:}\NormalTok{chemical}\SpecialCharTok{:}\NormalTok{replicateNum, }
                     \AttributeTok{sep =} \StringTok{"\_"}\NormalTok{,}
                     \AttributeTok{remove =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{united\_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   sample_reunited reading
## 1    Toronto_O3_1      10
## 2    Toronto_O3_2      22
## 3   Toronto_NO2_1      30
\end{verbatim}

You can read more about the \texttt{unite} function \href{https://tidyr.tidyverse.org/reference/unite.html}{here}.

\hypertarget{renaming-columnsheaders}{%
\subsection{Renaming columns/headers}\label{renaming-columnsheaders}}

Sometimes a name is lengthy, or cumbersome to work with in R. While something like \texttt{This\_is\_a\_valid\_header} is valid and compatible with R and tidyverse functions, you may want to change it to make it easier to work with (i.e.~less typing). Simply use the \texttt{rename()} function:

Inspect the original column names:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(badHeader)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "UVVis_Wave_Length_nM" "Absorbance"
\end{verbatim}

Use \texttt{rename()} to change the column name and save the result to a new dataframe:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{renamed\_data }\OtherTok{\textless{}{-}} \FunctionTok{rename}\NormalTok{(badHeader, }\AttributeTok{wavelength\_nM =}\NormalTok{ UVVis\_Wave\_Length\_nM)}

\CommentTok{\# Inspect the column names of the renamed dataframe}
\FunctionTok{colnames}\NormalTok{(renamed\_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "wavelength_nM" "Absorbance"
\end{verbatim}

\hypertarget{chaining-multiple-operations}{%
\subsection{Chaining multiple operations}\label{chaining-multiple-operations}}

So far we learned some standalone functions that can tidy up your data. But what if you want to do multiple of these operations to a dataset?

Let's start by talking about the seemingly intuitive but tedious approach. We can transform data by breaking down the process into individual steps:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected\_data }\OtherTok{\textless{}{-}} \FunctionTok{select}\NormalTok{(atr\_plastics, wavenumber, EPDM, }\StringTok{\textasciigrave{}}\AttributeTok{Sample: Shopping bag}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{longer\_data }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_longer}\NormalTok{(selected\_data, }\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{wavenumber, }\AttributeTok{names\_to =} \StringTok{"Material\_Type"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"Value"}\NormalTok{)}
\NormalTok{atr\_plastics\_transformed }\OtherTok{\textless{}{-}} \FunctionTok{rename}\NormalTok{(longer\_data, }\AttributeTok{Wave\_Num =}\NormalTok{ wavenumber)}

\NormalTok{atr\_plastics\_transformed}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14,314 x 3
##    Wave_Num Material_Type         Value
##       <dbl> <chr>                 <dbl>
##  1     550. EPDM                 0.212 
##  2     550. Sample: Shopping bag 0.0236
##  3     551. EPDM                 0.212 
##  4     551. Sample: Shopping bag 0.0238
##  5     551. EPDM                 0.213 
##  6     551. Sample: Shopping bag 0.0239
##  7     552. EPDM                 0.213 
##  8     552. Sample: Shopping bag 0.0239
##  9     552. EPDM                 0.214 
## 10     552. Sample: Shopping bag 0.0240
## # i 14,304 more rows
\end{verbatim}

Now, let's see how we can transform the same \texttt{atr\_plastics} tibble using the \texttt{\%\textgreater{}\%} operator by chaining operations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_plastics\_transformed }\OtherTok{\textless{}{-}}\NormalTok{ atr\_plastics }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(wavenumber, EPDM, }\StringTok{\textasciigrave{}}\AttributeTok{Sample: Shopping bag}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{wavenumber, }\AttributeTok{names\_to =} \StringTok{"Material\_Type"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"Value"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{Wave\_Num =}\NormalTok{ wavenumber)}

\NormalTok{atr\_plastics\_transformed}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14,314 x 3
##    Wave_Num Material_Type         Value
##       <dbl> <chr>                 <dbl>
##  1     550. EPDM                 0.212 
##  2     550. Sample: Shopping bag 0.0236
##  3     551. EPDM                 0.212 
##  4     551. Sample: Shopping bag 0.0238
##  5     551. EPDM                 0.213 
##  6     551. Sample: Shopping bag 0.0239
##  7     552. EPDM                 0.213 
##  8     552. Sample: Shopping bag 0.0239
##  9     552. EPDM                 0.214 
## 10     552. Sample: Shopping bag 0.0240
## # i 14,304 more rows
\end{verbatim}

We will formally introduce the unfamiliar operator \texttt{\%\textgreater{}\%} (pipe) in the next chapter (check out 12.6 if interested). For now, just remember that there is a way to chain your functions like the above example!

\hypertarget{tips-for-recording-data}{%
\section{Tips for recording data}\label{tips-for-recording-data}}

In case you haven't picked up on it, tidying data in R is much easier if the data is recorded consistently. You can't always control how your data will look, but in the event that you can (i.e.~your inputting the instrument readings into \emph{Excel} on the bench top) here are some tips to make your life easier:

\begin{itemize}
\tightlist
\item
  \emph{Be consistent}. If you're naming your samples make sure they all contain the same elements in the same order. The sample names \texttt{Toronto\_O3\_1} and \texttt{Toronto\_O3\_2} can easily be broken up as demonstrated in {[}Separating columns{]}; \texttt{O3\_Toronto\_1}, \texttt{TorontoO32}, and \texttt{Toronto\_1} can't be.
\item
  \emph{Use as simple as possible headers}. Often you'll be pasting instrument readings into one \texttt{.csv} using \emph{Excel} on whatever computer records the instrument readings. In these situations it's often much easier to paste things in columns. Recall the capabilities of \texttt{pivot\_longer} and how you can break up names as described in {[}Making data `longer'{]}. \texttt{Chemical\_A\_1} and \texttt{Chemical\_B\_2} are headers that are descriptive for your sample and can be easily pivoted into their own columns. \texttt{Chemical\ A\ 1\ (\ I\ think?!)} is a header that isn't.
\item
  \emph{Make sure data types are consistent within a column}. This harks back to the {[}Importing data into R{]} chapter, but a single non-numeric character can cause R to misinterpret an entire column leading to headaches down the line.
\item
  \emph{Save your data in UTF-8 format}. Excel and other programs often allow you to export your data in a variety of \texttt{.csv} encodings, but this can affect how R reads when importing your data. Make sure you select \texttt{UTF-8} encoding when exporting your data.
\end{itemize}

\hypertarget{further-reading-3}{%
\section{Further reading}\label{further-reading-3}}

As always, the \emph{R for Data Science} book goes into more detail on all of the elements discussed above. For the material covered here you may want to read \href{https://r4ds.had.co.nz/tidy-data.html}{Chapter 9: Tidy Data}.

\hypertarget{exercise-6}{%
\section{Exercise}\label{exercise-6}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{resturcturing-your-data}{%
\chapter{Resturcturing Your Data}\label{resturcturing-your-data}}

In the realm of data analysis, the structure of your data can be just as crucial as the data itself. When dealing with complex datasets in R, or any other analytical environment, the way you organize and reshape your data can significantly impact the efficiency and clarity of your analyses. This chapter delves into the art of restructuring data in R, focusing on two powerful functions: \texttt{pivot\_longer} and \texttt{pivot\_wider}. These tools, part of the \texttt{tidyr} package, are essential for transforming data into a format that aligns perfectly with your analytical objectives.

Understanding and mastering these functions will equip you with the skills to seamlessly toggle between different data layouts. Whether you need to condense wide datasets into longer, more detailed formats using \texttt{pivot\_longer}, or expand long datasets into a wider, more summarized form with \texttt{pivot\_wider}, this chapter will guide you through each step with practical examples and insights. By the end of this chapter, you'll not only be adept at manipulating your data's structure in R but also appreciate how such transformations can unveil new perspectives and insights in your data analysis journey.

\hypertarget{making-data-longer}{%
\section{Making data longer}\label{making-data-longer}}

Let's revisit our spectroscopy data from the previous chapter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_plastics }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{)}

\CommentTok{\# This just outputs a table you can explore within your browser}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(atr\_plastics)}
\end{Highlighting}
\end{Shaded}

As we can see this our ATR spectroscopy results of several plastics, as recorded for a \emph{CHM 317} lab, is structured similarly to the example in Figure \ref{fig:tidy-example}A. The ATR absorbance spectra of the four plastics are recorded in separate columns. Again, this format makes intuitive sense when recording in the lab, and for working in Excel, but isn't the friendliest with R. When making plots with \texttt{ggplot}, we can only specify one \texttt{y} variable. In the example plot below it's the absorbance spectrum of \texttt{Polystyrene}. However, if wanted to plot the other spectra for comparison, we'd need to repeat our \texttt{geom\_point} call.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plotting Polystyrene absorbance spectra}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
       \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ wavenumber,}
            \AttributeTok{y =}\NormalTok{ Polystyrene)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-86-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plotting Polystyrene and Polyethylene absorbance spectra}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
       \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ wavenumber,}
            \AttributeTok{y =}\NormalTok{ Polystyrene)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_plastics, }
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
                 \AttributeTok{y =}\NormalTok{ Polyethylene))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-86-2.pdf}

While the code above works, it's not particularly handy and undermines much of the utility of \texttt{ggplot} because the data \emph{isn't} tidy. Fortunately the \texttt{pivot\_longer} function can easily restructure our data into the \emph{long} format to work with \texttt{ggplot}. Let's demonstrate that:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_long }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_longer}\NormalTok{(atr\_plastics, }\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{wavenumber, }
               \AttributeTok{names\_to =} \StringTok{"sample"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"absorbance"}\NormalTok{)}

\CommentTok{\# head() only prints the first couple of lines}
\FunctionTok{head}\NormalTok{(atr\_long)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   wavenumber sample               absorbance
##        <dbl> <chr>                     <dbl>
## 1       550. EPDM                   0.212   
## 2       550. Polystyrene            0.0746  
## 3       550. Polyethylene           0.000873
## 4       550. Sample: Shopping bag   0.0236  
## 5       551. EPDM                   0.212   
## 6       551. Polystyrene            0.0746
\end{verbatim}

Let's break down the code we've executed via the \texttt{pivot\_longer} function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{cols\ =\ -wavenumber} specifies that we're selecting every other column \emph{but} wave number.

  \begin{itemize}
  \tightlist
  \item
    we could have just as easily specified each column individually using \texttt{cols\ =\ c("EPDM",...)} but it's easier to use \texttt{-} to specify what we \emph{don't} want to select.
  \end{itemize}
\item
  \texttt{names\_to\ =\ "sample"} specifies that the column header (i.e.~names) be converted into an observation under the \texttt{sample} column.
\item
  \texttt{values\_to\ =\ "absorbance"} specifies that the absorbance values under each of the selected headers be placed into the \texttt{aborsbance} column.
\end{enumerate}

Now that we've reclassified out data into the `longer', we can exploit the explicitly introduced \emph{sample} variable to easily plot all of our spectra:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance, }
           \AttributeTok{colour =}\NormalTok{ sample)}
\NormalTok{       ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-88-1.pdf}

We'll talk more about \texttt{ggplot} in the {[}Visualizations{]} chapter, but for now you can see how our code could scale to accommodate any number of different samples, whereas the previous attempt to plot the ``wide'' data would require an explicit call to each column.

\texttt{pivot\_longer} has many other features that you can take advantage of. We highly recommend reading the examples listed on the \href{https://tidyr.tidyverse.org/reference/pivot_longer.html}{pivot\_longer page} to get a better sense of the possibilities. For example it's common to record multiple observations in a single column header, i.e.~\texttt{Chemical\_A\_0\_mM}. We can exploit common naming conventions like this to easily split up these observations as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(example)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   wavelength_nm Chemical_A_0_mM Chemical_A_1_mM Chemical_B_0_mM Chemical_B_1_mM
## 1           488               0               1               2              NA
## 2           572               0               5               7              20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example\_long }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_longer}\NormalTok{(example,}
   \AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"Chemical"}\NormalTok{),}
   \AttributeTok{names\_prefix =} \StringTok{"Chemical\_"}\NormalTok{,}
   \AttributeTok{names\_to =} \FunctionTok{c}\NormalTok{(}\StringTok{"Chemical"}\NormalTok{, }\StringTok{"Concentration"}\NormalTok{, }\StringTok{"Conc\_Units"}\NormalTok{),}
   \AttributeTok{names\_sep =} \StringTok{"\_"}\NormalTok{,}
   \AttributeTok{values\_to =} \StringTok{"Absorbance"}\NormalTok{,}
   \AttributeTok{values\_drop\_na =} \ConstantTok{TRUE}
\NormalTok{ )}

\FunctionTok{head}\NormalTok{(example\_long)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavelength_nm Chemical Concentration Conc_Units Absorbance
##           <dbl> <chr>    <chr>         <chr>           <dbl>
## 1           488 A        0             mM                  0
## 2           488 A        1             mM                  1
## 3           488 B        0             mM                  2
## 4           572 A        0             mM                  0
## 5           572 A        1             mM                  5
## 6           572 B        0             mM                  7
\end{verbatim}

\hypertarget{making-data-wider}{%
\section{Making Data Wider}\label{making-data-wider}}

In data analysis, specific requirements or packages, such as \texttt{matrixStats} and \texttt{matrixTests}, often necessitate reshaping your data into a matrix or `wide' format. The \texttt{pivot\_wider} function from the \texttt{tidyr} package is a robust tool for this transformation, operating as the inverse of the \texttt{pivot\_longer} function we discussed earlier. Essentially, \texttt{pivot\_wider} is used to spread key-value pairs across a dataset, transforming it from a long to a wide format. This is especially useful when you need your data structured in a wide matrix for certain analytical procedures or visual presentations. To learn more about the \texttt{pivot\_wider} function, I recommend reading the documentation \href{https://tidyr.tidyverse.org/reference/pivot_wider.html}{here}.

For example, consider a dataset where we need to compare absorbance data across different samples. With \texttt{pivot\_wider}, we can transform this data so that each sample is represented in its own column. This transformation is executed as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_wide }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_wider}\NormalTok{(atr\_long, }
                        \AttributeTok{names\_from =}\NormalTok{ sample, }
                        \AttributeTok{values\_from =}\NormalTok{ absorbance)}

\CommentTok{\# Viewing the first few lines of the transformed dataset}
\FunctionTok{head}\NormalTok{(atr\_wide)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavenumber  EPDM Polystyrene Polyethylene `Sample: Shopping bag`
##        <dbl> <dbl>       <dbl>        <dbl>                  <dbl>
## 1       550. 0.212      0.0746     0.000873                 0.0236
## 2       551. 0.212      0.0746     0.000834                 0.0238
## 3       551. 0.213      0.0745     0.000819                 0.0239
## 4       552. 0.213      0.0745     0.000825                 0.0239
## 5       552. 0.214      0.0745     0.000868                 0.0240
## 6       553. 0.214      0.0746     0.000949                 0.0240
\end{verbatim}

Here's a breakdown of this code:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{names\_from\ =\ sample}: This argument specifies which column in our long data will be used to create new column headers in the wide format. Each unique value in the \texttt{sample} column becomes a separate column in the resulting wide dataset.
\item
  \texttt{values\_from\ =\ absorbance}: This tells R that the values filling these new sample columns should be taken from the \texttt{absorbance} column.
\end{enumerate}

The result is a more traditional, wide-format dataset where each column represents a different sample's absorbance values, facilitating side-by-side comparisons.

\hypertarget{practical-uses-of-pivot_wider}{%
\subsection{\texorpdfstring{Practical Uses of \texttt{pivot\_wider}}{Practical Uses of pivot\_wider}}\label{practical-uses-of-pivot_wider}}

The \texttt{pivot\_wider} function is not only useful for converting long data to wide but also for data summarization and creating formats suitable for reports or specific analyses. If you're dealing with summarized data, such as averages or counts, spreading this data into a wide format can make it more interpretable and easier to analyze.

Furthermore, \texttt{pivot\_wider} can be an essential part of a more complex data transformation process. In many cases, data manipulation might require alternating between widening and lengthening to achieve the desired structure for your analysis.

Understanding both \texttt{pivot\_longer} and \texttt{pivot\_wider} equips you with a versatile toolkit for shaping your data. Whether you're preparing data for specific package requirements, like \texttt{matrixStats} or \texttt{matrixTests}, or simply need to restructure your dataset for clarity and analysis, these functions are invaluable in the R programming environment.

\hypertarget{further-reading-4}{%
\section{Further reading}\label{further-reading-4}}

As always, the \emph{R for Data Science} book goes into more detail on all of the elements discussed above. For the material covered here you may want to read \href{https://r4ds.had.co.nz/tidy-data.html}{Chapter 9: Tidy Data}.

\hypertarget{exercise-7}{%
\section{Exercise}\label{exercise-7}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{transform-data-manipulation}{%
\chapter{Transform: Data Manipulation}\label{transform-data-manipulation}}

Transformation encompasses any steps you take to manipulate, reshape, refine, or transform your data. We've already touched upon some useful transformation functions in previous example code snippets, such as the \texttt{mutate} function for adding columns. This section will explore some of the most useful functionalities of the \texttt{dplyr} package, explicitly introduce the pipe operator \texttt{\%\textgreater{}\%}, and showcase how you can leverage these tools to quickly manipulate your data.

The essential \texttt{dplyr} functions are :

\begin{itemize}
\tightlist
\item
  \texttt{mutate()} to create new columns/variables from existing data
\item
  \texttt{arrange()} to reorder rows
\item
  \texttt{filter()} to refine observations by their values (in other words by row)
\item
  \texttt{select()} to pick variables by name (in other words by column)
\item
  \texttt{summarize()} to collapse many values down to a single summary.
\end{itemize}

We'll go through each of these functions, but we highly recommend you read \href{https://r4ds.had.co.nz/transform.html}{Chapter 3: Data Transformation} from \emph{R for Data Science} to get a more comprehensive breakdown of these functions. Note that the information here is based on a \texttt{tidyverse} approach, but this is only one way of doing things. Please see the \protect\hyperlink{further-reading}{Further reading} section for links to other suitable approaches to data transformation.

Let's explore the functionality of \texttt{dplyr} using some flame absorption/emission spectroscopy (FAES) data from a \emph{CHM317} lab. This data represents the emission signal of five sodium (Na) standards measured in triplicate:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Importing using tips from Import chapter}
\NormalTok{FAES }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/FAESdata.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# see section on Pipe}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{std\_Na\_conc,}
               \AttributeTok{names\_to =} \StringTok{"replicate"}\NormalTok{, }
               \AttributeTok{names\_prefix =} \StringTok{"reading\_"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"signal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{separate}\NormalTok{(}\AttributeTok{col =}\NormalTok{ std\_Na\_conc,}
           \AttributeTok{into =} \FunctionTok{c}\NormalTok{(}\StringTok{"type"}\NormalTok{, }\StringTok{"conc\_Na"}\NormalTok{, }\StringTok{"units"}\NormalTok{),}
           \AttributeTok{sep =} \StringTok{" "}\NormalTok{,}
           \AttributeTok{convert =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(FAES)}
\end{Highlighting}
\end{Shaded}

\textbf{Note} the use of \texttt{convert\ =\ TRUE} in the \texttt{separate()} call. This runs a type convert on new columns. If we didn't include this, the \texttt{conc\_Na} column would be of type character because the numbers originated from a string. \texttt{convert()} ensures they're converted to numeric. \textbf{Always use \texttt{convert\ =\ TRUE}} when you separate columns.

\hypertarget{selecting-by-row-or-value}{%
\section{Selecting by row or value}\label{selecting-by-row-or-value}}

\texttt{filter()} allows up to subset our data based on observation (row) values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, conc\_Na }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   type  conc_Na units replicate signal
##   <chr>   <dbl> <chr> <chr>      <dbl>
## 1 blank       0 ppm   1           502.
## 2 blank       0 ppm   2           592.
## 3 blank       0 ppm   3           581.
\end{verbatim}

Note how we need to pass logical operations to \texttt{filter()} to specify which rows we want to select. In the above code, we used \texttt{filter()} to get all rows where the concentration of sodium is equal to 0 (\texttt{==\ 0}). Note the presence of two equal signs (\texttt{==}). In R one equal sign (\texttt{=}) is used to pass an argument, two equal signs (\texttt{==}) is the logical operation ``is equal'' and is used to test equality (i.e.~that both sides have the same value). A frequent mistake is to use \texttt{=} instead of \texttt{==} when testing for equality.

\hypertarget{logical-operators}{%
\subsection{Logical operators}\label{logical-operators}}

\texttt{filter()} can use other \emph{relational} and \emph{logical} operators or combinations thereof. Relational operators compare values and logical operators carry out Boolean operations (TRUE or FALSE). Logical operators are used to combine multiple relational operators\ldots{} let's just list what they are and how we can use them:

\begin{tabular}{l|l|l}
\hline
Operator & Type & Description\\
\hline
> & relational & Less than\\
\hline
< & relational & Greater than\\
\hline
<= & relational & Less than or equal to\\
\hline
>= & relational & Greater than or equal to\\
\hline
== & relational & Equal to\\
\hline
!= & relational & Not equal to\\
\hline
\& & logical & AND\\
\hline
! & logical & NOT\\
\hline
| & logical & OR\\
\hline
is.na() & function & Checks for missing values, TRUE if NA\\
\hline
\end{tabular}

\begin{itemize}
\tightlist
\item
  Selecting all signals below a threshold value
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, signal }\SpecialCharTok{\textless{}} \DecValTok{4450}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   type  conc_Na units replicate signal
##   <chr>   <dbl> <chr> <chr>      <dbl>
## 1 blank       0 ppm   1           502.
## 2 blank       0 ppm   2           592.
## 3 blank       0 ppm   3           581.
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Selecting signals between values
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, signal }\SpecialCharTok{\textgreater{}=} \DecValTok{4450} \SpecialCharTok{\&}\NormalTok{ signal }\SpecialCharTok{\textless{}} \DecValTok{8150}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   type     conc_Na units replicate signal
##   <chr>      <dbl> <chr> <chr>      <dbl>
## 1 standard     0.1 ppm   1          5656.
## 2 standard     0.1 ppm   2          5654.
## 3 standard     0.1 ppm   3          5667.
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Selecting all other replicates other than replicate \texttt{2}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, replicate }\SpecialCharTok{!=} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 5
##    type     conc_Na units replicate signal
##    <chr>      <dbl> <chr> <chr>      <dbl>
##  1 blank        0   ppm   1           502.
##  2 blank        0   ppm   3           581.
##  3 standard     0.1 ppm   1          5656.
##  4 standard     0.1 ppm   3          5667.
##  5 standard     0.2 ppm   1          9393.
##  6 standard     0.2 ppm   3          9332.
##  7 standard     0.5 ppm   1         20187.
##  8 standard     0.5 ppm   3         20153.
##  9 standard     1   ppm   1         30798.
## 10 standard     1   ppm   3         30790.
\end{verbatim}

\begin{itemize}
\tightlist
\item
  selecting the first standard replicate OR any of the blanks.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, (type }\SpecialCharTok{==} \StringTok{"standard"} \SpecialCharTok{\&}\NormalTok{ replicate }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{|}\NormalTok{ (type }\SpecialCharTok{==} \StringTok{"blank"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 5
##   type     conc_Na units replicate signal
##   <chr>      <dbl> <chr> <chr>      <dbl>
## 1 blank        0   ppm   1           502.
## 2 blank        0   ppm   2           592.
## 3 blank        0   ppm   3           581.
## 4 standard     0.1 ppm   1          5656.
## 5 standard     0.2 ppm   1          9393.
## 6 standard     0.5 ppm   1         20187.
## 7 standard     1   ppm   1         30798.
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Removing any missing values (\texttt{NA}) using \texttt{is.na()}. Note there are no missing values in our data set so nothing will be removed, if we removed the NOT operator (\texttt{!}) we would have selected all rows \emph{with} missing values.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(FAES, }\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(signal))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 5
##    type     conc_Na units replicate signal
##    <chr>      <dbl> <chr> <chr>      <dbl>
##  1 blank        0   ppm   1           502.
##  2 blank        0   ppm   2           592.
##  3 blank        0   ppm   3           581.
##  4 standard     0.1 ppm   1          5656.
##  5 standard     0.1 ppm   2          5654.
##  6 standard     0.1 ppm   3          5667.
##  7 standard     0.2 ppm   1          9393.
##  8 standard     0.2 ppm   2          9363.
##  9 standard     0.2 ppm   3          9332.
## 10 standard     0.5 ppm   1         20187.
## 11 standard     0.5 ppm   2         20141.
## 12 standard     0.5 ppm   3         20153.
## 13 standard     1   ppm   1         30798.
## 14 standard     1   ppm   2         30837.
## 15 standard     1   ppm   3         30790.
\end{verbatim}

These are just some examples, but you can combine the logical operators in any way that works for you. Likewise, there are multiple combinations that will yield the same result, it's up to you do figure out which works best for you.

\hypertarget{arranging-rows}{%
\section{Arranging rows}\label{arranging-rows}}

\texttt{arrange()} reorders the rows based on the value you passed to it. By default it arranges the specified values into ascending order. Let's arrange our data our data by increasing order of signal value:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{( FAES, signal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 5
##    type     conc_Na units replicate signal
##    <chr>      <dbl> <chr> <chr>      <dbl>
##  1 blank        0   ppm   1           502.
##  2 blank        0   ppm   3           581.
##  3 blank        0   ppm   2           592.
##  4 standard     0.1 ppm   2          5654.
##  5 standard     0.1 ppm   1          5656.
##  6 standard     0.1 ppm   3          5667.
##  7 standard     0.2 ppm   3          9332.
##  8 standard     0.2 ppm   2          9363.
##  9 standard     0.2 ppm   1          9393.
## 10 standard     0.5 ppm   2         20141.
## 11 standard     0.5 ppm   3         20153.
## 12 standard     0.5 ppm   1         20187.
## 13 standard     1   ppm   3         30790.
## 14 standard     1   ppm   1         30798.
## 15 standard     1   ppm   2         30837.
\end{verbatim}

Since our original \texttt{FAES} data is already arranged by increasing \texttt{conc\_Na} and \texttt{replicate}, let's inverse that order by arranging \texttt{conc\_Na} into descending order using the \texttt{desc()} function WHILE arranging the \texttt{signal} values in ascending order:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Note the order of precedence (left{-}to{-}right)}
\FunctionTok{arrange}\NormalTok{(FAES, }\FunctionTok{desc}\NormalTok{(conc\_Na), signal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 5
##    type     conc_Na units replicate signal
##    <chr>      <dbl> <chr> <chr>      <dbl>
##  1 standard     1   ppm   3         30790.
##  2 standard     1   ppm   1         30798.
##  3 standard     1   ppm   2         30837.
##  4 standard     0.5 ppm   2         20141.
##  5 standard     0.5 ppm   3         20153.
##  6 standard     0.5 ppm   1         20187.
##  7 standard     0.2 ppm   3          9332.
##  8 standard     0.2 ppm   2          9363.
##  9 standard     0.2 ppm   1          9393.
## 10 standard     0.1 ppm   2          5654.
## 11 standard     0.1 ppm   1          5656.
## 12 standard     0.1 ppm   3          5667.
## 13 blank        0   ppm   1           502.
## 14 blank        0   ppm   3           581.
## 15 blank        0   ppm   2           592.
\end{verbatim}

Just note with \texttt{arrange()} that \texttt{NA} values will always be placed at the bottom, whether you use \texttt{desc()} or not.

\hypertarget{selecting-column-name}{%
\section{Selecting column name}\label{selecting-column-name}}

\texttt{select()} allows you to readily select columns by name. Note however that it will always return a tibble, even if you only select one variable/column.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(FAES, signal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 1
##    signal
##     <dbl>
##  1   502.
##  2   592.
##  3   581.
##  4  5656.
##  5  5654.
##  6  5667.
##  7  9393.
##  8  9363.
##  9  9332.
## 10 20187.
## 11 20141.
## 12 20153.
## 13 30798.
## 14 30837.
## 15 30790.
\end{verbatim}

You can also select multiple columns using the same operators and helper functions described in \protect\hyperlink{tidying-your-data}{Tidying Your Data}:.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(FAES, conc\_Na}\SpecialCharTok{:}\NormalTok{replicate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 3
##    conc_Na units replicate
##      <dbl> <chr> <chr>    
##  1     0   ppm   1        
##  2     0   ppm   2        
##  3     0   ppm   3        
##  4     0.1 ppm   1        
##  5     0.1 ppm   2        
##  6     0.1 ppm   3        
##  7     0.2 ppm   1        
##  8     0.2 ppm   2        
##  9     0.2 ppm   3        
## 10     0.5 ppm   1        
## 11     0.5 ppm   2        
## 12     0.5 ppm   3        
## 13     1   ppm   1        
## 14     1   ppm   2        
## 15     1   ppm   3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Getting columns containing the character "p"}
\FunctionTok{select}\NormalTok{(FAES, }\FunctionTok{contains}\NormalTok{(}\StringTok{"p"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 2
##    type     replicate
##    <chr>    <chr>    
##  1 blank    1        
##  2 blank    2        
##  3 blank    3        
##  4 standard 1        
##  5 standard 2        
##  6 standard 3        
##  7 standard 1        
##  8 standard 2        
##  9 standard 3        
## 10 standard 1        
## 11 standard 2        
## 12 standard 3        
## 13 standard 1        
## 14 standard 2        
## 15 standard 3
\end{verbatim}

\hypertarget{deleting-columns-or-rows}{%
\section{Deleting Columns or Rows}\label{deleting-columns-or-rows}}

While the process of selecting and filtering data is pivotal in data analysis, there are instances when you may need to remove specific columns or rows entirely. This is useful especially when you're dealing with redundant or irrelevant data that might clutter your analysis.

\hypertarget{deleting-columns}{%
\subsection{Deleting columns}\label{deleting-columns}}

To delete a column, you can use the \texttt{select()} function with the \texttt{-} sign before the column name you want to remove:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This will remove the \textquotesingle{}signal\textquotesingle{} column from the FAES dataset}
\FunctionTok{head}\NormalTok{(}\FunctionTok{select}\NormalTok{(FAES, }\SpecialCharTok{{-}}\NormalTok{signal))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##   type     conc_Na units replicate
##   <chr>      <dbl> <chr> <chr>    
## 1 blank        0   ppm   1        
## 2 blank        0   ppm   2        
## 3 blank        0   ppm   3        
## 4 standard     0.1 ppm   1        
## 5 standard     0.1 ppm   2        
## 6 standard     0.1 ppm   3
\end{verbatim}

Multiple columns can be deleted by providing more column names after the \texttt{-} sign:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Deleting both \textquotesingle{}signal\textquotesingle{} and \textquotesingle{}replicate\textquotesingle{} columns from the FAES dataset}
\FunctionTok{head}\NormalTok{(}\FunctionTok{select}\NormalTok{(FAES, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(signal, replicate)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   type     conc_Na units
##   <chr>      <dbl> <chr>
## 1 blank        0   ppm  
## 2 blank        0   ppm  
## 3 blank        0   ppm  
## 4 standard     0.1 ppm  
## 5 standard     0.1 ppm  
## 6 standard     0.1 ppm
\end{verbatim}

\hypertarget{deleting-rows}{%
\subsection{Deleting rows}\label{deleting-rows}}

To delete rows, the \texttt{filter()} function can be used in conjunction with relational or logical conditions that define the rows you wish to exclude:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This will remove rows where \textquotesingle{}signal\textquotesingle{} values are less than 20000}
\FunctionTok{filter}\NormalTok{(FAES, }\SpecialCharTok{!}\NormalTok{(signal }\SpecialCharTok{\textless{}} \DecValTok{20000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   type     conc_Na units replicate signal
##   <chr>      <dbl> <chr> <chr>      <dbl>
## 1 standard     0.5 ppm   1         20187.
## 2 standard     0.5 ppm   2         20141.
## 3 standard     0.5 ppm   3         20153.
## 4 standard     1   ppm   1         30798.
## 5 standard     1   ppm   2         30837.
## 6 standard     1   ppm   3         30790.
\end{verbatim}

The key here is the use of the \texttt{!} (NOT) operator which excludes rows that meet the specified condition.

\hypertarget{adding-new-variables}{%
\section{Adding new variables}\label{adding-new-variables}}

\texttt{mutate()} allows you to add new variable (read columns) to your existing data set. It'll probably be the workhorse function you'll use during your data transformation as you can readily pass other functions and mathematical operators to it to transform your data. let's suppose that our standards were diluted by a factor of 10, we can add a new column for this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(FAES, }\StringTok{"dil\_fct"} \OtherTok{=} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 6
##    type     conc_Na units replicate signal dil_fct
##    <chr>      <dbl> <chr> <chr>      <dbl>   <dbl>
##  1 blank        0   ppm   1           502.      10
##  2 blank        0   ppm   2           592.      10
##  3 blank        0   ppm   3           581.      10
##  4 standard     0.1 ppm   1          5656.      10
##  5 standard     0.1 ppm   2          5654.      10
##  6 standard     0.1 ppm   3          5667.      10
##  7 standard     0.2 ppm   1          9393.      10
##  8 standard     0.2 ppm   2          9363.      10
##  9 standard     0.2 ppm   3          9332.      10
## 10 standard     0.5 ppm   1         20187.      10
## 11 standard     0.5 ppm   2         20141.      10
## 12 standard     0.5 ppm   3         20153.      10
## 13 standard     1   ppm   1         30798.      10
## 14 standard     1   ppm   2         30837.      10
## 15 standard     1   ppm   3         30790.      10
\end{verbatim}

We can also create multiple columns in the same \texttt{mutate()} call:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(FAES, }
       \AttributeTok{dil\_fct =} \DecValTok{10}\NormalTok{, }
       \AttributeTok{adj\_signal =}\NormalTok{ signal }\SpecialCharTok{*}\NormalTok{ dil\_fct)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 7
##    type     conc_Na units replicate signal dil_fct adj_signal
##    <chr>      <dbl> <chr> <chr>      <dbl>   <dbl>      <dbl>
##  1 blank        0   ppm   1           502.      10      5023.
##  2 blank        0   ppm   2           592.      10      5918.
##  3 blank        0   ppm   3           581.      10      5815.
##  4 standard     0.1 ppm   1          5656.      10     56563.
##  5 standard     0.1 ppm   2          5654.      10     56536.
##  6 standard     0.1 ppm   3          5667.      10     56674.
##  7 standard     0.2 ppm   1          9393.      10     93934.
##  8 standard     0.2 ppm   2          9363.      10     93627.
##  9 standard     0.2 ppm   3          9332.      10     93320.
## 10 standard     0.5 ppm   1         20187.      10    201869.
## 11 standard     0.5 ppm   2         20141.      10    201405.
## 12 standard     0.5 ppm   3         20153.      10    201530.
## 13 standard     1   ppm   1         30798.      10    307977.
## 14 standard     1   ppm   2         30837.      10    308365.
## 15 standard     1   ppm   3         30790.      10    307898.
\end{verbatim}

Couple of things to note:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The variable we're creating needs to be in quotation marks, hence \texttt{dil\_fct} for our dilution factor variable
\item
  The variables we're referencing do not need to be in quotation marks; hence \texttt{signal} because this variable already exist.
\item
  Note the order of precedence: \texttt{dil\_fct} is created first so we can reference in the second argument, we would get an error if we swapped the order.
\end{enumerate}

\hypertarget{mutate-with-a-condition}{%
\subsection{Mutate with a condition}\label{mutate-with-a-condition}}

In data analysis, there are often scenarios where we want to categorize or re-label values based on certain conditions. The \texttt{case\_when()} function, provided by the \texttt{dplyr} package, offers a versatile and readable solution for handling these multiple conditions.

The syntax for \texttt{case\_when()} is straightforward: for each condition, you specify the logical test followed by the tilde (\textasciitilde) operator, and then the value or expression to return if the condition is \texttt{TRUE}.

With our FAES data, say you want to label each \texttt{conc\_Na} as ``Low'', ``Medium'', or ``High'' based on its value. You can use \texttt{case\_when()} within \texttt{mutate()} as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(FAES, }
       \AttributeTok{conc\_Na\_level =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{         conc\_Na }\SpecialCharTok{\textless{}} \FloatTok{0.2} \SpecialCharTok{\textasciitilde{}} \StringTok{"Low"}\NormalTok{,}
\NormalTok{         conc\_Na }\SpecialCharTok{\textless{}} \FloatTok{0.4} \SpecialCharTok{\textasciitilde{}} \StringTok{"Medium"}\NormalTok{,}
         \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \StringTok{"High"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 6
##    type     conc_Na units replicate signal conc_Na_level
##    <chr>      <dbl> <chr> <chr>      <dbl> <chr>        
##  1 blank        0   ppm   1           502. Low          
##  2 blank        0   ppm   2           592. Low          
##  3 blank        0   ppm   3           581. Low          
##  4 standard     0.1 ppm   1          5656. Low          
##  5 standard     0.1 ppm   2          5654. Low          
##  6 standard     0.1 ppm   3          5667. Low          
##  7 standard     0.2 ppm   1          9393. Medium       
##  8 standard     0.2 ppm   2          9363. Medium       
##  9 standard     0.2 ppm   3          9332. Medium       
## 10 standard     0.5 ppm   1         20187. High         
## 11 standard     0.5 ppm   2         20141. High         
## 12 standard     0.5 ppm   3         20153. High         
## 13 standard     1   ppm   1         30798. High         
## 14 standard     1   ppm   2         30837. High         
## 15 standard     1   ppm   3         30790. High
\end{verbatim}

For those interested in exploring further, there's a similar function called \texttt{ifelse()} which provides conditional transformations in R. You can learn more about it \href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/ifelse}{here}.

\hypertarget{useful-mutate-function}{%
\subsection{Useful mutate function}\label{useful-mutate-function}}

There are a myriad of functions you can make use of with the mutate function. Here are some of the mathematical operators available in R:

\begin{tabular}{l|l}
\hline
Operator.Function & Definition\\
\hline
+ & additon\\
\hline
- & subtraction\\
\hline
* & multiplication\\
\hline
/ & division\\
\hline
\textasciicircum{} & exponent; to the power of...\\
\hline
log() & returns the specified base-log; see also log10() and log2()\\
\hline
\end{tabular}

\hypertarget{group-and-summarize-data}{%
\section{Group and summarize data}\label{group-and-summarize-data}}

\texttt{summarize} effectively summarized your data based on functions you've passed to it. Looking at our \texttt{FAES} data we'd probably want the mean of the triplicate signals, alongside the standard deviation. Let's see what happens when we apply the summarize function straight up:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(FAES, }\StringTok{"mean"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(signal), }\StringTok{"stdDev"} \OtherTok{=} \FunctionTok{sd}\NormalTok{(signal))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##     mean stdDev
##    <dbl>  <dbl>
## 1 13310. 11242.
\end{verbatim}

This doesn't look like what we wanted. What we got was the mean and standard deviation of \emph{all} of the signals, regardless of the concentration of the standard. Also note how we've lost the other columns/variables and are only left with the mean and stdDev. This is all because we need to \textbf{group} our observations by a variable. We can do this by using the \texttt{group\_by()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groupedFAES }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(FAES, type, conc\_Na)}
\FunctionTok{summarise}\NormalTok{(groupedFAES, }\StringTok{"mean"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(signal), }\StringTok{"stdDev"} \OtherTok{=} \FunctionTok{sd}\NormalTok{(signal))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'type'. You can override using the
## `.groups` argument.
\end{verbatim}

\begin{verbatim}
## # A tibble: 5 x 4
## # Groups:   type [2]
##   type     conc_Na   mean stdDev
##   <chr>      <dbl>  <dbl>  <dbl>
## 1 blank        0     559.  48.9 
## 2 standard     0.1  5659.   7.34
## 3 standard     0.2  9363.  30.7 
## 4 standard     0.5 20160.  24.0 
## 5 standard     1   30808.  25.0
\end{verbatim}

Here we've created a new data set, \texttt{groupedFAES}, that we grouped by the variables \texttt{type} and \texttt{conc\_Na} so we could get the mean and standard deviation of each group. Note the multiple levels of grouping. For this data set we could have omitted the \texttt{type} variable, but in larger datasets you may have multiple groupings (i.e.~from different location), so you can group by multiple variables to get smaller groups.

\hypertarget{useful-summarize-functions}{%
\subsection{Useful summarize functions}\label{useful-summarize-functions}}

We've used the \texttt{mean()} and \texttt{sd()} functions above, but there are a host of other useful functions you can use in conjunction with summarize. See \textbf{Useful Functions} in the \texttt{summarise()} documentation (enter \texttt{?summarise}) in the console. This is also discussed at in more depth in the \protect\hyperlink{summarizing-data}{Summarizing Data} chapter.

\hypertarget{the-pipe-chaining-functions-together}{%
\section{The pipe: chaining functions together}\label{the-pipe-chaining-functions-together}}

With the tools presented here we could do a decent job analyzing our \texttt{FAES} data. Let's say we wanted to subtract the mean of the \texttt{blank} from each \texttt{standard} signal and then get summarize those results. It would look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{blank }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(FAES, type }\SpecialCharTok{==} \StringTok{"blank"}\NormalTok{)}
\NormalTok{meanBlank }\OtherTok{\textless{}{-}} \FunctionTok{summarize}\NormalTok{(blank, }\FunctionTok{mean}\NormalTok{(signal))}
\NormalTok{meanBlank }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(meanBlank)}

\FunctionTok{paste}\NormalTok{(}\StringTok{"The mean signal from the blank triplicate is:"}\NormalTok{, meanBlank)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The mean signal from the blank triplicate is: 558.5249"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stds\_1 }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(FAES, type }\SpecialCharTok{==} \StringTok{"standard"}\NormalTok{)}
\NormalTok{stds\_2 }\OtherTok{\textless{}{-}} \FunctionTok{mutate}\NormalTok{(stds\_1, }\StringTok{"cor\_sig"} \OtherTok{=}\NormalTok{ signal }\SpecialCharTok{{-}}\NormalTok{ meanBlank)}
\NormalTok{stds\_3 }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(stds\_2, conc\_Na)}
\NormalTok{stds\_4 }\OtherTok{\textless{}{-}} \FunctionTok{summarize}\NormalTok{(stds\_3, }\StringTok{"mean"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(cor\_sig), }\StringTok{"stdDev"} \OtherTok{=} \FunctionTok{sd}\NormalTok{(cor\_sig))}
\NormalTok{stds\_4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 3
##   conc_Na   mean stdDev
##     <dbl>  <dbl>  <dbl>
## 1     0.1  5101.   7.34
## 2     0.2  8804.  30.7 
## 3     0.5 19602.  24.0 
## 4     1   30249.  25.0
\end{verbatim}

While the code above did it's job, it's certainly wasn't easy to type and certainly not easy to read. At every step of the way we've saved our updated data outputs to a new variable (\texttt{stds\_1}, \texttt{stds\_2}, etc.). However, most of these intermediates aren't important, and moreover the repetitive names clutter our code. As the code above is written, we've had to pay special attending to the variable suffix to make sure we're calling the correct data set as our code has progresses. An alternative would be to reassign the outputs back to the original variable name (i.e.~\texttt{stds\_1\ \textless{}-\ mutate(stds\_1,\ ...)}), but that doesn't solve the issue of readability as there's still redundant assigning.

A solution for this is the pipe operator \texttt{\%\textgreater{}\%} ( pronounced as ``then''), an incredibly useful tool for writing more legible and understandable code. The pipe basically changes how you read code to emphasize the functions you're working with by passing the intermediate steps to hidden processes in the background. Re-writing the code above, we'd get something like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meanBlank }\OtherTok{\textless{}{-}}\NormalTok{ FAES }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(type }\SpecialCharTok{==}\StringTok{"blank"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\FunctionTok{mean}\NormalTok{(signal)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.numeric}\NormalTok{()}

\FunctionTok{paste}\NormalTok{(}\StringTok{"The mean signal from the blank triplicate is:"}\NormalTok{, meanBlank)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The mean signal from the blank triplicate is: 558.5249"
\end{verbatim}

Things may look a bit different, but our underlying code hasn't changed much. What's happening is the pipe operator passes the output to the first argument of the next function. So the output of \texttt{filter...} is passed to the first argument of \texttt{sumamrise...}, and the argument we specified in \texttt{summarise} is actually the \emph{second} argument it receives. You're probably wondering how hiding stuff makes your code more legible, but think of \texttt{\%\textgreater{}\%} as being equivalent to ``then''. We can read our code as:

\begin{quote}
``Take the \texttt{FAES} dataset, \emph{then} filter for \texttt{type\ ==\ "blank"} \emph{then} collapse the dataset to the mean \texttt{signal} value and \emph{then} convert to numeric value \emph{then} pass this final output to the new variable \texttt{meanBlank}.''
\end{quote}

Not only is the pipe less typing, but the emphasis is on the functions so you can better understand what you're doing vs.~where all the intermediates are going. Extending our piping to the second batch of code we get:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stds }\OtherTok{\textless{}{-}}\NormalTok{ FAES }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(type }\SpecialCharTok{==} \StringTok{"standard"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\StringTok{"cor\_sig"} \OtherTok{=}\NormalTok{ signal }\SpecialCharTok{{-}}\NormalTok{ meanBlank) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(conc\_Na) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\StringTok{"mean"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(cor\_sig), }\StringTok{"stdDev"} \OtherTok{=} \FunctionTok{sd}\NormalTok{(cor\_sig))}

\NormalTok{stds}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 3
##   conc_Na   mean stdDev
##     <dbl>  <dbl>  <dbl>
## 1     0.1  5101.   7.34
## 2     0.2  8804.  30.7 
## 3     0.5 19602.  24.0 
## 4     1   30249.  25.0
\end{verbatim}

Same thing. The underlying code hasn't changed much, but it's much more legible and we can clearly see we're subtracting the \texttt{meanBlank} value from each measured signal then summarizing the corrected signals.

\hypertarget{notes-on-piping}{%
\subsection{Notes on piping}\label{notes-on-piping}}

The pipe is great and especially useful with \emph{tidyverse} packages, but it does have some limitations:

\begin{itemize}
\tightlist
\item
  You can't easily extract intermediate steps. So you'll need to break up your pipping chain to output any intermediate steps you can.
\item
  The benefit of piping is legibility; this goes away as you increase the number of steps as you lose track of what's going on. Keep the piping short and thematically similar.
\item
  Pipes are linear, if you have multiple inputs or outputs you should consider an alternative approach.
\end{itemize}

\hypertarget{further-reading-5}{%
\section{Further reading}\label{further-reading-5}}

\begin{itemize}
\tightlist
\item
  \href{https://r4ds.had.co.nz/transform.html}{Chapter 5: Data Transformation} of \emph{R for Data Science} for a deeper breakdown of \texttt{dplyr} and it's functionality.
\item
  \href{https://r4ds.had.co.nz/pipes.html}{Chapter 18: Pipes} of \emph{R for Data Science} for more information on pipes.
\item
  \href{https://tavareshugo.github.io/data_carpentry_extras/base-r_tidyverse_equivalents/base-r_tidyverse_equivalents.html}{Syntax equivalents: base R vs Tidyverse} by Hugo Taveres for a comparison of base-R solutions to tidyverse. This entire book is largely biased towards tidyverse solutions, but there's no denying that certain base-R can be more elegant. Check out this write up to get a better idea.
\end{itemize}

\hypertarget{exercise-8}{%
\section{Exercise}\label{exercise-8}}

There is a set of exercises available for this chapter!

\textbf{Not sure how to access and work on the exercise Rmd files? }

\begin{itemize}
\item
  Refer to Chapter 3.3 for step-by-step instructions on accessing the exercises and working within the UofT JupyterHub's RStudio environment.
\item
  Alternatively, if you'd like to simply access the individual files, you can download them directly from this \href{https://github.com/UofTChem-Teaching/R4EnvChem-Exercises}{repository}.
\end{itemize}

Always remember to save your progress regularly and consult the textbook's guidelines for submitting your completed exercises.

\hypertarget{ggplot-basic-visualizations}{%
\chapter{ggplot basic visualizations}\label{ggplot-basic-visualizations}}

\texttt{ggplot2} is loaded by default with the \texttt{tidyverse} suite of packages. Let's revisit our spectroscopy data we encountered in \protect\hyperlink{tidying-your-data}{Tidying your data}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\NormalTok{atr\_long }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ATR\_plastics.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{wavenumber, }
               \AttributeTok{names\_to =} \StringTok{"sample"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"absorbance"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 7157 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## dbl (5): wavenumber, EPDM, Polystyrene, Polyethylene, Sample: Shopping bag
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First 50 rows of data}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(atr\_long[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\hypertarget{building-plots-ups}{%
\section{Building plots ups}\label{building-plots-ups}}

The \texttt{gg} in \texttt{ggplot2} stands for the \emph{grammar of graphics},(H. Wickham 2009) and it's a way to break down graphics (plots) into small pieces that can be discussed (hence grammar). We'll take a look at this grammar via \texttt{geoms} (what kind of plot), \texttt{aes} (aesthetic choices), etc. For now, understand that this means we need to build up graphics/plots piece-by-piece and layer-by-layer. This extends beyond code to how we code. No sense in putting lipstick on a pig. Plot often, and discard the useless ones. Take the time to pretty up your plot \emph{after} you're satisfied with the underlying data.

\hypertarget{basic-plotting}{%
\section{Basic plotting}\label{basic-plotting}}

\texttt{ggplot2} uses \texttt{geoms} to specify what type of plot to create. Different plots are used to tell different stories and have different strengths and weakness. We'll explore these more in \protect\hyperlink{visualizations-for-env-chem}{Visualizations for Env Chem}, but for now we'll focus on \texttt{geom\_point()}, which simply plots data as points on an {[}x,y{]} coordinate. In other words, a scatter plot.

Let's plot our tided \texttt{atr\_long} data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }\AttributeTok{y =}\NormalTok{ absorbance)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-120-1.pdf}

Let's ignore the plot for now and look at our code down:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{ggplot()} initializes a \emph{ggplot object}, basically an empty plot.
\item
  We then specified we want to plot data from our \texttt{atr\_long} dataset (\texttt{data\ =\ atr\_long}).
\item
  We then specified our \emph{aesthetic mappings} via \texttt{aes()}. Here we'll pass information for how we want the plot to look.
\item
  To our aesthetic mappings we've specified which values from \texttt{atr\_long} are supposed to be our x-axis values (\texttt{x\ =\ wavenumber}) and y-axis values (\texttt{y\ =\ absorbance}).
\item
  We then add the \texttt{geom\_point()} layer to create a scatter plot of {[}x,y{]} points .
\end{enumerate}

Now let's look at our result. What we see is a point for every recorded absorbance measurements from our ATR analysis. We can clearly see the spectra of the different plastics in our data, however they're all coloured the same. This is because we've only specified the x and y values. As far as \texttt{ggplot()} is concerned, these are the only values that matter, but we know different.

Fortunately you can pass multiple variables to different \texttt{aes()} options to enhance our plot. For instance, we can pass the \texttt{sample} variable, which specifies which sample a spectrum originates from, to the \texttt{colour} option:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance, }
           \AttributeTok{colour =}\NormalTok{ sample)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-121-1.pdf}

Now we have a legend which clearly specifies which points are associated with each sample. But now the points are too large, potentially masking certain peaks. We can adjust the size of each point as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance, }
           \AttributeTok{colour =}\NormalTok{ sample)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-122-1.pdf}

We specified \texttt{size\ =\ 0.5} in the \texttt{geom\_point()} call because it's a constant. We can map \texttt{size} to any continuous variable, such as the absorbance:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance, }
           \AttributeTok{colour =}\NormalTok{ sample,}
           \AttributeTok{size =}\NormalTok{ absorbance)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-123-1.pdf}

Sometimes this makes sense (i.e.~a \emph{bubble chart}) but for our example, having the size of the points increase as the absorbance increases doesn't provide any new information (it actually clutters our plot).

\hypertarget{changing-plot-labels}{%
\section{Changing plot labels}\label{changing-plot-labels}}

By default \texttt{ggplot} uses the header of the columns you passed for the \texttt{x} and \texttt{y} \texttt{aes()} options. Because headers are written for code they're often poor label titles for plots. We can specify new labels and plot titles as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance, }
           \AttributeTok{colour =}\NormalTok{ sample)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"ATR Spetra"}\NormalTok{,}
       \AttributeTok{subtitle =} \StringTok{"Courtesy of CHM317 student data"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Wavenumber, cm\^{}{-}1"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Absorbance (arbitrary units)"}\NormalTok{,}
       \AttributeTok{caption =} \StringTok{"hi mom"}\NormalTok{,}
       \AttributeTok{colour =} \StringTok{"Plastic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-124-1.pdf}

Note how we changed the title of the legend with \texttt{colour\ =\ "Plastics"}. This is because the legend is generated from our colour aesthetic (\texttt{aes(...,\ colour\ =\ sample)}). If our legend was based off of the size aesthetic, we would use \texttt{size\ =\ "New\ Title"} to change the title for the size legend.

\hypertarget{small-multiples}{%
\section{Small Multiples}\label{small-multiples}}

Sometimes your plots become overwhelming, a phenomena called overplotting, which prevent your from comparing graphs or charts. A popular solution is \href{https://en.wikipedia.org/wiki/Small_multiple}{\emph{small multiples}}, a series of smilar plots using the same scale and axes. This is readily accomplished in R using \href{https://ggplot2-book.org/facet.html}{\texttt{facet\_grid()}} (which creates a 2-D grid ) or \href{https://ggplot2-book.org/facet.html}{\texttt{facet\_wrap()}} (a single 1d ribbon wrapped into 2D space). You simply specy which variable you want to differentiate your plots, for us it's \texttt{sample}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atr\_long, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sample)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-125-1.pdf}

Note the use of the tilde (\texttt{\textasciitilde{}}) in \texttt{facet\_wrap(\textasciitilde{}sample)}; in this situation, it's shorthand telling \texttt{facet\_wrap()} to make small multiples off of the sample variable.

\hypertarget{plotting-subsets-of-data}{%
\section{Plotting subsets of data}\label{plotting-subsets-of-data}}

Often you won't want to plot everything in your dataset. Rather, you'll want to plot a specific chemical, city, location, etc. To that end you want to plot a \emph{subset} of your data. There are a couple of ways to handle this.

You can subset your data on the fly using \texttt{subset()}. This way allows you to specify based off of \protect\hyperlink{logical-operators}{Logical operators} as such:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(atr\_long, sample }\SpecialCharTok{==} \StringTok{"EPDM"}\NormalTok{),}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-126-1.pdf}

or

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(atr\_long, wavenumber }\SpecialCharTok{\textgreater{}=}\DecValTok{2500}\NormalTok{),}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }
           \AttributeTok{y =}\NormalTok{ absorbance)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-127-1.pdf}

Another approach is to use \texttt{filter()} and pipe to \texttt{ggplot()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atr\_long }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(sample }\SpecialCharTok{!=} \StringTok{"EPDM"} \SpecialCharTok{\&}\NormalTok{ wavenumber }\SpecialCharTok{\textless{}=} \DecValTok{2500} \SpecialCharTok{|}\NormalTok{sample }\SpecialCharTok{==} \StringTok{"EPDM"} \SpecialCharTok{\&}\NormalTok{ wavenumber }\SpecialCharTok{\textgreater{}=} \DecValTok{3500}\NormalTok{ ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(., }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavenumber, }\AttributeTok{y =}\NormalTok{ absorbance, }\AttributeTok{colour =}\NormalTok{ sample)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-128-1.pdf}

There are pros and cons to either approach. \texttt{subset()} on the fly is best for simple task, like plotting a single city, whereas the piping approach is best for more complex sorting.

\hypertarget{summarizing-data}{%
\chapter{Summarizing Data}\label{summarizing-data}}

Summarizing data is what it sounds like. You're reducing the number of rows in your dataset based on some predetermined method. Taking the average of a group of numbers is summarizing the data. Many numbers have been condensed to one: the average. In this chapter we'll go over summarizing data, and some aesthetic changes we can make for publication ready tables.

\hypertarget{data-to-play-with}{%
\section{Data to play with}\label{data-to-play-with}}

We'll take a look at the 2018 hourly mean NO\textsubscript{2} concentrations for the Atlantic provinces (New Brunswick, Prince Edward Island, Nova Scotia, and Newfoundland). The dataset is available in the \href{https://github.com/DavidRossHall/R4EnvChem-ProjectTemplate}{\emph{R4EnvChem} Project Template} repository. Also if you're keen, you can download any number of atmospheric datasets from \emph{Environment and Climate Change Canada}'s (ECCC) National Airborne Pollution Program's (NAPS) website \href{https://data.ec.gc.ca/data/air/monitor/national-air-pollution-surveillance-naps-program/Data-Donnees/?lang=en}{here}

Since ECCC stores their NAPS data in a matrix layout, we need to briefly tidy it up:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atlNO2 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/2018hourlyNO2\_Atl.csv"}\NormalTok{, }\AttributeTok{skip =} \DecValTok{7}\NormalTok{, }\AttributeTok{na =}\FunctionTok{c}\NormalTok{(}\StringTok{"{-}999"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename\_with}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{tolower}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"/.*"}\NormalTok{, }\StringTok{""}\NormalTok{, .x))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"h"}\NormalTok{), }
               \AttributeTok{names\_prefix =} \StringTok{"h"}\NormalTok{, }
               \AttributeTok{names\_to =} \StringTok{"hour"}\NormalTok{, }
               \AttributeTok{names\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{hour =}\NormalTok{ as.numeric),}
               \AttributeTok{values\_to =} \StringTok{"conc"}\NormalTok{, }
               \AttributeTok{values\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{conc =}\NormalTok{ as.numeric),}
               \AttributeTok{values\_drop\_na =} \ConstantTok{TRUE}\NormalTok{) }

\CommentTok{\# First 50 rows of dataset}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(atlNO2[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

Note in our dataset that both Halifax NS and Saint John NB have three NAPS stations each. It won't matter for our aggregation, but if we were exploring this data in more depth this is something we would want to take into account.

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-130-1.pdf}

\hypertarget{summarizing-data-by-group}{%
\section{Summarizing data by group}\label{summarizing-data-by-group}}

While we can readily summarize an entire dataset, we often want to summarize \emph{groups} within our dataset. In our case, it's {[}NO\textsubscript{2}{]} in each city. To this end, we need to combine the\texttt{group\_by()} and \texttt{summarize()} functions. \texttt{summarise()} also works for the Americans. This approach allows us to (1) specify which groups we want summarized, and (2) how we want them summarized. We'll talk more about point (2) later on, for now, let's look at point (1)

Let's calculate the mean hourly NO\textsubscript{2} concentrations in the 4 provinces in our dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumAtl }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(p) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(conc))}

\NormalTok{sumAtl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   p      mean
##   <chr> <dbl>
## 1 NB    2.86 
## 2 NL    2.30 
## 3 NS    2.36 
## 4 PE    0.975
\end{verbatim}

That's it. 186339 unique rows summarized like that. Note that \texttt{summarize} produces a \emph{new} data frame, so you'll want to double check on the outputted data types. Let's break down what our code does:

\begin{itemize}
\tightlist
\item
  We're creating a new data frame, so we store it in \texttt{sumAtl}.
\item
  We then take our \texttt{atlNO2} dataset and group our dataset by province using \texttt{group\_by(p)}.
\item
  We then summarize our grouped data by summarizing the NO\textsubscript{2} concentration with \texttt{summarize(mean\ =\ mean(conc)}.

  \begin{itemize}
  \tightlist
  \item
    Note that since we're creating a new data set, we need to create new columns. This is what \texttt{mean\ =\ mean(conc)} does. We're creating a column \emph{called mean}, which contains the \emph{numerical mean} 1-hr NO\textsubscript{2} values which were calculated using the \texttt{mean()} function. Simple\ldots{}
  \end{itemize}
\end{itemize}

Let's dig a little deeper. The \href{https://ccme.ca/en/air-quality-report}{\emph{Canadian Ambient Air Quality Standards}} stipulates that the annual mean of 1-hour means for NO\textsubscript{2} cannot exceed 17.0 ppb in 2020, and 12.0 ppb in 2025. Let's see if any city in our dataset violated these standards in 2018.

To do this, we'll group by province (\texttt{p}) and city (\texttt{city}). This will retain our provinces column that we might want to use later on.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumAtl }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(p, city) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(conc))}

\NormalTok{sumAtl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 19 x 3
## # Groups:   p [4]
##    p     city                 mean
##    <chr> <chr>               <dbl>
##  1 NB    Bathurst            1.21 
##  2 NB    Edmundston          4.52 
##  3 NB    Fredericton         1.82 
##  4 NB    Moncton             3.37 
##  5 NB    Saint John          3.02 
##  6 NL    Corner Brook        2.71 
##  7 NL    Grand Falls-Windsor 0.918
##  8 NL    Labrador City       2.51 
##  9 NL    Marystown           0.277
## 10 NL    Mount Pearl         1.53 
## 11 NL    St Johns            5.33 
## 12 NS    Halifax             3.44 
## 13 NS    Kentville           0.841
## 14 NS    Pictou              1.19 
## 15 NS    Port Hawkesburry    2.53 
## 16 NS    Sydney              2.66 
## 17 PE    Charlottetown       1.85 
## 18 PE    Southampton         0.512
## 19 PE    Wellington          0.455
\end{verbatim}

Looks like there aren't any offenders. For tips on visualizing these results please see the {[}Visualizations{]} chapter.

\hypertarget{further-summarize-operations}{%
\subsection{Further summarize operations}\label{further-summarize-operations}}

There are other options we can use to summarize out data. A handy list is provided on the \href{https://dplyr.tidyverse.org/reference/summarise.html}{\texttt{summarize()} help page}. The most common ones you'll need are:

\begin{itemize}
\tightlist
\item
  \texttt{mean()} which calculates the arithmetic mean, a.k.a. the average.
\item
  \texttt{median()} which calculates the sample median, the value separating the higher 50\% of data from the lower 50\% of a data sample.
\item
  \texttt{sd()} which calculates the sample standard deviation.
\item
  \texttt{min()} and \texttt{max()} which returns the smallest and largest value in the dataset.
\item
  \texttt{n()} which provides the number of entries in a group. Note you don't specify a variable for n.~
\end{itemize}

Let's seem them in action:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumAtl }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(p, city) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(conc),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(conc),}
            \AttributeTok{min =} \FunctionTok{min}\NormalTok{(conc), }
            \AttributeTok{max =} \FunctionTok{max}\NormalTok{(conc), }
            \AttributeTok{n =} \FunctionTok{n}\NormalTok{())}

\NormalTok{sumAtl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 19 x 7
## # Groups:   p [4]
##    p     city                 mean    sd   min   max     n
##    <chr> <chr>               <dbl> <dbl> <dbl> <dbl> <int>
##  1 NB    Bathurst            1.21  1.91      0    27  8755
##  2 NB    Edmundston          4.52  4.82      0    45  8756
##  3 NB    Fredericton         1.82  4.04      0    39  8729
##  4 NB    Moncton             3.37  4.71      0    39  8749
##  5 NB    Saint John          3.02  4.04      0    41 26051
##  6 NL    Corner Brook        2.71  2.47      0    28  8505
##  7 NL    Grand Falls-Windsor 0.918 1.26      0    27  7746
##  8 NL    Labrador City       2.51  4.05      0    46  8612
##  9 NL    Marystown           0.277 0.635     0    11  7142
## 10 NL    Mount Pearl         1.53  2.82      0    68  8522
## 11 NL    St Johns            5.33  6.14      0    49  8670
## 12 NS    Halifax             3.44  4.19      0    39 17591
## 13 NS    Kentville           0.841 1.22      0    20  8640
## 14 NS    Pictou              1.19  1.52      0    20  8515
## 15 NS    Port Hawkesburry    2.53  4.29      0    59  8601
## 16 NS    Sydney              2.66  2.93      0    37  8675
## 17 PE    Charlottetown       1.85  2.87      0    35  8690
## 18 PE    Southampton         0.512 0.683     0    16  6799
## 19 PE    Wellington          0.455 0.747     0     9  8591
\end{verbatim}

Note that the functions we pass to summarize adhere to rules of missing values. That is to say, if even one value in a group is an \texttt{NA}, the entire group defaults to \texttt{NA}. Consequently, if your confident this isn't an issue, you can pass the argument \texttt{na.rm\ =\ TRUE} to any of the summarize functions, which would look like \texttt{mean\ =\ mean(conc,\ na.rm\ =\ TRUE)}. This will ignore any \texttt{NA} values and return a numeric value like you probably expect.

\hypertarget{pretty-tables-with-flextable}{%
\section{Pretty tables with flextable}\label{pretty-tables-with-flextable}}

While the summarize function does an excellent job of summarizing our data, the outputted dataset isn't really fit for publication. This is doubly so if you used summarize as the last step of your chemical quantification and you want a nice and pretty table of mean sample concentration with standard deviations.

To this end we'll use the `flextable' package. Please refer to \href{https://davidgohel.github.io/flextable/index.html}{flextable R package}. There are other packages to make tables, but we're using \texttt{flextable} as it's consistent between HTML and PDF outputs.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(flextable)}

\FunctionTok{flextable}\NormalTok{(sumAtl)}
\end{Highlighting}
\end{Shaded}

\global\setlength{\Oldarrayrulewidth}{\arrayrulewidth}

\global\setlength{\Oldtabcolsep}{\tabcolsep}

\setlength{\tabcolsep}{0pt}

\renewcommand*{\arraystretch}{1.5}



\providecommand{\ascline}[3]{\noalign{\global\arrayrulewidth #1}\arrayrulecolor[HTML]{#2}\cline{#3}}

\begin{longtable}[c]{|p{0.75in}|p{0.75in}|p{0.75in}|p{0.75in}|p{0.75in}|p{0.75in}|p{0.75in}}



\ascline{1.5pt}{666666}{1-7}

\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{p}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{city}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{mean}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{sd}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{min}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{max}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{n}}}} \\

\ascline{1.5pt}{666666}{1-7}\endfirsthead 

\ascline{1.5pt}{666666}{1-7}

\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{p}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{city}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{mean}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{sd}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{min}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{max}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{n}}}} \\

\ascline{1.5pt}{666666}{1-7}\endhead



\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Bathurst}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.2133638}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.9068865}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{27}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,755}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Edmundston}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.5189584}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.8193387}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{45}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,756}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Fredericton}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.8243785}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.0444904}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,729}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Moncton}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.3702137}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.7126128}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,749}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Saint\ John}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.0226479}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.0382273}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{41}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{26,051}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Corner\ Brook}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.7084068}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.4696380}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{28}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,505}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Grand\ Falls-Windsor}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.9175058}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.2614504}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{27}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{7,746}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Labrador\ City}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.5062703}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.0540802}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{46}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,612}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Marystown}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.2766732}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.6349850}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{11}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{7,142}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Mount\ Pearl}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.5341469}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.8249929}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{68}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,522}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{St\ Johns}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{5.3297578}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{6.1384817}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{49}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,670}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Halifax}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.4383492}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.1871164}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{17,591}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Kentville}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.8410880}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.2186010}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{20}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,640}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Pictou}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.1937757}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.5180486}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{20}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,515}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Port\ Hawkesburry}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.5254040}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.2856534}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{59}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,601}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Sydney}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.6610951}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.9300039}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{37}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,675}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Charlottetown}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.8513234}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.8669404}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{35}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,690}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Southampton}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.5115458}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.6831778}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{16}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{6,799}}}} \\





\multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{\raggedright}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Wellington}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.4554767}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.7471108}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{9}}}} & \multicolumn{1}{>{\raggedleft}m{\dimexpr 0.75in+0\tabcolsep}}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{8,591}}}} \\

\ascline{1.5pt}{666666}{1-7}



\end{longtable}



\arrayrulecolor[HTML]{000000}

\global\setlength{\arrayrulewidth}{\Oldarrayrulewidth}

\global\setlength{\tabcolsep}{\Oldtabcolsep}

\renewcommand*{\arraystretch}{1}

Perhaps that isn't pretty enough for you. Doubtlessly your instructor will tell you to combine the mean and standard deviation into one value (i.e.~\(mean \pm sd\)). We'll do this in two steps.

\begin{itemize}
\tightlist
\item
  Step 1: Use \texttt{unite()} to merge the \texttt{mean} and \texttt{sd} values together rowise; values will be separated by ±.

  \begin{itemize}
  \tightlist
  \item
    ± is a legit symbol, try \texttt{Alt+241}or copy and paste it from this book.
  \end{itemize}
\item
  Step 2: Pretty up our table to significant digits, and perform some aesthetic changes.
\end{itemize}

\hypertarget{uniting-columns}{%
\subsection{Uniting columns}\label{uniting-columns}}

Firstly, our \texttt{mean} and \texttt{sd} columns contain way too many decimal places. We'll need to round them down before we use \texttt{unite()} to paste together the two columns into one. During our \texttt{unite()} call, we'll use \texttt{sep\ =\ "\ ±\ "} to separate the \texttt{mean} from \texttt{sd} values (otherwise they'd be pasted as one long number).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prettySumAtl }\OtherTok{\textless{}{-}}\NormalTok{ sumAtl }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%.1f"}\NormalTok{, mean), }
         \AttributeTok{sd =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%.1f"}\NormalTok{, sd)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unite}\NormalTok{(}\StringTok{"mean ± sd"}\NormalTok{, mean}\SpecialCharTok{:}\NormalTok{sd, }\AttributeTok{sep =} \StringTok{" ± "}\NormalTok{ ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n) }\CommentTok{\# removing n column}

\NormalTok{prettySumAtl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 19 x 5
## # Groups:   p [4]
##    p     city                `mean ± sd`   min   max
##    <chr> <chr>               <chr>       <dbl> <dbl>
##  1 NB    Bathurst            1.2 ± 1.9       0    27
##  2 NB    Edmundston          4.5 ± 4.8       0    45
##  3 NB    Fredericton         1.8 ± 4.0       0    39
##  4 NB    Moncton             3.4 ± 4.7       0    39
##  5 NB    Saint John          3.0 ± 4.0       0    41
##  6 NL    Corner Brook        2.7 ± 2.5       0    28
##  7 NL    Grand Falls-Windsor 0.9 ± 1.3       0    27
##  8 NL    Labrador City       2.5 ± 4.1       0    46
##  9 NL    Marystown           0.3 ± 0.6       0    11
## 10 NL    Mount Pearl         1.5 ± 2.8       0    68
## 11 NL    St Johns            5.3 ± 6.1       0    49
## 12 NS    Halifax             3.4 ± 4.2       0    39
## 13 NS    Kentville           0.8 ± 1.2       0    20
## 14 NS    Pictou              1.2 ± 1.5       0    20
## 15 NS    Port Hawkesburry    2.5 ± 4.3       0    59
## 16 NS    Sydney              2.7 ± 2.9       0    37
## 17 PE    Charlottetown       1.9 ± 2.9       0    35
## 18 PE    Southampton         0.5 ± 0.7       0    16
## 19 PE    Wellington          0.5 ± 0.7       0     9
\end{verbatim}

Note to round the numbers we used \texttt{sprintf()} to round out numbers. This is because in the final publication it's important to keep trailing zeros (i.e.~\texttt{1.0} and not \texttt{1}), but R's \texttt{round()} will drop these. \texttt{mean\ =\ sprintf("\%.1f",\ mean)} takes the existing values in the \texttt{mean} column, rounds them to one digit, that's what \texttt{"\%.1f"} means (``\%.2f'' would be two digits and so on), and paste them back into the \texttt{mean} column. Same situation for the \texttt{sd} column.

\hypertarget{pretty-tables}{%
\subsection{Pretty tables}\label{pretty-tables}}

Now we'll want to make a pretty table. Despite the emphasis on visualizations in this book, tables are an under appreciate means to convey information. Often when you're only plotting a handful of numbers, a table would better serve the reader. So don't overlook this point of your report. If you've distilled hours of your work to a handful of numbers, you best serve them up on a silver platter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ft }\OtherTok{\textless{}{-}} \FunctionTok{flextable}\NormalTok{(prettySumAtl) }
  
\NormalTok{ft }\OtherTok{\textless{}{-}} \FunctionTok{set\_header\_labels}\NormalTok{(ft, }
                        \AttributeTok{p =} \StringTok{"province"}\NormalTok{)}

\NormalTok{ft }\OtherTok{\textless{}{-}} \FunctionTok{set\_table\_properties}\NormalTok{(ft, }\AttributeTok{layout =} \StringTok{"autofit"}\NormalTok{)}
\NormalTok{ft }\OtherTok{\textless{}{-}} \FunctionTok{align}\NormalTok{(ft, }\AttributeTok{j =} \StringTok{"mean ± sd"}\NormalTok{, }\AttributeTok{align =} \StringTok{"right"}\NormalTok{, }\AttributeTok{part =} \StringTok{"all"}\NormalTok{)}
\NormalTok{ft}
\end{Highlighting}
\end{Shaded}

\global\setlength{\Oldarrayrulewidth}{\arrayrulewidth}

\global\setlength{\Oldtabcolsep}{\tabcolsep}

\setlength{\tabcolsep}{0pt}

\renewcommand*{\arraystretch}{1.5}



\providecommand{\ascline}[3]{\noalign{\global\arrayrulewidth #1}\arrayrulecolor[HTML]{#2}\cline{#3}}

\begin{longtable}[c]{ccccc}



\ascline{1.5pt}{666666}{1-5}

\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{province}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{city}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{mean\ ±\ sd}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{min}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{max}}}} \\

\ascline{1.5pt}{666666}{1-5}\endfirsthead 

\ascline{1.5pt}{666666}{1-5}

\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{province}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{city}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{mean\ ±\ sd}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{min}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{max}}}} \\

\ascline{1.5pt}{666666}{1-5}\endhead



\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Bathurst}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.2\ ±\ 1.9}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{27}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Edmundston}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{4.5\ ±\ 4.8}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{45}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Fredericton}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.8\ ±\ 4.0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Moncton}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.4\ ±\ 4.7}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NB}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Saint\ John}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.0\ ±\ 4.0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{41}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Corner\ Brook}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.7\ ±\ 2.5}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{28}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Grand\ Falls-Windsor}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.9\ ±\ 1.3}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{27}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Labrador\ City}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.5\ ±\ 4.1}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{46}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Marystown}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.3\ ±\ 0.6}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{11}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Mount\ Pearl}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.5\ ±\ 2.8}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{68}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NL}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{St\ Johns}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{5.3\ ±\ 6.1}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{49}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Halifax}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{3.4\ ±\ 4.2}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{39}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Kentville}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.8\ ±\ 1.2}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{20}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Pictou}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.2\ ±\ 1.5}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{20}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Port\ Hawkesburry}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.5\ ±\ 4.3}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{59}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{NS}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Sydney}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{2.7\ ±\ 2.9}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{37}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Charlottetown}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{1.9\ ±\ 2.9}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{35}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Southampton}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.5\ ±\ 0.7}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{16}}}} \\





\multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{PE}}}} & \multicolumn{1}{>{}l}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{Wellington}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0.5\ ±\ 0.7}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{0}}}} & \multicolumn{1}{>{}r}{\textcolor[HTML]{000000}{\fontsize{11}{11}\selectfont{\global\setmainfont{DejaVu Sans}{9}}}} \\

\ascline{1.5pt}{666666}{1-5}



\end{longtable}



\arrayrulecolor[HTML]{000000}

\global\setlength{\arrayrulewidth}{\Oldarrayrulewidth}

\global\setlength{\tabcolsep}{\Oldtabcolsep}

\renewcommand*{\arraystretch}{1}

\hypertarget{part-part-4-visualization-in-r}{%
\part*{Part 4: Visualization in R}\label{part-part-4-visualization-in-r}}
\addcontentsline{toc}{part}{Part 4: Visualization in R}

\hypertarget{visualizations-for-env-chem}{%
\chapter{Visualizations for Env Chem}\label{visualizations-for-env-chem}}

Visualizations have always been an important part of data science and chemistry. Good graphics illuminate trends and patterns you may have otherwise missed and allow us to quickly inspect thousands of values. R via the \texttt{ggplot2} package is one of, if not the premier, data visualization language available. This chapter will formally introduce the \texttt{ggplot2} package, explain a bit of the logic undergirding it's operation, and give you some quick examples of how it works. Afterwards we'll delve deeper into specific visualizations you'll use and encounter in your studies culminating in preparing your plots for publication.

We've already encountered and produced several types of plots to visualize our data. We've also gone over the theory and basic operations of \texttt{ggplot()} in the {[}ggplot basics{]} section. Now, we'll expand on these and explicitly walk through the most common data visualization methods you'll encounter in the field of environmental chemistry. Additionally, we'll learn how to get your plots ready for publication.

The plots we'll be covering include:

\begin{itemize}
\tightlist
\item
  {[}Bar Charts{]}
\item
  \protect\hyperlink{box-plots}{Box Plots}
\item
  \protect\hyperlink{histograms}{Histograms}
\item
  \protect\hyperlink{scatter-plots}{Scatter Plots}
\item
  \protect\hyperlink{interactive-plots}{Interactive Plots}
\item
  {[}Plotting for publication{]}
\end{itemize}

These are only a smattering of the possible data visualizations you can perform in R. We're focusing on them because of their ubiquity in our field, but they often won't be the ideal visualizations you need to communicate \emph{your story}. We highly recommend you check out the following resources. Not only are they a great source of inspiration, they provide example code to get you up and running. We consult them regularly.

\begin{itemize}
\tightlist
\item
  \href{https://www.data-to-viz.com/}{\textbf{Data to viz}} which features a decision tree to help you decide on what plot would serve you best.
\item
  \href{https://exts.ggplot2.tidyverse.org/gallery/}{\textbf{ggplot2 extensions gallery}} which is the best repository to the plethora of \texttt{ggplot2()} extensions. If you need a specialized plot, check here. Odds are someone has a solution to your problem. Some great extensions include \href{https://github.com/slowkow/ggrepel}{\texttt{ggrepel}} for easy labelling of points; \href{https://docs.r4photobiology.info/ggpmisc/}{\texttt{ggpmisc}} for statistical annotations; and \href{https://rpkgs.datanovia.com/ggpubr/}{\texttt{ggpubr}} for publication ready plots, group wise comparisons, and annotation of statistical significance.
\item
  \href{https://www.r-graph-gallery.com/index.html}{\textbf{The R Graph Gallery}} contains hundreds of charts made with R. While it's not as easy to navigate as \emph{Data to viz}, it does contain many more examples; it is definitely worth exploring.
\end{itemize}

\hypertarget{discrete-vs.-continuous-variables}{%
\section{Discrete vs.~continuous variables}\label{discrete-vs.-continuous-variables}}

The type of plots available to you, and how they display, are dependent on the type of data. Namely, whether your data is \emph{discrete} (i.e .can only take particular values) or \emph{continuous} (is not restricted to defined separate values, but can occupy any value over a continuous range). So a variable consisting of cities would be discrete, whereas a variable like concentration of a chemical would be continuous. You can treat numeric data as categorical if you so chose. Understanding the difference between discrete and continuous data will shape how you plot your data.

\hypertarget{prerequisites}{%
\section{Prerequisites}\label{prerequisites}}

Additionally, for this section we'll mostly be using the \texttt{atlNO2} and \texttt{sumAtl} datasets we created in the \protect\hyperlink{summarizing-data}{Summarizing data} chapter. Please revisit that chapter for details on that dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{atlNO2 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/2018hourlyNO2\_Atl.csv"}\NormalTok{, }\AttributeTok{skip =} \DecValTok{7}\NormalTok{, }\AttributeTok{na =}\FunctionTok{c}\NormalTok{(}\StringTok{"{-}999"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename\_with}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{tolower}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"/.*"}\NormalTok{, }\StringTok{""}\NormalTok{, .x))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"h"}\NormalTok{), }
               \AttributeTok{names\_prefix =} \StringTok{"h"}\NormalTok{, }
               \AttributeTok{names\_to =} \StringTok{"hour"}\NormalTok{, }
               \AttributeTok{names\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{hour =}\NormalTok{ as.numeric),}
               \AttributeTok{values\_to =} \StringTok{"conc"}\NormalTok{, }
               \AttributeTok{values\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{conc =}\NormalTok{ as.numeric),}
               \AttributeTok{values\_drop\_na =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 8395 Columns: 31
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## chr  (3): Pollutant//Polluant, City//Ville, P/T//P/T
## dbl (28): NAPS ID//Identifiant SNPA, Latitude//Latitude, Longitude//Longitud...
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumAtl }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(p, city) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(conc), }
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(conc), }
            \AttributeTok{median =} \FunctionTok{median}\NormalTok{(conc), }
            \AttributeTok{min =} \FunctionTok{min}\NormalTok{(conc), }
            \AttributeTok{max =} \FunctionTok{max}\NormalTok{(conc))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'p'. You can override using the `.groups`
## argument.
\end{verbatim}

\hypertarget{common-types-of-graphs}{%
\chapter{Common types of graphs}\label{common-types-of-graphs}}

In this chapter, you will learn how to create some of the most commonly used graphs, including bar plots, box plots, histograms, and scatterplots. These powerful visualization tools will enable you to explore and communicate your data effectively, gaining valuable insights along the way.

\hypertarget{bar-chart}{%
\section{Bar chart}\label{bar-chart}}

Bar charts, also called \emph{column} charts, represent \emph{categorical} data with rectangular bars whose height/length is proportional to the values they represent.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sumAtl,}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ city, }
           \AttributeTok{y =}\NormalTok{ mean)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\CommentTok{\# rotates plot 90 degrees}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-138-1.pdf}

Pretty boring, but it's gotten the job done. \textbf{Note} that we used \texttt{coord\_flip()} to rotate our plot 90\(^\circ\) therefore the supplied \texttt{x} option of \texttt{city} is now plotted on the \texttt{y-axis}. This makes reading long categorical names (i.e.~the names of cities) easier. \texttt{coord\_flip()} doesn't change anything else except the final orientation of the plot.

Also note that \texttt{ggplot()} includes \texttt{geom\_col()} and \texttt{geom\_bar()}. While both can be used to make bar charts. \texttt{geom\_col()} is used when you want to represent values in the data (i.e.~the precalculated mean as shown above), whereas \texttt{geom\_bar()} makes the height of the bar proportional to the number of cases in each group.

\hypertarget{adding-error-bars}{%
\subsection{Adding error bars}\label{adding-error-bars}}

Any measurement always has an associated uncertainty/variability. These values are expressed visually via \emph{error bars} demarcating the minimum and maximum variability and give a general idea of how precise a measurement is. In our \texttt{sumAtl} dataset we've calculated the standard deviation as a measure of uncertainty. In our example, we've used the standard deviation (\texttt{sd}) as a measure of uncertainty of our calculated annual means.

To plot error bars we use \texttt{geom\_errorbar()} and pass the min and max values we want the error bars to be. In our case, the lowest value would be \texttt{ymin\ =\ mean\ -\ sd}, and the highest would be \texttt{ymin\ =\ mean\ +\ sd}. Our plotted error bars now indicated plus or minus one standard deviation from the mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sumAtl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ city, }\AttributeTok{y =}\NormalTok{ mean)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ sd, }
                    \AttributeTok{ymax =}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ sd)) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-139-1.pdf}

Some of the error bars indicate we could get a \emph{negative} concentration of NO\textsubscript{2}. This is physically impossible, but it does suggest we should evaluate the distribution of our data (see below). Note that since we're calculating error bar ranges on the fly, we've had to specify new aesthetic arguments to \texttt{geom\_errorbar()}.

\hypertarget{ordering-bar-charts}{%
\subsection{Ordering bar charts}\label{ordering-bar-charts}}

Often with bar charts (and similar plots), it's useful to \emph{order} the bars to help tell a story or convey information. We can effectuate this using \texttt{fct\_reorder()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sumAtl, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{fct\_reorder}\NormalTok{(city, mean),}
           \AttributeTok{y =}\NormalTok{ mean)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ sd, }
                    \AttributeTok{ymax =}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ sd)) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-140-1.pdf}

So in our aesthetics call for \texttt{geom\_bar} we specified the \texttt{x} variable should be \texttt{city}, but ordered based on their corresponding \texttt{mean} value. Doing this has helped shed some light on trends in NO\textsubscript{2} levels. For one, despite Labrador City having lower mean {[}NO\textsubscript{2}{]}, we can now easily see that it has a larger variation in {[}NO\textsubscript{2}{]} then Corner Brook.

\hypertarget{grouping-bar-charts}{%
\subsection{Grouping bar charts}\label{grouping-bar-charts}}

Sometimes you'll want to group bar charts as in the concentration of several chemicals in different locations. We can easily group bar charts in ggplot. Let's go ahead and group our mean annual {[}NO\textsubscript{2}{]} by province by simply (1) reordering based on province, and (2) colour bars based on province:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sumAtl, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{fct\_reorder}\NormalTok{(city, p),}
           \AttributeTok{y =}\NormalTok{ mean, }
           \AttributeTok{fill =}\NormalTok{ p)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ sd, }
                    \AttributeTok{ymax =}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ sd)) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-141-1.pdf}

There are other ways to group your bar charts depending on the story you want to tell and the data you have. Please consult the \href{https://www.r-graph-gallery.com/48-grouped-barplot-with-ggplot2.html}{Grouped, stacked and percent stacked barplot in ggplot2} page from the \emph{R-graph-gallery}.

\hypertarget{box-plots}{%
\section{Box Plots}\label{box-plots}}

Box plots give a summary of the \emph{distribution} of a numeric variable through their \emph{quartiles}. You've no doubt seen them before, but they're often misinterpreted. Let's create a box-plot using \texttt{geom\_boxplot()} and our Atlantic hourly NO\textsubscript{2} measurements, then we'll break down how to interpret it.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atlNO2, }
       \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ city, }\AttributeTok{y =}\NormalTok{ conc)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-142-1.pdf}

Let's break down how to interpret \emph{one} box before tackling the entire set. As previously mentioned, box plots describe data in their \emph{quartiles}. Quartiles basically arrange the data from the lowest to highest value and split the data at \emph{three points}:

\begin{itemize}
\tightlist
\item
  \emph{The first quartile} (Q1) is halfway between the lowest value and the median (50\%) of the data. In other words 25\% of the data lies \emph{below} Q1.
\item
  \emph{The second quartile} (Q2) is the median. 50\% of the data lies below, and 50\% lies above this point.
\item
  \emph{The third quartile} (Q3) is halfway between the median and the \emph{highest} value in the data. In other words, 75\% of the data lies \emph{below} Q3.
\end{itemize}

The \emph{box} in box-plots represents the range between Q1 and Q3. This is known as the \emph{inter-quartile range} (IQR) and 50\% of the total data falls somewhere inside this box. You can estimate the distribution by the symmetry of the box. if Q1 to the median is smaller than the median to Q3, the data has a \emph{positive skew} (right sided skew), and vice versa.

Rounding it out, \texttt{geom\_boxplot()} includes \emph{whiskers}, the thin lines emanating out from the box. This is used the predict outliers and is calculated as \(outliers = \pm 1.5 \times IQR\). Anything outside the whiskers is considered an ``outliers'' or an extreme point, and is plotted individually.

Putting this all together, let's look at the {[}NO\textsubscript{2}{]} for St.~Johns city:

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-143-1.pdf}

Note that we've plotted the actual distribution of the data. Prior to computers, this was incredibly difficult to do, hence the use of box plots which can be drawn knowing only five points. However, the simplicity in calculating box-plots means they can hide trends and observations of your data. On top of that, they aren't very intuitive (see the score of text you just read to understand them). Consequently, we strongly recommend you explore some of the \protect\hyperlink{box-plot-alternatives}{Box plot alternatives} unless you explicitly need to create box-plots.

\hypertarget{box-plot-alternatives}{%
\subsection{Box plot alternatives}\label{box-plot-alternatives}}

The first alternative to box-plots is the \emph{violin plot} which is made using \texttt{geom\_violin()}. It is similar to the box-plot, but instead of displaying the quartiles, it plots the density within each group and is a bit more intuitive then box-plots. While the example below isn't the most convincing given the scale of the dataset, violin plots are useful for identifying underlying trends in the distribution of data. For example, in the plot below we can see that some towns such as Marystown principle has days where {[}NO\textsubscript{2}{]} = 0 ppb, whereas Grand Falls-Windsor has a large number of days with low, but measurable levels of NO\textsubscript{2}. This might be because of difference in regional ambient levels of NO\textsubscript{2}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atlNO2, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ city, }\AttributeTok{y =}\NormalTok{ conc, }\AttributeTok{fill =}\NormalTok{ p)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_violin}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/atl-violin-1.pdf}

Another alternative is to plot the points over top of the box-plot. You've encountered this example in \protect\hyperlink{r-coding-basics}{R coding basics}. Truth be told, there are countless way to visualize distribution.

\hypertarget{statistical-comparisons-between-groups}{%
\subsection{Statistical comparisons between groups}\label{statistical-comparisons-between-groups}}

Often box-plots are used to show differences in distributions between two groups (i.e.~population in Location A vs.~Location B). How you determine this statistically is a different story, but packages such as \texttt{ggpubr} have many built in functionalists to display the results of these outcomes.

From our NO\textsubscript{2} data, St.~Johns appears to have the highest levels of NO\textsubscript{2}. Let's apply a pairwise test against other Newfoundland communities to see if our observation is \emph{statistically significant} based upon the results of a \emph{Wilcoxon test}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfld }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(p }\SpecialCharTok{==} \StringTok{"NL"}\NormalTok{) }\CommentTok{\# only nfld stations}

\CommentTok{\# Code from ggpubr website}
\NormalTok{ggpubr}\SpecialCharTok{::}\FunctionTok{ggviolin}\NormalTok{(nfld, }\AttributeTok{x =} \StringTok{"city"}\NormalTok{, }\AttributeTok{y =} \StringTok{"conc"}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  ggpubr}\SpecialCharTok{::}\FunctionTok{stat\_compare\_means}\NormalTok{(}\AttributeTok{ref.group =} \StringTok{"St Johns"}\NormalTok{,}
                             \AttributeTok{method =} \StringTok{"wilcox.test"}\NormalTok{,}
                             \AttributeTok{label =} \StringTok{"p.signif"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-144-1.pdf}

Based on the results of our test, all other stations in Newfoundland have statistically significant differences in the median NO2 values. Note the validity of this statistical approach to this particular problem is called into question based on the distribution of the data etc. We've included it to demonstrate how to label significance on plots, rather than an explicit discussion on statistics.

For more information on \texttt{ggpubr}, adding p-values and significance labels, and different pairwise statistical test please visit \href{http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/}{ggpubr: Publication Ready Plots}.

\hypertarget{histograms}{%
\section{Histograms}\label{histograms}}

Histograms are an approximate representation of the distributions of numerical data. They're an approximation because you arbitrarily ``bin'' your data into groups and then count the number of values inside that bin. The frequency, or count, in each bin is represented by the height of a rectangle whose width equals that of the bin. \texttt{geom\_histogram()} is used to create histograms:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(atlNO2, }\AttributeTok{city =} \StringTok{"St Johns"}\NormalTok{), }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \StringTok{"Distribution of St. Johns\textquotesingle{} NO2 levels in 2018"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: In subset.data.frame(atlNO2, city = "St Johns") :
##  extra argument 'city' will be disregarded
\end{verbatim}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-145-1.pdf}

We can alter the resolution of our histogram by modifying the width of the bins using the \texttt{binwidth} argument or by specifying the number of bins with the \texttt{bins} argument. The former is useful when you don't know the range of your data, whereas the latter is useful is you do (i.e.~numbers between 0 and 100).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(atlNO2, }\AttributeTok{city =} \StringTok{"St Johns"}\NormalTok{), }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \StringTok{"Distribution of St. Johns\textquotesingle{} NO2 levels in 2018, binwidth = 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: In subset.data.frame(atlNO2, city = "St Johns") :
##  extra argument 'city' will be disregarded
\end{verbatim}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-146-1.pdf}

\hypertarget{multiple-histograms}{%
\subsection{Multiple histograms}\label{multiple-histograms}}

While you can overlap histograms, it get's difficult to read with more than a handful of datasets. If we wanted to plot histograms of all the cities in our dataset we would have to use a small multiple via the \texttt{facet\_grid()} or \texttt{facet\_wrap()} arguments. \texttt{facet\_grid()} allows you to arrange many small plots on a grid defined by variables in your dataset (i.e.~columns for provinces, and rows for different pollutants). In the example below we've used \texttt{facet\_wrap(\textasciitilde{}city)} which creates a 2D layout of histograms of each cities NO\textsubscript{2} values. Note the tilde , \texttt{\textasciitilde{}}, preceding in \texttt{\textasciitilde{}city}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atlNO2, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc, }\AttributeTok{fill =}\NormalTok{ p)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{city)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-147-1.pdf}

\hypertarget{scatter-plots}{%
\section{Scatter plots}\label{scatter-plots}}

Scatter plots display values of two variables, one of which is a \emph{continuous} variable. Each data point ins plotted as an individual point on.You've already made scatter plots in the form of a time series during the Section 1 tutorial exercise. We've already touched upon scatter plots during the {[}Linear Regression{]} chapter where we also overlaid our linear model over our concentration points. So now we'll touch upon some things you can do to improve your scatter plots.

\hypertarget{marginal-plots}{%
\subsection{Marginal plots}\label{marginal-plots}}

You can easily combine a scatter plot with marginal plot. This is useful to summarize one dimension of our scatter plot. For example, let's revisit the time series plot we made in \protect\hyperlink{r-coding-basics}{R coding basics}. We might want to know the distribution of concentrations of the individual pollutants. using the \texttt{ggExtra} package and the \texttt{ggMarginal()} function we can get the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torontoAir }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/2018{-}01{-}01\_60430\_Toronto\_ON.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 507 Columns: 8
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## chr  (3): city, p, pollutant
## dbl  (4): naps, latitude, longitude, concentration
## dttm (1): date.time
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# note we\textquotesingle{}re storing our plot in the variable \textquotesingle{}torPlot\textquotesingle{}}
\CommentTok{\# and we\textquotesingle{}re not plotting SO2}
\NormalTok{torPlot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(torontoAir, pollutant }\SpecialCharTok{!=} \StringTok{"SO2"}\NormalTok{), }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date.time,}
           \AttributeTok{y =}\NormalTok{ concentration,}
           \AttributeTok{colour =}\NormalTok{ pollutant)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"bottom"}\NormalTok{)}

\CommentTok{\# We\textquotesingle{}re passing our torPlot to the ggMarginal Function}
\NormalTok{ggExtra}\SpecialCharTok{::}\FunctionTok{ggMarginal}\NormalTok{(torPlot, }\AttributeTok{margins =} \StringTok{"y"}\NormalTok{, }\AttributeTok{groupColour =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{groupFill =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-148-1.pdf}

We can now see the distributions of NO\textsubscript{2} and O\textsubscript{3} overlaid on the vertical axis. note that \texttt{ggMarginal()} only works with scatter plots.

There are plenty of other marginal options scatted about various packages. You can see many of them in action (with beautiful examples) at \href{http://motioninsocial.com/tufte/\#minimal-line-plot}{Tufte in R} by Lukasz Piwek.

\hypertarget{customizing-your-plots}{%
\chapter{Customizing your plots}\label{customizing-your-plots}}

Up until now we haven't payed much attention to the explicit aesthetics of plots beyond what we needed for our exploratory analysis. However, many journals, publications, instructors, etc. will want plots to adhere to certain aesthetic standards. There's scores of options to play with, so we recommend you consult the \href{https://raw.githubusercontent.com/rstudio/cheatsheets/master/data-visualization.pdf}{ggplot2 Cheat Sheet}.

\hypertarget{interactive-plots}{%
\section{Interactive Plots}\label{interactive-plots}}

Ultimately you're visualizations will be printed to a static PDF document, but in the interim having an interactive plot can be helpful for data exploration. The \texttt{plotly} package magically makes most \texttt{ggplots} interactive with a simply command. Here's an example with our Toronto air quality data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torPlot2 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ torontoAir,}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date.time,}
           \AttributeTok{y =}\NormalTok{ concentration,}
           \AttributeTok{colour =}\NormalTok{ pollutant)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}

\NormalTok{plotly}\SpecialCharTok{::}\FunctionTok{ggplotly}\NormalTok{(torPlot2)}
\end{Highlighting}
\end{Shaded}

This is also super useful when surveying spectroscopy data, although the large number of points in those datasets can take a while to render into interactive plotly plots.

\hypertarget{plot-themes}{%
\section{Plot Themes}\label{plot-themes}}

Overall themes can be applied to ggplot. The simple and minimalist \texttt{theme\_classic()} is satisfactory for most submissions, but you can peruse the available these in ggplot \href{https://ggplot2.tidyverse.org/reference/ggtheme.html}{here} or you can explore many more themes in the \href{https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/}{\texttt{ggthemes} package}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# generating example plot to modify }
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ torontoAir, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date.time,}
           \AttributeTok{y =}\NormalTok{ concentration,}
           \AttributeTok{colour =}\NormalTok{ pollutant)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }

\CommentTok{\# default theme}
\NormalTok{default }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+} \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \StringTok{"Default geom\_scatter"}\NormalTok{)}


\CommentTok{\# Classic theme}
\NormalTok{classic }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"theme\_classic()"}\NormalTok{)}
 

\CommentTok{\# arranging into grid}
\NormalTok{gridExtra}\SpecialCharTok{::}\FunctionTok{grid.arrange}\NormalTok{(default, classic, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-150-1.pdf}

\hypertarget{legends}{%
\section{Legends}\label{legends}}

You can specify the position of the legend under the \texttt{theme()} option as such:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bottom }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+} \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"bottom"}\NormalTok{)}

\NormalTok{inside }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+} \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(.}\DecValTok{95}\NormalTok{, .}\DecValTok{95}\NormalTok{))}

\NormalTok{gridExtra}\SpecialCharTok{::}\FunctionTok{grid.arrange}\NormalTok{(bottom, inside, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-151-1.pdf}

Other legend positions include: ``none'', ``left'', ``right'', ``bottom'', ``top'', or a two-element numeric vector to specify the location such as \texttt{c(0.95,\ 0.95)} for inside the top-right corner. \texttt{c(0.05,\ 0.05)} would place it inside the bottom right corner, and so on. Also note that \texttt{legend.position\ =\ "none"} will remove the legend entirely.

\hypertarget{modifying-labels}{%
\section{Modifying labels}\label{modifying-labels}}

The labels generated for the plots are derived from the variable names passed along to the \texttt{ggplot()} function. Consequently, variable names that are easy to code become ugly labels on the plot. You can modify labels using the \texttt{labs()} function. Note in the example below that we changed the legend's title by specifying what \texttt{aes()} option we used to create the legend; in the example below it's \texttt{colour}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\SpecialCharTok{+} \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Toronto Air quality"}\NormalTok{,}
         \AttributeTok{subtitle =} \StringTok{"from Jan 1st to 8th, 2018"}\NormalTok{, }
         \AttributeTok{xlab =} \StringTok{"Date"}\NormalTok{,}
         \AttributeTok{ylab =} \StringTok{"Concentration (ppb)"}\NormalTok{,}
         \AttributeTok{colour =} \StringTok{"Pollutant"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-152-1.pdf}

\hypertarget{modifying-axis}{%
\section{Modifying Axis}\label{modifying-axis}}

We've already talked about labelling axis titles in \protect\hyperlink{modifying-labels}{Modifying labels}, and adding marginal plots in \protect\hyperlink{scatter-plots}{Scatter plots}. So we'll just briefly touch upon some simple axis modifications.

\hypertarget{transforming-axix}{%
\subsection{Transforming axix}\label{transforming-axix}}

Transformations are largely related to \emph{continuous} data, and are done using \texttt{scale\_y\_continuous()} or \texttt{scale\_x\_continuous()} functions. For example to scale the y-axis of our plot we'd do the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log10"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Log10(concentration)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-153-1.pdf}

Other useful transformations include ``log2'' for base-2 logs, ``date'' for dates, and ``hms'' for time. The later two are useful if R hasn't correctly interpreted your dataset. The data type for the \texttt{data.time} column of our dataset was correctly interpreted during our initial importation using \texttt{read\_csv()}. Hooray for doing it right the first time.

\hypertarget{limits}{%
\subsection{Limits}\label{limits}}

The limits of plots created with \texttt{ggplot()} are automatically assigned, but you can override these using the \texttt{lims()} function. For example we can specify the limits of our example plot to show from 0 to 100 ppb:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\SpecialCharTok{+} \FunctionTok{lims}\NormalTok{(}\AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-154-1.pdf}

\hypertarget{axis-tickslabels}{%
\subsection{Axis ticks/labels}\label{axis-tickslabels}}

Sometimes when you are plotting, the length of the axis labels is unreadable. This is often the case with categorical data, such as the name of cities like we've encountered earlier. We addressed this earlier in {[}Bar charts{]} by rotating the plot 90\(^\circ\) with the \texttt{coord\_flip()} function. This is often the best solution as it's how we read English. Another solution is to rotate the axis labels themselves:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{basePlot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(sumAtl, p }\SpecialCharTok{==} \StringTok{"NL"}\NormalTok{),}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ city, }
           \AttributeTok{y =}\NormalTok{ mean)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{()}

\NormalTok{default }\OtherTok{\textless{}{-}}\NormalTok{ basePlot }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"default plot"}\NormalTok{)}

\NormalTok{flip }\OtherTok{\textless{}{-}}\NormalTok{ basePlot }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"coord\_flip()"}\NormalTok{)}

\NormalTok{rotated }\OtherTok{\textless{}{-}}\NormalTok{ basePlot }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"element\_text(angle = 45)"}\NormalTok{)}

\NormalTok{rotatedHJust }\OtherTok{\textless{}{-}}\NormalTok{ basePlot }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"element\_text(angle = 45, hjust = 1)"}\NormalTok{)}


\NormalTok{gridExtra}\SpecialCharTok{::}\FunctionTok{grid.arrange}\NormalTok{(default, flip, rotated, rotatedHJust, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-155-1.pdf}

\hypertarget{arranging-plots}{%
\section{Arranging plots}\label{arranging-plots}}

We talked about how facets can be used to generate multiple plots from a dataset (small multiples), but sometimes you want to combine two or more \emph{different} plots together. There are a couple of ways, but we've been using \texttt{grid.arrange()} from the \texttt{gridExtra} pacakge (as demonstrated above). You can read up on \href{https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html}{\texttt{gridExtra} here}. There is also the \href{https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html}{\texttt{ggarrange} function} from the \texttt{ggpubr} package which, amongst other things, can easily create shared legends between plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colchart }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sumAtl,}
                   \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{fct\_reorder}\NormalTok{(city, mean),}
                       \AttributeTok{y =}\NormalTok{ mean, }
                       \AttributeTok{fill =}\NormalTok{ p)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ sd, }
                    \AttributeTok{ymax =}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ sd)) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }

\NormalTok{boxplot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ atlNO2, }
                  \FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ city, }
                       \AttributeTok{y =}\NormalTok{ conc,}
                       \AttributeTok{fill =}\NormalTok{ p)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{coord\_flip}\NormalTok{()}

\NormalTok{boxplot}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-156-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggpubr}\SpecialCharTok{::}\FunctionTok{ggarrange}\NormalTok{(colchart, }
\NormalTok{                  boxplot, }
                  \AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }
                  \AttributeTok{nrow =} \DecValTok{1}\NormalTok{,}
                  \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{),}
                  \AttributeTok{common.legend =} \ConstantTok{TRUE}\NormalTok{, }
                  \AttributeTok{legend =} \StringTok{"bottom"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-156-2.pdf}

\hypertarget{anotating-plots}{%
\section{Anotating plots}\label{anotating-plots}}

Everyplot can do with a bit of annotation. These range from providing critical information for contextualizing and understanding your plot to pointing out something you think the reader might miss but should know. These are different then \emph{captions}, which is accomplished in the \texttt{rmarkdown} chunk header (see \protect\hyperlink{r-code-chunk-options}{R code chunk options} for a refresher).

Let's quickly plot a map of annual mean 1-hr {[}NO2{]} in our dataset so we can visualzie them spatially. Note, the map we're making here is rather basic, to make prettier maps see {[}CHM410: Air Quality Lab{]}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# need lat and long value for map}
\NormalTok{mapNO2 }\OtherTok{\textless{}{-}}\NormalTok{ atlNO2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(latitude, longitude, p,  city) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(conc))}

\CommentTok{\#install.packages("ggmap")}
\CommentTok{\# library(ggmap)}
\CommentTok{\# }
\CommentTok{\# atlMap \textless{}{-} get\_stamenmap(bbox = make\_bbox(lon = mapNO2$longitude, }
\CommentTok{\#                                          lat = mapNO2$latitude, }
\CommentTok{\#                                          f = 0.1), }
\CommentTok{\#                         zoom = 6, }
\CommentTok{\#                         maptype = "terrain", }
\CommentTok{\#                         crop = FALSE)}
\CommentTok{\# }
\CommentTok{\# atlMap \textless{}{-} ggmap(atlMap) }
\CommentTok{\# }
\CommentTok{\# atlMap}
\end{Highlighting}
\end{Shaded}

Now we want to plot our annual mean 1-hr {[}NO2{]} onto the map. We've covered this in detail in {[}Plotting Airbeam data spatially{]}, but for this plot we spefically want to annotate each point with it's corresponding city location. Doing this manually would take ages, so we're going to use the \href{https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html}{\texttt{ggrepel} package}. We simply need to specify which column (\texttt{naps\ id}) we'll use for our labels:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# atlMap + geom\_point(data = mapNO2, }
\CommentTok{\#              aes(x=longitude,}
\CommentTok{\#                  y=latitude,}
\CommentTok{\#                  colour = mean,}
\CommentTok{\#                  size = mean),}
\CommentTok{\#              alpha = 0.8) +}
\CommentTok{\#   scale\_alpha(guide = "none") + \# removing legend for alpha}
\CommentTok{\#   scale\_size(guide = "none") + \# removing legend for size}
\CommentTok{\#   ggrepel::geom\_label\_repel(data = mapNO2, }
\CommentTok{\#                             aes(x=longitude,}
\CommentTok{\#                                 y=latitude,}
\CommentTok{\#                                 label = city),}
\CommentTok{\#                             box.padding = 0.5,}
\CommentTok{\#                             max.overlaps = Inf)}
\CommentTok{\# }
\end{Highlighting}
\end{Shaded}

Again, not the prettiest map, but that's up to you to fix in post. \href{https://ggrepel.slowkow.com/articles/examples.html}{\texttt{geom\_text\_repel()}} is an incredibly useful package for quickly annotating plots. If you need to label/annotate points check it out.

\hypertarget{part-part-5-modelling-in-r}{%
\part*{Part 5: Modelling in R}\label{part-part-5-modelling-in-r}}
\addcontentsline{toc}{part}{Part 5: Modelling in R}

\hypertarget{modelling-linear-regression}{%
\chapter{Modelling: Linear Regression}\label{modelling-linear-regression}}

Modelling is basically math used to describe some type of system, and they are a forte of R, a language tailor made for statistical computing\ldots{} Every model has assumptions, limitations, and all around tricky bits to working. There is no shortage of modelling in a myriad of context, but in this chapter we'll discuss and break down the most common model you'll encounter, the \emph{linear regression model}, in the most common context, the \emph{linear calibration model}, using the most common function, \texttt{lm()}.

You have probably encountered the linear regression model under the pseudonym ``trend-lines'', most likely generated by \emph{Excel}'s ``add trend-line option'' (as in CHM135). While the models we'll be constructing with \texttt{lm()} work much the same \emph{mathematically}, unlike \emph{Excel}, R returns \emph{alllll} of the model outputs. Correspondingly, it's easy to get lost between juggling R code, the seemingly endless model outputs, and keeping yourself grounded in the real systems you're attempting to model.

To this end, this chapter is broken into the following parts:

\begin{itemize}
\tightlist
\item
  \protect\hyperlink{modelling-theory}{Modelling theory} where we briefly touch upon \emph{what} model is being calculated.
\item
  \protect\hyperlink{modelling-in-r}{Modelling in R} where we provide a boilerplate template for \emph{how} to calculate models in R.
\item
  \protect\hyperlink{visualizing-models}{Visualizing models} where we explore our model results.
\item
  \protect\hyperlink{calculating-concentrations}{Calculating Concentrations} where we use our model to calculate the concentration.
\end{itemize}

\hypertarget{modelling-theory}{%
\section{Modelling Theory}\label{modelling-theory}}

The \emph{linear calibration model} relates the response of an instrument to the value of the \emph{measurand}. The measurand is simply what we're measuring, often the concentration of an analyte. So we use the measurand, which we can control via preparation of standards from reference material as the \emph{independent} variable, with the instrument output being the \emph{dependent} variable (as instrument response varies with concentration). Altogether we're:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measuring the instrument response of standards of known concentration and samples of unknown concentration.
\item
  Calculating the linear calibration model (i.e.~line of best fit) through our standards.
\item
  Using the measurement model to calculate the concentration in our unknown from their respective instrument response.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{R4EnvChem_files/figure-latex/reg-plot-1.pdf}
\caption{\label{fig:reg-plot}Linear calibration model; figure modified from Hibbert and Gooding (2006).}
\end{figure}

Before we can calculate concentrations, we need a measurement model. In other words, an equation that relates instrument response to sample concentration (or other factors). For simple linear calibration, we use:

\[ y = a + bx\]

Where:

\begin{itemize}
\tightlist
\item
  \(y\) is the instrument response
\item
  \(x\) is the independent variable (i.e.~sample concentration)
\item
  \(a\) and \(b\) are the coefficients of the model; otherwise known as intercept and slope, respectively.
\end{itemize}

We'll gloss over some of the more technical aspects of modelling, and discuss other in more detail below. For now, know that:

\begin{itemize}
\tightlist
\item
  We're assuming our linear model is correct (i.e.~the instruments actually responds linearly to concentration).
\item
  All uncertainties reside in the dependant variable \(y\) (i.e.~no errors in preparation of the standards).
\item
  The values of \(a\) and \(b\) are determined by minimizing the \emph{sum of the residuals squared}.

  \begin{itemize}
  \tightlist
  \item
    The residuals are the difference between the actual measured response and where it would be if it were on the calibration line.
  \end{itemize}
\end{itemize}

Once we have our line of best fit, we can calculate the concentration of our unknown sample \(i\), from it's measured response \(y_i\) by:

\[ x_i = \frac{y_i ~-~b}{a}\]

There is more going on under the hood then what we're describing here, but this should be enough to get you up and running. If you would like a greater breakdown of linear calibration modelling, we suggest you read Chapter 5 of \emph{Data Analysis for Chemistry} by Hibbert and Gooding. An online version is accessible via the University of Toronto's Library. Also there is no reason the instrument response must be linear. In fact, we spend a great deal of time arranging our experiment to that we land in the `linear range'. For details on non-linear modelling in R see {[}Non-Linear Regression{]}

\hypertarget{modelling-in-r}{%
\section{Modelling in R}\label{modelling-in-r}}

Now that we have a rough understanding of what we're trying to do, let's go over \emph{how} to calculate linear regression models in R. Note model is a general term, in this situation we'll be calculating a \textbf{calibration curve}. All calibration curves are models, but not all models are calibration curves.

For our example dataset we'll import a dataset consisting of four analytical standards of sodium plus a calibration blank all run in triplicate. The standards were measured via flame atomic emission spectroscopy (FAES). Let's import the FAES calibration results we saw in {[}Transform: dplyr and data manipulation{]}. As we've already seen, our data is composed of four standards and a blank analyzed in triplicate. Since we're focusing on modelling, \emph{we'll treat the blank as a standard in our model fitting}.
So let's import our dataset:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Importing using tips from Import chapter}

\NormalTok{FAES }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/FAESdata.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{std\_Na\_conc,}
               \AttributeTok{names\_to =} \StringTok{"replicate"}\NormalTok{, }
               \AttributeTok{names\_prefix =} \StringTok{"reading\_"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"signal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{separate}\NormalTok{(}\AttributeTok{col =}\NormalTok{ std\_Na\_conc,}
           \AttributeTok{into =} \FunctionTok{c}\NormalTok{(}\StringTok{"type"}\NormalTok{, }\StringTok{"conc\_Na"}\NormalTok{, }\StringTok{"units"}\NormalTok{),}
           \AttributeTok{sep =} \StringTok{" "}\NormalTok{,}
           \AttributeTok{convert =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"standard"}\NormalTok{)}

\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(FAES)}
\end{Highlighting}
\end{Shaded}

And let's quickly plot our data. You should always visualize your data before modelling, especially for linear calibration modelling. Unlike \emph{statistical} modelling. Visualizing your data is the easiest way to spot trends and gross errors in your data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ FAES,}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc\_Na, }
           \AttributeTok{y =}\NormalTok{ signal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-161-1.pdf}

\hypertarget{base-r-linear-model}{%
\subsection{Base R Linear Model}\label{base-r-linear-model}}

R's base \texttt{lm()} function for linear regression is excellent, but it's outputs have some messy quirks. It's easier to show that, so let's calculate the linear relationship between the \texttt{signal} as a function of \texttt{conc\_Na}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(signal }\SpecialCharTok{\textasciitilde{}}\NormalTok{ conc\_Na, }\AttributeTok{data =}\NormalTok{ FAES)}
\NormalTok{lm\_fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = signal ~ conc_Na, data = FAES)
## 
## Coefficients:
## (Intercept)      conc_Na  
##        2615        29707
\end{verbatim}

Reading the code above (recall that we're reading it from \emph{right to left} because it's base R):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We're taking the FAES data we created earlier; \texttt{data\ =\ FAES}
\item
  We're comparing \texttt{signal} (the dependent, y, variable) to \texttt{conc\_Na} (the independent, x, variable) via the tilde \texttt{\textasciitilde{}}. The way to read this is: \emph{``Signal depends on concentration''}.
\item
  We're comparing these two variables using the \texttt{lm()} function for generalized linear models.
\item
  All of the model outputs are stored in the \texttt{lm\_fit} variable.
\end{enumerate}

As we can see, the model outputs are pretty brief and not much more than \emph{Excel}'s outputs. We can use \texttt{summary()} to extract more information to better understand our model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = signal ~ conc_Na, data = FAES)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2112.78 -1528.53    70.51   821.50  2718.20 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2615.1      665.2   3.931  0.00172 ** 
## conc_Na      29707.2     1304.5  22.772 7.34e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1824 on 13 degrees of freedom
## Multiple R-squared:  0.9755, Adjusted R-squared:  0.9737 
## F-statistic: 518.6 on 1 and 13 DF,  p-value: 7.341e-12
\end{verbatim}

Now we have a lot more information from our model (don't worry about what everything means, it's discussed further in Section 3. For now, understand that it's a hot mess.

\hypertarget{cleaning-up-model-ouputs}{%
\subsection{Cleaning up model ouputs}\label{cleaning-up-model-ouputs}}

\texttt{summary()} provides a decent overview of our model's performance, but the outputs are difficult to work with. Let's turn to the \texttt{broom()} package to clean up our model outputs.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}

\NormalTok{calCurve }\OtherTok{\textless{}{-}}\NormalTok{ FAES }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(type) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{nest}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fit =} \FunctionTok{map}\NormalTok{(data, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{lm}\NormalTok{(signal }\SpecialCharTok{\textasciitilde{}}\NormalTok{ conc\_Na, }\AttributeTok{data =}\NormalTok{ .x)),}
         \AttributeTok{tidied =} \FunctionTok{map}\NormalTok{(fit, tidy),}
         \AttributeTok{glanced =} \FunctionTok{map}\NormalTok{(fit, glance),}
         \AttributeTok{augmented =} \FunctionTok{map}\NormalTok{(fit, augment)}
\NormalTok{         )}
\NormalTok{calCurve}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
## # Groups:   type [1]
##   type     data              fit    tidied           glanced           augmented
##   <chr>    <list>            <list> <list>           <list>            <list>   
## 1 standard <tibble [15 x 4]> <lm>   <tibble [2 x 5]> <tibble [1 x 12]> <tibble>
\end{verbatim}

Things look a bit more complicated than our earlier example, so let's break down our code line by line:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We're taking the \texttt{FAES} dataset that we created earlier.
\item
  \texttt{group\_by(type)} groups all rows by \texttt{type}, in this situation we have only one type: \texttt{standard}.
\item
  \texttt{nest()} collapses everything other than the \texttt{type} column into smaller data-frames. In this situation, all other information is stored as a \texttt{tibble} under the \texttt{data} column; this is the data used to calculate the linear model.
\item
  Withing the \texttt{mutate} function, we've created four columns: \texttt{fit}, \texttt{tidied}, \texttt{glanced}, and \texttt{augmented}.
\end{enumerate}

And it's these columns that contain our cleaned up model outputs. \texttt{fit} contains the raw output from the linear regression model for \texttt{signal} as a function of \texttt{conc\_Na} using the \texttt{lm()} function. The output is in the form of a list, similar to what \texttt{summary()} gave us above. Again, this is exceptionally messy, hence why we used the \texttt{tidy()}, \texttt{glance()}, and \texttt{augment()} functions from the \texttt{broom} package . \texttt{map()} just means we're applying the function \texttt{tidy()} to the individual output list created by \texttt{lm()} and stored in the \texttt{fit} column. Note that the \texttt{tidy()}, \texttt{glanced()}, and \texttt{augmented} outputs are tibbles. So we now have a tibble containing specific model output values (i.e.~\texttt{(Intercept)}), lists (i.e.~\texttt{fit}), and tibbles (\texttt{tidied}). This is known as **nested data*. We're no longer in Kansas anymore\ldots{}

We'll break down what each function did below. Keep in mind however that \texttt{lm()} is used for a variety of statistical tests, and consequently has many associated outputs. Some are essential, others are useful, and some are useless for linear calibration. There are also many ways to use these additional model outputs to calculate outliers, etc. but you shouldn't have any outliers in your calibration model. Don't rely on statistics to bail you out of poor chemical technique.

\hypertarget{glanced-outputs}{%
\subsection{Glanced outputs}\label{glanced-outputs}}

Anyways, let's take a look at our model results. The \texttt{glanced} tibble contains ``\ldots a concise one-row summary of the model. This typically contains values such as R\^{}2, adjusted R\^{}2, and residual standard error that are computed once for the entire mode''{[}\^{}linear-regression-1{]} Because the data is nested, we'll need to use \texttt{unnest()} to flatten it back out into regular columns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glanced }\OtherTok{\textless{}{-}}\NormalTok{ calCurve }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unnest}\NormalTok{(glanced)}

\CommentTok{\# DT is to make interactive tables for the book.}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(glanced, }
              \AttributeTok{options =} \FunctionTok{list}\NormalTok{(}\AttributeTok{scrollX =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

What you see here is a bit more than what you'd get from \emph{Excel}'s `line-of-best fit' output. In brief, :

\begin{itemize}
\tightlist
\item
  \texttt{type}, \texttt{data}, \texttt{fit}, \texttt{tidied}, and \texttt{augmented} are columns we've created earlier.
\item
  \texttt{r.squared} is a statistical measure of fit that indicates how much variation of a dependent variable is explained by the independent variable. The closer \texttt{r.squared} is to 1, the more variance is captured by the model.
\item
  \texttt{adj.r.squared} is the same as \texttt{r.squared} in this situation. This is because \texttt{r.squared} will always increase if we add more exploratory variables to our model; the \texttt{adj.r.squared} accounts for the number of exploratory variables used in the model.

  \begin{itemize}
  \tightlist
  \item
    In our case we only have one exploratory variable, hence they're approximately the same.
  \end{itemize}
\item
  The other columns are different measurements of goodness-of-fit and hypothesis testing of the model. See \protect\hyperlink{further-reading}{Further reading}.
\end{itemize}

\hypertarget{tidied-outputs}{%
\subsection{Tidied outputs}\label{tidied-outputs}}

But what about the slope and the intercept? After all, that's what we need to calculate the concentration in our unknowns. Let's take a look at \texttt{tidied} from the \texttt{tidy()} function which constructs a tibble that summarizes the model's statistical findings. This includes coefficients and p-values for each term in a regression:{]}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# storing because we\textquotesingle{}ll use it later on. }

\NormalTok{tidied }\OtherTok{\textless{}{-}}\NormalTok{ calCurve }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest}\NormalTok{(tidied)}

\CommentTok{\# DT is to make interactive tables for the book.}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(tidied, }
              \AttributeTok{options =} \FunctionTok{list}\NormalTok{(}\AttributeTok{scrollX =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Again, a lot more to unpack compared to \emph{Excel}. That's because the \texttt{lm()} function in R calculates a generalized linear model. \texttt{lm()} performs a linear regression model, which we normally think of as an equation of the form \(y= a + bx\) as discussed earlier. But, regression models can be expanded to account for multiple variables (hence \emph{multiple linear regression}) of the form:

\[y = \beta _{0} + \beta _{1} x_{1} + \beta _{2} x_{2} ... \beta _{p} x_{p}\]{]}

where,

\begin{itemize}
\tightlist
\item
  \(y\) = dependent variable
\item
  \(x\) = exploratory variable; there's no limit how many you can input
\item
  \(\beta _{0}\) = y-intercept (constant term)
\item
  \(\beta _{p}\) = slope coefficient for each explanatory variable
\end{itemize}

With our linear calibration model, we only have one input variable for our model (\texttt{conc}), so the above formula collapses down to \(y = \beta _{0} + \beta _{1} x_{1}\). So looking at our tidied model outputs:

\begin{itemize}
\tightlist
\item
  each row corresponds to a model coefficient (under the \texttt{term} column).
\item
  For each modelling parameter, we're provided an estimate of it's numerical value: \texttt{estimate}. These are the values we'll use to calculate concentration.
\item
  \texttt{std.error} measures how precisely the model estimates the coefficient's unknown value; smaller is better.
\item
  \texttt{p.value} is a indication of the significance of a model coefficient; the closer to zero the better.

  \begin{itemize}
  \tightlist
  \item
    If we were to use multiple parameters in our model (eg. concentration and temperature) we could use the \texttt{p.value} to determine if a given coefficient was useful for our model.
  \end{itemize}
\end{itemize}

We can extract the value of the model coefficients for subsequent calculations as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# intercept}
\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(tidied[}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{])}

\CommentTok{\# slope }
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(tidied[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{])}

\FunctionTok{paste}\NormalTok{(}\StringTok{"The equation of our calibration curve is: y = "}\NormalTok{, a, }\StringTok{" + "}\NormalTok{, b,}\StringTok{"x"}\NormalTok{, }\AttributeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The equation of our calibration curve is: y = 2615.11945030675 + 29707.1701380368x"
\end{verbatim}

\hypertarget{augmented-outputs}{%
\subsection{Augmented outputs}\label{augmented-outputs}}

Finally let's take a look at the outputs of the \texttt{augment} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# storing because we\textquotesingle{}ll use it later on. }

\NormalTok{augmented }\OtherTok{\textless{}{-}}\NormalTok{ calCurve }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest}\NormalTok{(augmented)}

\CommentTok{\# DT is to make interactive tables for the book.}
\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(augmented, }
              \AttributeTok{options =} \FunctionTok{list}\NormalTok{(}\AttributeTok{scrollX =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

As you can see, \texttt{augment()} adds columns to the original data that was modelled. For our purposes we're interested:

\begin{itemize}
\tightlist
\item
  \texttt{signal} and \texttt{conc\_Na}, the original data used in our model.
\item
  \texttt{.fitted}, the predicted value of the point according to our calculated model.
\item
  \texttt{.resid}, the residuals of that point (different between measured and fitted values.)
\item
  The other parameters are different measurements of the influence of each point on the model fitting. They can be used to detect outliers; see \protect\hyperlink{further-reading}{Further reading}
\end{itemize}

\hypertarget{why-we-approach-modelling-this-way}{%
\subsection{Why we approach modelling this way}\label{why-we-approach-modelling-this-way}}

You may be wondering why we've seemingly overcomplicated a simple enough procedure. Fair enough, we've showcased an analysis with a simple data set. However, as you progress in your studies you'll be quantifying \emph{many} compounds, often at the same time in the same instrument runs. If you organize your data in a tidy format, you can plot calibration curves for \emph{all} of your compounds with the same block of code. Essentially you use \texttt{group\_by()} to group your data by compound/element. Subsequently, the same code is expandable from 1 compound to as many as you can ever hope to quantify in one shot. So for upper year labs where you're analyzing tens of compounds (\emph{cough} CHM410 Dust Lab) you can generate calibration curves for all your compounds at once.

\hypertarget{visualizing-models}{%
\section{Visualizing models}\label{visualizing-models}}

At the top of the chapter we plotted out standards to visualize a linear trend. Visualizations is an essential component when calculating calibration curves, and indeed our standards appeared to follow a linear trend, which was corroborated by the model we calculated above. However, for publications/reports you'll need to create a plot with both your standards \emph{and} model with the displayed equation, so below is a bit of stock code you can use as a starting point to create these plots. Note that it requires the \texttt{ggpmisc} package to display the equation:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ FAES,}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc\_Na, }
           \AttributeTok{y =}\NormalTok{ signal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{\textquotesingle{}lm\textquotesingle{}}\NormalTok{, }\AttributeTok{se=}\NormalTok{F) }\SpecialCharTok{+}
\NormalTok{  ggpmisc}\SpecialCharTok{::}\FunctionTok{stat\_poly\_eq}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\CommentTok{\# formula uses aesthetic names}
                        \AttributeTok{rr.digits =} \DecValTok{4}\NormalTok{, }\CommentTok{\# reported digits of r{-}squared}
                        \FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{paste}\NormalTok{(..eq.label.., ..rr.label.., }\AttributeTok{sep =} \StringTok{"\textasciitilde{}\textasciitilde{}\textasciitilde{}"}\NormalTok{)), }
                        \AttributeTok{parse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Registered S3 methods overwritten by 'ggpp':
##   method                  from   
##   heightDetails.titleGrob ggplot2
##   widthDetails.titleGrob  ggplot2
\end{verbatim}

\begin{verbatim}
## Registered S3 method overwritten by 'ggpmisc':
##   method                  from   
##   as.character.polynomial polynom
\end{verbatim}

\begin{verbatim}
## Warning: The dot-dot notation (`..eq.label..`) was deprecated in ggplot2 3.4.0.
## i Please use `after_stat(eq.label)` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.
\end{verbatim}

\begin{verbatim}
## `geom_smooth()` using formula = 'y ~ x'
\end{verbatim}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-165-1.pdf}

\hypertarget{vizualizing-residuals}{%
\subsection{Vizualizing residuals}\label{vizualizing-residuals}}

As stated earlier, residuals are the difference between measured and fitted values. They're often overlooked in linear calibration and folks are hot to plot a straight line through their data. This has the unintended effect of fooling your eyes into thinking your data is linear. Consequently, it is always a good idea to plot the residuals of your model as this will magnify any trends or discrepancies of your calibration model. A good linear model will have the residuals randomly distributed about zero. Other examples of patterns in residuals are shown below:

\begin{figure}
\centering
\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-166-1.pdf}
\caption{\label{fig:unnamed-chunk-166}Example residual patterns; figure adapted from Hibbert and Gooding (2006).}
\end{figure}

\begin{itemize}
\tightlist
\item
  Normally distributed residuals is satisfactory for linear modelling. Note the relatively small magnitude of the residuals.
\item
  Curvature throughout range results from an instrument become saturated. Consequently, the linear model will `cut' through the curve. This is a good indication that you'll need to either breakdown your calibration curve into two or more parts or utilize a non-linear model.
\item
  Heteroscedasticity means the variance of the response is proportional to the concentration. This is often the case in instrumental analysis. See \protect\hyperlink{weighing}{Weighing} below.
\item
  Outliers shouldn't exist in your calibration plot, nevertheless, a plot of residuals can readily highlight an outlier point.
\end{itemize}

\hypertarget{plotting-residuals}{%
\subsection{Plotting residuals}\label{plotting-residuals}}

To plot residuals, we use our \texttt{augmented} dataset from above, and simply create a plot of the independent variable vs.~the residuals. Here we plot the FAES calibration model and it's residuals. Note that the residuals indicate curvature throughout the range. We may have over extended our calibration range \emph{outside} of the linear range of our instrument.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ FAES,}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc\_Na, }
           \AttributeTok{y =}\NormalTok{ signal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{\textquotesingle{}lm\textquotesingle{}}\NormalTok{, }\AttributeTok{se=}\NormalTok{F) }\SpecialCharTok{+}
\NormalTok{  ggpmisc}\SpecialCharTok{::}\FunctionTok{stat\_poly\_eq}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\CommentTok{\# formula uses aesthetic names}
                        \AttributeTok{rr.digits =} \DecValTok{4}\NormalTok{, }\CommentTok{\# reported digits of r{-}squared}
                        \FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{paste}\NormalTok{(..eq.label.., ..rr.label.., }\AttributeTok{sep =} \StringTok{"\textasciitilde{}\textasciitilde{}\textasciitilde{}"}\NormalTok{)), }
                        \AttributeTok{parse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}\NormalTok{) }

\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ augmented, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc\_Na, }\AttributeTok{y =}\NormalTok{ .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}

\NormalTok{ggpubr}\SpecialCharTok{::}\FunctionTok{ggarrange}\NormalTok{(a, b, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula = 'y ~ x'
\end{verbatim}

\begin{figure}
\centering
\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-167-1.pdf}
\caption{\label{fig:unnamed-chunk-167}(A) linear calibration model and (B) plot of model residuals.}
\end{figure}

\hypertarget{calculating-concentrations}{%
\section{Calculating Concentrations}\label{calculating-concentrations}}

In \protect\hyperlink{tidied-outputs}{Tidied outputs} we extracted our model coefficients (slope and intercept):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# intercept}
\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(tidied[}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{])}

\CommentTok{\# slope}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(tidied[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{])}

\FunctionTok{paste}\NormalTok{(}\StringTok{"The equation of our calibration curve is: y = "}\NormalTok{, a, }\StringTok{" + "}\NormalTok{, b,}\StringTok{"x"}\NormalTok{, }\AttributeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The equation of our calibration curve is: y = 2615.11945030675 + 29707.1701380368x"
\end{verbatim}

Now that we have our coefficients, we can calculate the sample concentration as described in \protect\hyperlink{modelling-theory}{Modelling Theory}. Let's import the FAES unknown dataset first:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{FAESsamples }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\AttributeTok{file =} \StringTok{"data/FAESUnknowns.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(sample, }\StringTok{\textasciigrave{}}\AttributeTok{dilution factor}\StringTok{\textasciigrave{}}\NormalTok{), }
               \AttributeTok{names\_to =} \StringTok{"replicate"}\NormalTok{,}
               \AttributeTok{names\_prefix =} \StringTok{"reading\_"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"signal"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 3 Columns: 5
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): sample
## dbl (4): dilution factor, reading_1, reading_2, reading_3
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{FAESsamples}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 4
##   sample    `dilution factor` replicate signal
##   <chr>                 <dbl> <chr>      <dbl>
## 1 wine                     10 1         12775.
## 2 wine                     10 2         12651.
## 3 wine                     10 3         12746.
## 4 tap-water                10 1          8014.
## 5 tap-water                10 2          7200.
## 6 tap-water                10 3          7203.
## 7 fish-tank               100 1         12085.
## 8 fish-tank               100 2         12073.
## 9 fish-tank               100 3         12156.
\end{verbatim}

Now it's simply a matter of calculating the concentration of the sample analyzed by the instrument, and correcting for the dilution factor to find the concentration in the parent sample:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{FAESsamples }\OtherTok{\textless{}{-}}\NormalTok{ FAESsamples }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\StringTok{"instConc"} \OtherTok{=}\NormalTok{ (signal }\SpecialCharTok{{-}}\NormalTok{ a)}\SpecialCharTok{/}\NormalTok{b,}
         \StringTok{"sampleConc"} \OtherTok{=}\NormalTok{ instConc }\SpecialCharTok{*} \StringTok{\textasciigrave{}}\AttributeTok{dilution factor}\StringTok{\textasciigrave{}}\NormalTok{)}

\NormalTok{DT}\SpecialCharTok{::}\FunctionTok{datatable}\NormalTok{(FAESsamples, }\AttributeTok{options =} \FunctionTok{list}\NormalTok{(}\AttributeTok{scrollX =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

And let's summarize our results using code from the \protect\hyperlink{summarizing-data}{Summarizing data} chapter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{FAESsamples }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(sample) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(sampleConc),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(sampleConc),}
            \AttributeTok{n =} \FunctionTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   sample     mean     sd     n
##   <chr>     <dbl>  <dbl> <int>
## 1 fish-tank 31.9  0.150      3
## 2 tap-water  1.64 0.158      3
## 3 wine       3.40 0.0219     3
\end{verbatim}

And there we go. See the \protect\hyperlink{summarizing-data}{Summarizing data} and {[}Visualizations{]} chapters for assiting an making prettier tables and visualizations, respectively.

\hypertarget{summary-5}{%
\section{Summary}\label{summary-5}}

In this chapter we've covered:

\begin{itemize}
\tightlist
\item
  The essential theory undergirding the linear calibration model.
\item
  How to scallably model in R with a consistent workflow for one or thousands of linear calibration models.
\item
  How to extract model parameters using the \texttt{tidy()}, \texttt{glance()}, and \texttt{augment()} functions from the \texttt{broom} package.
\item
  A brief overview of model parameters as they pertain to linear calibration.
\item
  Viasualizing models and the importance of visualizing residuals.
\item
  Calculating sample concentration from model outputs.
\end{itemize}

\hypertarget{further-reading-6}{%
\section{Further reading}\label{further-reading-6}}

As previously stated, we highly recommend reading Chapter 5: Calibration from \emph{Data Analysis for Chemistry} by Hibbert and Gooding for a more in-depth discussion of linear calibration modelling. The book can be accessed online via the University of Toronto's Library.

For a greater discussion on modelling in R, see \href{https://r4ds.had.co.nz/model-intro.html}{Modelling} in \href{https://r4ds.had.co.nz/index.html}{\emph{R for Data Science}}.

\hypertarget{going-deeper-with-modelling}{%
\section{Going deeper with modelling}\label{going-deeper-with-modelling}}

\hypertarget{weighing}{%
\subsection{Weighing}\label{weighing}}

As shown above, you'll often find that your calibration data is \emph{heteroscedastic}, meaning the variance increases with the concentration. This leads to \emph{leverage} of your line-of-best fit, as it is `pulled' by one way or another by the higher concentration standards then the lower. You can assign `weights' (how much a point impacts the model) in R, although you'll need to justify the validity of your approach. A common approach however, is to weight each standard by \(\frac{1}{x^2}\). This ensures that samples with higher concentration impact the line less, and vice-versa with low-concentration standards.

To utilize weight in R, we need to calculate the weigh prior to modelling, and subsequently specify the weights column

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# note that our blank has a concentration of 0, hence infinite weight. }
\CommentTok{\# we need to remove it to weight our data. }

\NormalTok{FAESweighed }\OtherTok{\textless{}{-}}\NormalTok{ FAES }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(conc\_Na }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{wght =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(conc\_Na}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}

\NormalTok{weightedCalCurve }\OtherTok{\textless{}{-}}\NormalTok{ FAESweighed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(type) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{nest}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fit =} \FunctionTok{map}\NormalTok{(data, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{lm}\NormalTok{(signal }\SpecialCharTok{\textasciitilde{}}\NormalTok{ conc\_Na, }\AttributeTok{data =}\NormalTok{ .x, }\AttributeTok{weights =}\NormalTok{ wght)),}
         \AttributeTok{tidied =} \FunctionTok{map}\NormalTok{(fit, tidy),}
         \AttributeTok{glanced =} \FunctionTok{map}\NormalTok{(fit, glance),}
         \AttributeTok{augmented =} \FunctionTok{map}\NormalTok{(fit, augment)}
\NormalTok{         ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unnest}\NormalTok{(augmented)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ weightedCalCurve, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc\_Na, }\AttributeTok{y =}\NormalTok{ signal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{\textquotesingle{}lm\textquotesingle{}}\NormalTok{, }\AttributeTok{se=}\NormalTok{F, }\AttributeTok{colour =} \StringTok{"red"}\NormalTok{, }\AttributeTok{label =} \StringTok{"unweighed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{\textquotesingle{}lm\textquotesingle{}}\NormalTok{, }\AttributeTok{se=}\NormalTok{F, }\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{, }
              \FunctionTok{aes}\NormalTok{(}\AttributeTok{weight=}\StringTok{\textasciigrave{}}\AttributeTok{(weights)}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{label =} \StringTok{"weighed"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in geom_smooth(method = "lm", se = F, colour = "red", label =
## "unweighed"): Ignoring unknown parameters: `label`
\end{verbatim}

\begin{verbatim}
## Warning in geom_smooth(method = "lm", se = F, colour = "blue", aes(weight =
## `(weights)`, : Ignoring unknown aesthetics: label
\end{verbatim}

\begin{verbatim}
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
\end{verbatim}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-172-1.pdf}

\hypertarget{modelling-non-linear-regression}{%
\chapter{Modelling: Non-Linear Regression}\label{modelling-non-linear-regression}}

We've touched upon the basics of modelling in R but it doesn't have to stop there. This chapter will expand upon the contents of \protect\hyperlink{modelling-linear-regression}{Modelling: Linear Regression} to cover non-linear regressions. Since we can't account for the myriad of models utilized throughout the field, we'll work through a case-study.

\hypertarget{experimental-background}{%
\section{Experimental Background}\label{experimental-background}}

For this chapter we'll be using data obtained from an experiment in \emph{CHM317}. In this experiment, students measure the fluorescence of the fluorescent dye acridine orange in the presence of sodium dodecyl sulfate (SDS). In, or near, the critical micellular region of SDS, there is a sharp change in absorbance and fluorescence of the solution. Tracking these changes in fluorescence, students can then estimate the CMC of SDS. Experimentally, students prepared solutions of a constant concentration of acridine orange and varying concentrations of SDS. The emission spectrum of each sample was recorded, and we want to take the maximal of each spectra as a data point to built our model.

Let's go ahead and import our data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{sds }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/CHM317/fluoro\_SDSCMC.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{!}\StringTok{\textasciigrave{}}\AttributeTok{Wavelength (nm)}\StringTok{\textasciigrave{}}\NormalTok{, }\CommentTok{\# select all columns BESIDES \textasciigrave{}Wavelength (nm)\textasciigrave{}}
               \AttributeTok{names\_to =} \FunctionTok{c}\NormalTok{(}\StringTok{"conc"}\NormalTok{, }\StringTok{"conc.units"}\NormalTok{, }\StringTok{"chemical"}\NormalTok{),}
               \AttributeTok{names\_pattern =} \StringTok{"(.*) (.) (.*)"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"intensity"}\NormalTok{,}
               \AttributeTok{names\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{conc =}\NormalTok{ as.numeric)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{wavelength =} \StringTok{\textquotesingle{}Wavelength (nm)\textquotesingle{}}\NormalTok{) }\CommentTok{\# renaming column, less typing later on. }

\FunctionTok{head}\NormalTok{(sds)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavelength   conc conc.units chemical intensity
##        <dbl>  <dbl> <chr>      <chr>        <dbl>
## 1        500 0.001  M          SDS          20.0 
## 2        500 0.0016 M          SDS          18.6 
## 3        500 0.004  M          SDS           7.02
## 4        500 0.0048 M          SDS           1.12
## 5        500 0.0056 M          SDS           5.48
## 6        500 0.0064 M          SDS           7.72
\end{verbatim}

And a quick plot to visualize our data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sds, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavelength,}
           \AttributeTok{y =}\NormalTok{ intensity, }
           \AttributeTok{colour =}\NormalTok{ conc)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-174-1.pdf}

Alright, alright, alright. Things are looking like we'd expect with some well behaved data. By plotting each point individually, we can really see the noise inherent with each reading. For a more robust analysis we'd typically conduct several replicates and average out the spectra for each concentration or apply some kind of model to smooth each peak. But today, we're just interested in getting the maximal fluorescence emission intensity from each reading.

Let's first annotate our plate to find the highest point, then go about extracting our data for analysis.

\hypertarget{annotating-maximal-values}{%
\subsection{Annotating maximal values}\label{annotating-maximal-values}}

Annotating the maximal point on the plot will take a bit more code then actually obtaining it from the data. For this we'll need to use the \texttt{ggpmisc} package which contains miscellaneous extensions for \texttt{ggplot2}, and \texttt{ggrepel} so our labels won't overlap.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggpmisc)}
\FunctionTok{library}\NormalTok{(ggrepel)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sds, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ wavelength,}
           \AttributeTok{y =}\NormalTok{ intensity, }
           \AttributeTok{colour =}\NormalTok{ conc)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
\NormalTok{  ggpmisc}\SpecialCharTok{::}\FunctionTok{stat\_peaks}\NormalTok{(}\AttributeTok{span =} \ConstantTok{NULL}\NormalTok{,}
                      \AttributeTok{geom =} \StringTok{"text\_repel"}\NormalTok{, }\CommentTok{\# From ggrepel}
                      \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{paste}\NormalTok{(..y.label.., ..x.label..)),}
                      \AttributeTok{x.label.fmt =} \StringTok{"at \%.0f nm"}\NormalTok{,}
                      \AttributeTok{y.label.fmt =} \StringTok{"Max intensity = \%.0f"}\NormalTok{,}
                      \AttributeTok{segment.colour =} \StringTok{"black"}\NormalTok{,}
                      \AttributeTok{arrow =}\NormalTok{ grid}\SpecialCharTok{::}\FunctionTok{arrow}\NormalTok{(}\AttributeTok{length =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\StringTok{"inches"}\NormalTok{)),}
                      \AttributeTok{nudge\_x =} \DecValTok{60}\NormalTok{,}
                      \AttributeTok{nudge\_y =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\AttributeTok{rows =} \FunctionTok{vars}\NormalTok{(conc))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-175-1.pdf}

By faceting the plot (i.e.~arranging many smaller plots vs.~one large one), we can easily see the increase in emission peak intensity as the concentration of SDS increases. Likewise, we can avoid the messy overlap of the max intensity annotations.

This is only one way to plot this data, but this is sufficient because we're simply inspecting our data at this point. And here we can see that the intensity all occur around a similar wavelength (\textasciitilde{} 528 nm)

\hypertarget{extracting-maximal-values}{%
\subsection{Extracting maximal values}\label{extracting-maximal-values}}

The plots we made above are great for inspecting our data, but what we really want is the maximal emission intensity value to calculate the CMC of SDS. We can see the maximal values on the plots, but there's no way we're typing those in manually. So let's go ahead and get out maximal values from our dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdsMax }\OtherTok{\textless{}{-}}\NormalTok{ sds }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(chemical, conc.units, conc) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(intensity }\SpecialCharTok{==} \FunctionTok{max}\NormalTok{(intensity)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\FunctionTok{head}\NormalTok{(sdsMax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   wavelength   conc conc.units chemical intensity
##        <dbl>  <dbl> <chr>      <chr>        <dbl>
## 1       520  0.0056 M          SDS           28.1
## 2       524  0.0072 M          SDS          116. 
## 3       527  0.0064 M          SDS           65.3
## 4       527  0.008  M          SDS          768. 
## 5       528. 0.012  M          SDS          810. 
## 6       528  0.0048 M          SDS           22.0
\end{verbatim}

All we did was tell R to take the row with the highest emission intensity value per group. We specified \texttt{chemical}, \texttt{conc.units}, and \texttt{conc}, in case we had more chemicals in our dataset.

Our maximum values match those we see in our plot above. Let's see how they stack up against each other:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sdsMax, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc, }
           \AttributeTok{y =}\NormalTok{ intensity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{R4EnvChem_files/figure-latex/sdsMaxPlot-1.pdf}
\caption{\label{fig:sdsMaxPlot}Plot of maximal fluoresence intensity at various concentrations of SDS.}
\end{figure}

\hypertarget{modelling-sigmoid-curve}{%
\section{Modelling Sigmoid Curve}\label{modelling-sigmoid-curve}}

So we want to find the critical micellular concentration of SDS using the maximum fluorescence emission. The CMC is at the `midpoint of the sinusoid curve'. Which means we'll need to a) plot a sinusoid curve and b) extract the midpoint.

The `sinusoid' or `S-shaped' curve mentioned in the lab manual is known as a \emph{logistic regression}. Logistic regressions are often used to model systems with a largely binary outcome. In other words, the system starts at point A, and remains there for awhile, before `quickly' jumping up (or down) to level B and remain there for the remainder. Examples include saturation and dose response curves.

For our CMC working data, the fluorescence intensity is low when the \([SDS] < CMC\), as micelles are not able to form. However once \([SDS] > CMC\), micelles form and the fluorescence intensity increases. We can see this trend in \ref{fig:sdsMaxPlot}.

There are different forms of logistic regression equations. The simplest form is the 1 parameter, or sigmoid, function which looks like \(f(x) = \frac{1}{1+e^{-x}}\). The outputs for this function are between 0 and 1. We could apply this formula to our model if we somehow normalized our fluorescence intensity accordingly. An alternative is to use the \emph{four parameter logistic regression}, which looks like:

\[f(x) =  \frac{a - d}{\left[ 1 + \left( \frac{x}{c} \right)^b \right ]} + d\]

where:

\begin{itemize}
\tightlist
\item
  \textbf{a} = the theoretical response when \(x = 0\)
\item
  \textbf{b} = the slope factor
\item
  \textbf{c} = the mid-range concentration (inflection point)

  \begin{itemize}
  \tightlist
  \item
    This is commonly referred to as the \emph{EC50} or \emph{LC50} in toxicology/pharmacology.
  \end{itemize}
\item
  \textbf{d} = the theoretical response when \(x = \infty\)
\end{itemize}

Why do we need such a complicated formula for our model? Well, looking again at \ref{fig:sdsMaxPlot} we see that the lower point is approximately 20, and not zero. Likewise, the upper limit appears to be around 825. The slope factor is necessary because the transition from the low to high steady state occurs over a small, but not immeasurable, concentration range. And lastly, by including the inflection point, we can calculate exactly for this value using \texttt{R} to get the CMC estimate.

\hypertarget{calculating-logistic-regression}{%
\subsection{Calculating Logistic Regression}\label{calculating-logistic-regression}}

A strength of \texttt{R} is it's flexibility in running various models, and logistic regression is no different. We can use a number of packages to reach these ends, specifically the \texttt{drc} package contains a plethora of functions for modelling dose response curves (hence \texttt{drc}). However, for this example well use a more generalized approach. Earlier we talked about linear regression, where we plot adjust the slope and intercept of a linear equation to best fit our data (see Calibration Curves). Recall that this optimization is based on minimizing the distance between the model and all of the experimental points (\emph{least squares}). Well the \texttt{stats} package has a function called \texttt{nls} that expands upon the this to nonlinear models. Per the \texttt{nls} function description: ``{[}nls{]} determine{[}s{]} the nonlinear (weighted) least\_squared estimates of the parameters of a nonlinear model.''

So we can create a formula in \texttt{R} based on the four-parameter logistic regression described above. After that, we'll need to produce some starting details from which the model can build off of. If we don't tell \texttt{nls} where to start, it can't function, as the search space is too large. Looking at @ref\{fig:sdsMaxPlot\}, the intensity appears to floor around 20; the intensity appears to max out around 820; the midpoint appears to be around 0.0075 M, and let's say the slope is 1. Remember, these are starting values from which \texttt{nls} starts to optimize from, and not the actual values used to construct the model.

So, let's create our model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logisModel }\OtherTok{\textless{}{-}} \FunctionTok{nls}\NormalTok{(intensity }\SpecialCharTok{\textasciitilde{}}\NormalTok{  (a}\SpecialCharTok{{-}}\NormalTok{d)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (conc }\SpecialCharTok{/}\NormalTok{c)}\SpecialCharTok{\^{}}\NormalTok{b) }\SpecialCharTok{+}\NormalTok{ d, }
                  \AttributeTok{data =}\NormalTok{ sdsMax, }
                  \AttributeTok{start =} \FunctionTok{list}\NormalTok{(}\AttributeTok{a =} \DecValTok{20}\NormalTok{,       }\CommentTok{\# min intensity}
                               \AttributeTok{b =} \DecValTok{1}\NormalTok{,        }\CommentTok{\# slope}
                               \AttributeTok{c =} \FloatTok{0.0075}\NormalTok{,   }\CommentTok{\# CMC}
                               \AttributeTok{d=} \DecValTok{820}\NormalTok{)       }\CommentTok{\# max intensity}
\NormalTok{                  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in numericDeriv(form[[3L]], names(ind), env, central = nDcentral): Missing value or an infinity produced when evaluating the model
\end{verbatim}

\ldots{} and we get an error message. Get used to these when modelling! Don't worry about understanding it completely, error messages are often written with programmers in mind so they can be a bit cryptic. You can often copy and paste these directly into any search engine to get some more information, but this one is simple enough: we either have a missing value or an infinity produced. Well we have six input parameters in our model: \texttt{a,\ b,\ c,\ d}, our independent variable \texttt{conc}, and our dependant variable \texttt{intensity}. We've also supplied starting values to all of them via the list we created inside the function. Therefore, one of our starting values must be too far off from a plausible start point and is causing troubles in the \texttt{nls} function. They all look good except for the slope start value \texttt{b\ =\ 1}.

The slope here is an approximation for the slope between the min value \texttt{a} and max value \texttt{d}. Looking at our data in @ref\{fig:sdsMaxPlot\}, that slope may be a bit shallow consider the large jump in intensity. Let's increase the value of \texttt{b} and try again:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logisModel }\OtherTok{\textless{}{-}} \FunctionTok{nls}\NormalTok{(intensity }\SpecialCharTok{\textasciitilde{}}\NormalTok{  (a}\SpecialCharTok{{-}}\NormalTok{d)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (conc }\SpecialCharTok{/}\NormalTok{c)}\SpecialCharTok{\^{}}\NormalTok{b) }\SpecialCharTok{+}\NormalTok{ d, }
                  \AttributeTok{data =}\NormalTok{ sdsMax, }
                  \AttributeTok{start =} \FunctionTok{list}\NormalTok{(}\AttributeTok{a =} \DecValTok{20}\NormalTok{,       }\CommentTok{\# min intensity}
                               \AttributeTok{b =} \DecValTok{10}\NormalTok{,       }\CommentTok{\# new slope}
                               \AttributeTok{c =} \FloatTok{0.0075}\NormalTok{,   }\CommentTok{\# CMC}
                               \AttributeTok{d=} \DecValTok{820}\NormalTok{)       }\CommentTok{\# max intensity}
\NormalTok{                  )}
\end{Highlighting}
\end{Shaded}

Eh, no errors! Once you progress beyond simple linear regressions, modelling becomes more of a craft. If we were trying to apply this model to multiple datasets, we would probably want to shop around \texttt{cran} to find a package with self-starting models. This way we can circumvent having to supply starting parameters. Anyways, that's for another day.

For now, let's take a look at our model outputs which are all stored in the \texttt{logisModel} variable. To this end, we'll use the \texttt{broom} package discussed in \protect\hyperlink{modelling-linear-regression}{Modelling: Linear Regression}. Specifically, we'll use \texttt{tidy} to get an output of our estimated model parameters (i.e.~\texttt{a,b,c}, and \texttt{d}), and \texttt{augment} for a data frame of containing the input values, and the estimated intensity values.

Let's look at our fitted values:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}

\NormalTok{augment }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(logisModel)}
\NormalTok{augment}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 4
##   intensity   conc .fitted   .resid
##       <dbl>  <dbl>   <dbl>    <dbl>
## 1      28.1 0.0056    49.4 -21.3   
## 2     116.  0.0072   116.   -0.123 
## 3      65.3 0.0064    49.7  15.6   
## 4     768.  0.008    768.    0.0977
## 5     810.  0.012    810.   -0.0861
## 6      22.0 0.0048    49.4 -27.5   
## 7      93.0 0.001     49.4  43.5   
## 8      31.7 0.004     49.4 -17.7   
## 9      57.0 0.0016    49.4   7.51
\end{verbatim}

What we can see here from \texttt{augment} are the \texttt{intensity} and \texttt{conc} values we inputted into R. \texttt{.fitted} are the intensity values for a given concentration fitted to out model, and \texttt{.resid} is the residuals, the difference between the actual and estimated values.

Let's go ahead and plot our actual and fitted values against each other.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(augment, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc, }\AttributeTok{y =}\NormalTok{ intensity, }\AttributeTok{colour =} \StringTok{"actual"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ .fitted)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ .fitted, }\AttributeTok{colour =} \StringTok{"fitted"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-180-1.pdf}

Looks pretty good, although it's interesting how the baseline at lower concentrations doesn't plateau like the model values. You'll note that the line produced by \texttt{geom\_line} will only draw a straight line between points. There's ways to address this, but we don't need to for our needs right now.

There doesn't appear to be any gross outliers in our model, so it seems to have done a good job. We can verify this by checking the residuals(see \protect\hyperlink{plotting-residuals}{Plotting residuals}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(augment, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ conc, }\AttributeTok{y =}\NormalTok{ .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{R4EnvChem_files/figure-latex/unnamed-chunk-181-1.pdf}

We can't see any obvious patterns in the residuals (i.e.~all are negative), so we can have further confidence in the fit of out model.

\hypertarget{extracting-model-parameters}{%
\subsection{Extracting model parameters}\label{extracting-model-parameters}}

To extract the model parameters \texttt{a}, \texttt{b}, \texttt{c}, and \texttt{d} we can use the \texttt{tidy} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}

\NormalTok{tidy }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(logisModel)}
\NormalTok{tidy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term   estimate  std.error statistic       p.value
##   <chr>     <dbl>      <dbl>     <dbl>         <dbl>
## 1 a      49.4     11.1            4.44 0.00678      
## 2 b      49.0      9.65           5.07 0.00385      
## 3 c       0.00755  0.0000785     96.2  0.00000000230
## 4 d     810.      27.3           29.7  0.000000808
\end{verbatim}

Looking past the scientific notation, our model values are pretty similar to what we estimated. Specifically, \texttt{c}, our midpoint value is 0.0076 M. Not too bad from our original estimate. And recall that the midpoint of our curve corresponds to the critical micellular concentration of SDS, which we've estimated to be 0.0076M. Not too far from the literature value of 0.0081 M.

\hypertarget{summary-6}{%
\section{Summary}\label{summary-6}}

In this chapter we reviewed non-linear modelling using a case study with four-parameter logistic regression. While the equation covered here might not be the one you need, the steps are identical:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Tidy and visually inspect your data to see and patterns
\item
  Determine which mathematical model you'll be using
\item
  Use the \texttt{nls} or other suitable package to calculate your model; you may need to tinker around with the starting values, estimate them from your data.
\item
  Verify your model outputs (both fitted and residuals).
\end{enumerate}

Lastly, we've also touched upon labelling maximal values in a plot using the \texttt{ggpmisc} package. Notably useful for determining local peaks in spectroscopy data.

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-Wickham2009}{}}%
Wickham, H. 2009. \emph{Ggplot2: Elegant Graphics for Data Analysis.} New York: Springer-Verlag.

\leavevmode\vadjust pre{\hypertarget{ref-wickham2014}{}}%
Wickham, Hadley. 2014. {``Tidy Data.''} \emph{Journal of Statistical Software} 59 (1): 1--23. \url{https://doi.org/10.18637/jss.v059.i10}.

\end{CSLReferences}

\end{document}
